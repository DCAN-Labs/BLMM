{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FS_sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "q4JYRICVBtjl",
        "AS5zhoWCDZ8E"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIMtrhFKB3Ay",
        "colab_type": "text"
      },
      "source": [
        "# FS implementation in python\n",
        "\n",
        "This code implements the Fisher Scoring algorithm for estimating the parameters of linear mixed effects models as described in [Demidenko 2013](https://www.wiley.com/en-us/Mixed+Models%3A+Theory+and+Applications+with+R%2C+2nd+Edition-p-9781118091579)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNFQ0-MpQuBm",
        "colab_type": "text"
      },
      "source": [
        "## Pip Installations\n",
        "\n",
        "Pip install everything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX02P0KvBWJr",
        "colab_type": "code",
        "outputId": "1257008f-8ec2-4955-cf57-cdbff49d919f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install sparse\n",
        "!pip install nibabel\n",
        "!pip install nilearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.17.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.3)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.17.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: sparse in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sparse) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from sparse) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.45 in /usr/local/lib/python3.6/dist-packages (from sparse) (0.47.0)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.45->sparse) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.45->sparse) (45.2.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (2.3.3)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel) (0.98)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.17.5)\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.14.1)\n",
            "Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (2.3.3)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.17.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.22.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.12.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (0.98)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4JYRICVBtjl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Python Imports\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkTBWbRKQ5ah",
        "colab_type": "text"
      },
      "source": [
        "We need:\n",
        " - `numpy` for matrix handling.\n",
        " - `scipy` for sparse matrix functions.\n",
        " - `pandas` for quick reading and writing of csv files.\n",
        " - `os` and `sys` for basic commandline functions\n",
        " - `time` for timing functions.\n",
        " - `matplotlib` for making displays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tebSlxvBBruv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cvxopt\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import scipy.sparse\n",
        "import scipy.sparse.linalg\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import sys\n",
        "import nibabel as nib\n",
        "import nilearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS5zhoWCDZ8E",
        "colab_type": "text"
      },
      "source": [
        "## Toy Dataset\n",
        "\n",
        "This section read ins and formats a toy dataset. The files used here were generated in `R` and with **True** values (those with postfix `True`) being those used to generate the data and **Estimated** (those with postfix `REst`) values being the estimates `R`'s `lmer` package generated from this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy39zwuhkn4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import shutil and remove old testdata\n",
        "#import shutil\n",
        "#shutil.rmtree('/Data')\n",
        "\n",
        "# Make a data directory\n",
        "if not os.path.isdir('/Data'):\n",
        "  os.mkdir('/Data')\n",
        "  \n",
        "os.chdir('/Data')\n",
        "\n",
        "# Clone small git repo containg some csv files.\n",
        "if not os.path.isdir('/Data/BLMM-testdata'):\n",
        "  !git clone https://github.com/TomMaullin/BLMM-testdata.git\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EWsCZjCQcc9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Z matrix\n",
        "\n",
        "The below reads in Z and makes an image of Z transpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoKOwHqcEKDT",
        "colab_type": "code",
        "outputId": "2f24ddc0-e0ca-46f4-cc56-68ba935e5d46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Read in random effects design matrix and convert it into it's sparse format in\n",
        "# cvxopt.\n",
        "Z_3col=pd.read_csv('/Data/BLMM-testdata/Z_3col.csv',header=None).values#pd.read_csv('/Data/BLMM-testdata/Z_3col_1factor.csv',header=None).values#\n",
        "Z = scipy.sparse.csr_matrix((Z_3col[:,2].tolist(), \\\n",
        "                            ((Z_3col[:,0]-1).astype(np.int64), \\\n",
        "                             (Z_3col[:,1]-1).astype(np.int64))))\n",
        "\n",
        "# Create an image of Z'\n",
        "imshow(Z.toarray().transpose(), \\\n",
        "       interpolation='nearest', vmin=-5, vmax=5, aspect='auto')\n",
        "\n",
        "# Number of subjects\n",
        "n = Z.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaiuxkypB7L8",
        "colab_type": "text"
      },
      "source": [
        "#### Dealing with ill-specified intercept models\n",
        "\n",
        "The above Random effects design matrix has multiple intercepts and is therefore of less than rank $q$; to resolve this we transform $Z$ by a matrix $c$ such that it's now has ($q-\\sum_{i=1}^r\\mathbb{1_{[\\text{Factor i has an intercept}]}}$) orthogonal columns (where $\\mathbb{1}$ is an indicator function). This is achieved in the below code by having $c$ as the unique matrix which subtracts, for each factor, the intercept for the last level of the factor away from the other levels of said factor. This may be clearer to understand in matrix format:\n",
        "\n",
        "Example:\n",
        "\n",
        "$$\\begin{bmatrix} z_1 & 0 & 0 \\\\ z_2 & 0 & 0 \\\\ z_3 & 0 & 0 \\\\0 & z_4 & 0 \\\\ 0 & z_5 & 0 \\\\ 0 & z_6 & 0 \\\\ 0 & 0 & z_7 \\\\ 0 & 0 & z_8 \\\\ 0 & 0 & z_9 \\\\ \\end{bmatrix} c = \\begin{bmatrix} z_1 & 0 \\\\ z_2 & 0 \\\\ z_3 & 0 \\\\0 & z_4 \\\\ 0 & z_5 \\\\ 0 & z_6 \\\\ -z_7 & -z_7 \\\\ -z_8 & -z_8  \\\\ -z_9 & -z_9  \\\\ \\end{bmatrix}$$\n",
        "\n",
        "In this example, $c$ would be given by the matrix:\n",
        "\n",
        "$$c = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ -1 & -1\\end{bmatrix}$$\n",
        "\n",
        "In this code I have made the assumption WLOG that the intercept for each factor, should it be included, is the first parameter listed for each factor.\n",
        "\n",
        "UPDATE: SCRAPPED - RUINED BLOCK DIAGONAL STRUCTURE OF Z"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Y29RLDB7af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import numba\n",
        "\n",
        "#@numba.jit\n",
        "#def obtainC(nlevels, nparams, interceptIndicator):\n",
        "  \n",
        "  # Columns per factor\n",
        "  # This array tells us how many columns each factor has in Z.\n",
        "  # i.e. colsPerFactor[k]=4 means the kth factor has 4 columns\n",
        "#  colsPerFactor = nlevels*nparams\n",
        "  \n",
        "  # List of first column of Z for each level of each factor (If an intercept has\n",
        "  # been included for factor k, then it is assumed that the intercept is in the \n",
        "  # first column of each level of factor k; therefore this list contains all \n",
        "  # intercept column indices by assumption). One additional entry is included at \n",
        "  # the end which is the number of columns in z; this can be useful looping.\n",
        "#  interceptCols = np.insert(np.cumsum(np.repeat(nparams, nlevels)),0,0)\n",
        "\n",
        "  # The below array marks the first entry for each factor in interceptCols\n",
        "  # i.e. interceptCols[factorChangepoints[k]] is the first intercept for\n",
        "  # factor k\n",
        "#  factorChangepoints = np.insert(np.cumsum(nlevels),0,0)\n",
        "\n",
        "  # Loop through each factor\n",
        "#  for k in np.arange(len(nlevels)):\n",
        "  \n",
        "    # If we have an intercept for this factor work out which\n",
        "    # columns hold the intercepts\n",
        "#    if interceptIndicator[k]==1:\n",
        "      \n",
        "      # Get the intercept columns for factor k\n",
        "#      interceptCols_k = interceptCols[factorChangepoints[k]:factorChangepoints[k+1]]-interceptCols[factorChangepoints[k]]\n",
        "      \n",
        "      # Get a vector with -1 in each position for all intercept columns\n",
        "#      negativeCols = np.zeros(colsPerFactor[k])\n",
        "#      negativeCols[interceptCols_k] = -1\n",
        "      \n",
        "      # Get an identity matrix which is number of columns for factor k by number\n",
        "      # of columns for factor k in size. This will become c for factor k\n",
        "#      c_k = np.eye(colsPerFactor[k])\n",
        "      \n",
        "      # This is the index of the column we are removing from Z with this transform\n",
        "#      toRemove = interceptCols_k[-1]\n",
        "      \n",
        "      # Place the negative Cols matrix in the row corresponding to the intercept \n",
        "      # column\n",
        "#      c_k[toRemove,:] = negativeCols\n",
        "#      c_k = np.delete(c_k,toRemove,axis=1)\n",
        "      \n",
        "#      if k == 0:\n",
        "        \n",
        "#        c = c_k\n",
        "        \n",
        "#      else:\n",
        "        \n",
        "#        c = scipy.linalg.block_diag(c, c_k)\n",
        "      \n",
        "#  imshow(c, \\\n",
        "#     interpolation='nearest', aspect='auto',vmax=2,vmin=-1)\n",
        "#  plt.colorbar()\n",
        "\n",
        "#  return(c)\n",
        "\n",
        "#t1 = time.time()\n",
        "#c=obtainC(nlevels, nparams, [1,1])      \n",
        "#t2 = time.time()\n",
        "#print(t2-t1)\n",
        "\n",
        "#t1 = time.time()\n",
        "#obtainC(nlevels, nparams, [1,1])      \n",
        "#t2 = time.time()\n",
        "#print(t2-t1)\n",
        "\n",
        "\n",
        "#print(np.cumsum(nlevels * nparams))\n",
        "\n",
        "#nparams = [2,2]\n",
        "#nparamstmp[1] = 3\n",
        "\n",
        "# List of columns of Z containing intercept\n",
        "#interceptCols = np.insert(np.cumsum(np.repeat(nparams, nlevels)),0,0)[:-1]\n",
        "\n",
        "# The below array marks the first entry for each factor in interceptCols\n",
        "# i.e. interceptCols[factorChangepoints[k]] is the first intercept for\n",
        "# factor k\n",
        "#factorChangepoints = np.insert(np.cumsum(nlevels),0,0)\n",
        "#print('factor change points')\n",
        "#print(factorChangepoints)\n",
        "\n",
        "# Columns per factor\n",
        "# This array tells us how many columns each factor has in Z.\n",
        "# i.e. colsPerFactor[k]=4 means the kth factor has 4 columns\n",
        "#colsPerFactor = nlevels*nparams\n",
        "#print('colsPerFactor')\n",
        "#print(colsPerFactor)\n",
        "\n",
        "#k = 0\n",
        "# Intercept columns for one factor\n",
        "#print(interceptCols[factorChangepoints[k]:factorChangepoints[k+1]])\n",
        "\n",
        "#print(interceptCols)\n",
        "#print(len(interceptCols))\n",
        "\n",
        "#print(Z[:, interceptCols].toarray())\n",
        "\n",
        "#print(np.cumsum(nlevels))\n",
        "\n",
        "#print(nparams)\n",
        "      \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_chXrSrlWjra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#imshow((Z @ scipy.sparse.csr_matrix(c)).toarray(), \\\n",
        "#     interpolation='nearest', aspect='auto', vmax = 2, vmin = -1)\n",
        "#plt.colorbar()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfRwOu46X44A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#imshow(((Z @ scipy.sparse.csr_matrix(c)).transpose() @ (Z @ scipy.sparse.csr_matrix(c))).toarray(), \\\n",
        "#     interpolation='nearest', aspect='auto', vmax = 2, vmin = -1)\n",
        "#plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9umWv0H7XGAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imshow((Z).toarray(), \\\n",
        "#     interpolation='nearest', aspect='auto', vmax = 2, vmin = -1)\n",
        "#plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBtxdq-gXtI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imshow((Z.transpose() @ Z).toarray(), \\\n",
        "#     interpolation='nearest', aspect='auto')\n",
        "#plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENn5FJVkU2ie",
        "colab_type": "text"
      },
      "source": [
        "#### Demean and rescale Z"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RivNVCyU21E",
        "colab_type": "code",
        "outputId": "5b84698f-7d61-4142-f497-bdde9687a641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def demeanAndRescaleZ(Z, nparams, nlevels):\n",
        "  \n",
        "  # List of columns of Z containing intercept, assume if there is an intercept;\n",
        "  # that it is in the first column of each level of each factor\n",
        "  interceptCols = np.insert(np.cumsum(np.repeat(nparams, nlevels)),0,0)[:-1]\n",
        "  \n",
        "  # Make demeaned and rescaled Z\n",
        "  Z_dr = Z\n",
        "  \n",
        "  # Loop through each column\n",
        "  for i in np.arange(Z.shape[1]):\n",
        "    \n",
        "    # Check if column is an intercept\n",
        "    if i in interceptCols:\n",
        "      \n",
        "      # If the array doesn't contain only zero and one\n",
        "      if not np.array_equal(np.unique(Z[:,i]), np.array([0,1])):\n",
        "        \n",
        "        Z_dr[np.nonzero(Z_dr[:,i]),i] = (Z_dr[np.nonzero(Z_dr[:,i]),i]-np.mean(Z_dr[np.nonzero(Z_dr[:,i]),i]))/np.std(Z_dr[np.nonzero(Z_dr[:,i]),i])\n",
        "                                         \n",
        "    else:\n",
        "      \n",
        "      Z_dr[np.nonzero(Z_dr[:,i]),i] = (Z_dr[np.nonzero(Z_dr[:,i]),i]-np.mean(Z_dr[np.nonzero(Z_dr[:,i]),i]))/np.std(Z_dr[np.nonzero(Z_dr[:,i]),i])\n",
        "        \n",
        "  return(Z_dr)\n",
        "nlevels = np.array([20,3])#])#\n",
        "nparams = np.array([2,2])#])#\n",
        "Z_dr = demeanAndRescaleZ(Z.toarray(), nparams, nlevels)\n",
        "\n",
        "imshow(Z_dr, \\\n",
        "     interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f8edffbfa58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAD8CAYAAACvm7WEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzweedO6Yw09",
        "colab_type": "code",
        "outputId": "7867c2c6-075b-4f33-bfe3-37cbbf44f33e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imshow(Z.toarray(), \\\n",
        "     interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()\n",
        "\n",
        "#Z_orig = Z.toarray()\n",
        "#Z = scipy.sparse.csr_matrix(Z_dr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f8edfef9198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD8CAYAAACxUoU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nESkBhbWISAkorEVESkBhLSJSAv8fy0d/LOaOFc8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkd2LdwKLWtP",
        "colab_type": "text"
      },
      "source": [
        "### Estimated Random Effects matrix\n",
        "\n",
        "The below reads in the Random effects variance predicted by `R`'s `lmer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOqQRAROqdkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in estimated variance\n",
        "RFXVar_REst = pd.read_csv('/Data/BLMM-testdata/estd_rfxvar.csv',header=None).values#pd.read_csv('/Data/BLMM-testdata/estd_rfxvar_1factor.csv',header=None).values#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RStOLwF_LlTE",
        "colab_type": "text"
      },
      "source": [
        "### Y vector\n",
        "\n",
        "The response vector is read in here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG8eWNdpPQOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=pd.read_csv('/Data/BLMM-testdata/Y.csv',header=None).values#pd.read_csv('/Data/BLMM-testdata/Y_1factor.csv',header=None).values#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHm6DjdbPTvg",
        "colab_type": "text"
      },
      "source": [
        "### X matrix\n",
        "\n",
        "The fixed effects design matrix is read in here. It consists of an intercept and two random (Gaussian) columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqTKH4n_Po8e",
        "colab_type": "code",
        "outputId": "dccb0e9f-8da3-436a-b0c4-193b77e889c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X=pd.read_csv('/Data/BLMM-testdata/X.csv',header=None).values#pd.read_csv('/Data/BLMM-testdata/X_1factor.csv',header=None).values#\n",
        "\n",
        "# Image of the first 20 rows of X\n",
        "imshow(X[1:20,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8edfe619e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFYAAAD4CAYAAAB2QBFpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niRDrRIh1IsQ6EWKdCLFO/A/Tno1q3pV2hwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_sXGD8qzskp",
        "colab_type": "text"
      },
      "source": [
        "### Number of Levels and Parameters\n",
        "\n",
        "The number of levels is given by a vector with one entry for each grouping factor. e.g. nlevels=[10,2] means there are 10 levels for factor 1 and 2 levels for factor 2. \n",
        "\n",
        "The number of parameters is given by a vector with one entry for each grouping factor. e.g. nparams=[3,4] means there are 3 variables for factor 1 and 4 variables for factor 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e5bUA2DztCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlevels = np.array([20,3])#])#\n",
        "nparams = np.array([2,2])#])#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0byKXygpCa1P",
        "colab_type": "text"
      },
      "source": [
        "### True b values\n",
        "\n",
        "The true recorded values of the random effects b vector in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzwuuWSdCbCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_True=pd.read_csv('/Data/BLMM-testdata/true_b.csv',header=None).values#pd.read_csv('/Data/BLMM-testdata/true_b_1factor.csv',header=None).values#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvfns6c-CbPd",
        "colab_type": "text"
      },
      "source": [
        "### True beta values\n",
        "\n",
        "The true fixed effects parameters used to generate this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlvolWwvCbbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_True=pd.read_csv('/Data/BLMM-testdata/true_beta.csv',header=None).values#pd.read_csv('/Data/BLMM-testdata/true_beta_1factor.csv',header=None).values#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVyBWvQK2Gw5",
        "colab_type": "text"
      },
      "source": [
        "### Product Matrices\n",
        "\n",
        "All products of matrices are calculated beforehand as it is both more computationally efficient and also similar to the setting we are interested in. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e53HYCsj2G7I",
        "colab_type": "code",
        "outputId": "d199bdc0-d054-4175-f2f7-c8b8ef8b9c4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Z transpose Z\n",
        "print(Z.shape)\n",
        "ZtZ = np.matmul(Z.toarray().transpose(),Z.toarray()) # This works for products involving sparse\n",
        "# Sparse \n",
        "# ZtZ = Z.transpose() * Z\n",
        "\n",
        "# Z transpose X\n",
        "XtZ = np.matmul(X.transpose(),Z.toarray())\n",
        "\n",
        "# X transpose Z\n",
        "ZtX = np.matmul(Z.toarray().transpose(),X)\n",
        "\n",
        "# ZtY\n",
        "ZtY = np.matmul(Z.toarray().transpose(),Y)\n",
        "\n",
        "# YtZ\n",
        "YtZ = np.matmul(Y.transpose(),Z.toarray())\n",
        "\n",
        "# XtX\n",
        "XtX = np.matmul(X.transpose(),X)\n",
        "\n",
        "# XtY\n",
        "XtY = np.matmul(X.transpose(),Y)\n",
        "\n",
        "# YtX\n",
        "YtX = np.matmul(Y.transpose(),X)\n",
        "\n",
        "# YtX\n",
        "YtY = np.matmul(Y.transpose(),Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilAB3qmDMHa8",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "This section contains miscellaneous functions used to help the `FS` function including functions to work out the duplication matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVkJVMSo1fCF",
        "colab_type": "text"
      },
      "source": [
        "###Matrix to Vector function\n",
        "\n",
        "This function takes in a matrix and vectorizes it (i.e. transforms it to a vector of each of the columns of the matrix stacked on top of one another). Example:\n",
        "\n",
        "$$\\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\\\\\end{bmatrix} \\rightarrow \\begin{bmatrix} a \\\\ d \\\\ g \\\\ b \\\\ e \\\\ h \\\\ c \\\\ f \\\\ i \\end{bmatrix}$$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBhQXRF01d9n",
        "colab_type": "code",
        "outputId": "59102d92-dc6c-4e25-cb77-348b88f47814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def mat2vec(matrix):\n",
        "  \n",
        "  #Return vectorised matrix\n",
        "  return(matrix.transpose().reshape(matrix.shape[0]*matrix.shape[1],1))\n",
        "\n",
        "# Example:\n",
        "matrix = np.random.randn(3,3)\n",
        "print(matrix)\n",
        "print(mat2vec(matrix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.24743997 -0.44658289  1.14229487]\n",
            " [ 0.16295752  0.13361416  0.4584038 ]\n",
            " [-0.35327204  0.14878323 -2.72201285]]\n",
            "[[-0.24743997]\n",
            " [ 0.16295752]\n",
            " [-0.35327204]\n",
            " [-0.44658289]\n",
            " [ 0.13361416]\n",
            " [ 0.14878323]\n",
            " [ 1.14229487]\n",
            " [ 0.4584038 ]\n",
            " [-2.72201285]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcIJAyHi1eTj",
        "colab_type": "text"
      },
      "source": [
        "###Matrix to Vector function\n",
        "\n",
        "This function takes in a (symmetric, square) matrix and half-vectorizes it (i.e. transforms it to a vector of each of the columns of the matrix, below and including the diagonal, stacked on top of one another). Example:\n",
        "\n",
        "$$\\begin{bmatrix} a & b & c \\\\ b & d & e \\\\ c & e & f \\\\\\end{bmatrix} \\rightarrow \\begin{bmatrix} a \\\\ b \\\\ c \\\\ d \\\\ e \\\\ f \\end{bmatrix}$$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fpQzdwA3QGq",
        "colab_type": "code",
        "outputId": "49b1d095-83e3-40ef-9f62-da1ac422e105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def mat2vech(matrix):\n",
        "  \n",
        "  # Get lower triangular indices\n",
        "  rowinds, colinds = np.tril_indices(matrix.shape[0]) #Try mat.transpose()[trilu]?\n",
        "  \n",
        "  # They're in the wrong order so we need to order them\n",
        "  # To do this we first hash them\n",
        "  indhash = colinds*matrix.shape[0]+rowinds\n",
        "  \n",
        "  # Sort permutation\n",
        "  perm=np.argsort(indhash)\n",
        "  \n",
        "  # Return vectorised half-matrix\n",
        "  return(np.array([matrix[rowinds[perm],colinds[perm]]]).transpose())\n",
        "\n",
        "# Example:\n",
        "matrix = np.random.randn(3,3)\n",
        "print(matrix*matrix.transpose())\n",
        "print(mat2vech(matrix*matrix.transpose()))\n",
        "\n",
        "#print(vech2mat(invDupMat(3) @ mat2vec(matrix*matrix.transpose())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5.68884519  0.05285794  1.24727827]\n",
            " [ 0.05285794  0.88935512 -0.06957667]\n",
            " [ 1.24727827 -0.06957667  0.044964  ]]\n",
            "[[ 5.68884519]\n",
            " [ 0.05285794]\n",
            " [ 1.24727827]\n",
            " [ 0.88935512]\n",
            " [-0.06957667]\n",
            " [ 0.044964  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V79rfwHp9eNe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DmbjUOh9euy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec2mat(vec):\n",
        "  \n",
        "  # Return matrix\n",
        "  return(vec.reshape(np.int64(np.sqrt(vec.shape[0])),np.int64(np.sqrt(vec.shape[0]))).transpose())\n",
        "\n",
        "# Example\n",
        "#vec = np.array([[1,2,3,4]]).transpose()\n",
        "#mat = vec2mat(vec)\n",
        "#print(vec)\n",
        "#print(mat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijBvOZsu9iKg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhitZciM9hcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vech2mat(vech):\n",
        "  \n",
        "  # dimension of matrix\n",
        "  n = np.int64((-1+np.sqrt(1+8*vech.shape[0]))/2)\n",
        "  matrix = np.zeros((n,n))\n",
        "  \n",
        "  # Get lower triangular indices\n",
        "  rowinds, colinds = np.tril_indices(matrix.shape[0])\n",
        "  \n",
        "  # They're in the wrong order so we need to order them\n",
        "  # To do this we first hash them\n",
        "  indhash = colinds*matrix.shape[0]+rowinds\n",
        "  \n",
        "  # Sort permutation\n",
        "  perm=np.argsort(indhash)\n",
        "  \n",
        "  # Assign values to lower half\n",
        "  matrix[rowinds[perm],colinds[perm]] = vech.reshape(vech.shape[0])\n",
        "  \n",
        "  # Assign values to upper half\n",
        "  matrix[colinds[perm],rowinds[perm]] = vech.reshape(vech.shape[0])\n",
        "  \n",
        "  # Return vectorised half-matrix\n",
        "  return(matrix)\n",
        "\n",
        "# Example:\n",
        "#vech = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]])\n",
        "#matrix = vech2mat(vech)\n",
        "#print(vech)\n",
        "#print(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd3_jaDe-MNy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qutTs-8S-MuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec2vech(vec):\n",
        "  \n",
        "  # Return vech\n",
        "  return(mat2vech(vec2mat(vec)))\n",
        "\n",
        "# Example\n",
        "#vec = np.array([[1],[2],[3],[2],[4],[5],[3],[5],[6]])\n",
        "#vech = vec2vech(vec)\n",
        "\n",
        "#print(vec)\n",
        "#print(vech)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Yp9RjT-PmL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8txTVtu-Pwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vech2vec(vech):\n",
        "  \n",
        "  # Return vec\n",
        "  return(mat2vec(vech2mat(vech)))\n",
        "\n",
        "# Example\n",
        "#vech = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]])\n",
        "#vec = vech2vec(vech)\n",
        "\n",
        "#print(vech)\n",
        "#print(vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG22u6mq9mQT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PD6f9bD9mgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dupMat(n):\n",
        "  \n",
        "  # Make vech of 1:(n(n+1)/2)\n",
        "  vech = np.arange(n*(n+1)/2)\n",
        "  \n",
        "  # Convert to vec\n",
        "  vec = vech2vec(vech)\n",
        "  \n",
        "  # Make D (sparse one hot encoded vec)\n",
        "  D = scipy.sparse.csr_matrix((np.ones(n**2),(np.arange(n**2),np.int64(vec).reshape(vec.shape[0]))))\n",
        "  \n",
        "  return(D)\n",
        "\n",
        "# Example\n",
        "#print(dupMat(3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVrM3CsGSIHL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FR-cwIkSIQJ",
        "colab_type": "code",
        "outputId": "8ba9aee0-3050-4613-fdee-e4b55b0cf598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def invDupMat(n):\n",
        "  \n",
        "  \n",
        "  # Make vech of 1:(n(n+1)/2)\n",
        "  vech = np.arange(n*(n+1)/2)\n",
        "  \n",
        "  # Convert to vec\n",
        "  vec = np.int64(vech2vec(vech))\n",
        "  vec = vec.reshape(vec.shape[0])\n",
        "  \n",
        "  # Work out frequency of each entry\n",
        "  freq = 1/np.bincount(vec)\n",
        "  \n",
        "  # Work out duplication matrix\n",
        "  D = scipy.sparse.csr_matrix((freq[vec],(vec,np.arange(n**2))))\n",
        "  \n",
        "  return(D)\n",
        "\n",
        "import scipy.sparse\n",
        "# Example\n",
        "print(invDupMat(3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 0)\t1.0\n",
            "  (1, 1)\t0.5\n",
            "  (1, 3)\t0.5\n",
            "  (2, 2)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (3, 4)\t1.0\n",
            "  (4, 5)\t0.5\n",
            "  (4, 7)\t0.5\n",
            "  (5, 8)\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiPsThtWbwJS",
        "colab_type": "text"
      },
      "source": [
        "#### Commutation matrix\n",
        "\n",
        "----\n",
        "This function takes as input;\n",
        "\n",
        "----\n",
        " - $a$: A postive integer.\n",
        " - $b$: A postive integer.\n",
        "\n",
        "----\n",
        "And returns:\n",
        "\n",
        "----\n",
        " - $K$: The commutation matrix (in sparse format) which maps $vec(A)$ to $vec(A')$ for an arbitrary matrix $A$ of dimensions $(a \\times b)$, i.e. $K$ is the unique matrix which satisfies, for all $A$;\n",
        "\n",
        " $$K vec(A) = vec(A')$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3HR-zVobwee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def comMat2D(a, b):\n",
        "#\n",
        "#  # Example matrix with unique elements\n",
        "#  m = np.arange(a*b).reshape(a,b)\n",
        "#\n",
        "#  # Vec(m) and Vec(m')\n",
        "#  vecm = mat2vec(m)\n",
        "#  vecmt = mat2vec(m.transpose())\n",
        "#\n",
        "#  # Work out mapping between them.\n",
        "#  K=scipy.sparse.csr_matrix((vecm.transpose()==vecmt).astype(int))\n",
        "#\n",
        "#  return(K)\n",
        "\n",
        "def comMat2D(a, b):\n",
        "\n",
        "  # Get row indices\n",
        "  row  = np.arange(a*b)\n",
        "\n",
        "  # Get column indices\n",
        "  col  = row.reshape((a, b), order='F').ravel()\n",
        "\n",
        "  # Ones to put in the matrix\n",
        "  data = np.ones(a*b, dtype=np.int8)\n",
        "\n",
        "  # Sparse it\n",
        "  K = scipy.sparse.csr_matrix((data, (row, col)), shape=(a*b, a*b))\n",
        "  \n",
        "  # Return K\n",
        "  return(K)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbUAVObBcki5",
        "colab_type": "text"
      },
      "source": [
        "The below code tests and times ``comMat2D``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfcMJM3ecOHl",
        "colab_type": "code",
        "outputId": "ed632f67-26b2-4c0e-af08-f3e0c1c9f4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Random dimensions\n",
        "a = np.random.randint(100,500)\n",
        "b = np.random.randint(100,500)\n",
        "\n",
        "# Get K\n",
        "t1 = time.time()\n",
        "K = comMat2D(a,b)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "# Random A\n",
        "A = np.random.randn(a,b)\n",
        "\n",
        "print(np.allclose(mat2vec(A.transpose()),K @ mat2vec(A)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0019652843475341797\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA-MNCZb-ew-",
        "colab_type": "text"
      },
      "source": [
        "#### Permutation of I kron K kron I\n",
        "\n",
        "The below function takes as inputs:\n",
        " \n",
        " ----\n",
        " - $k_1$: A positive integer.\n",
        " - $k_2$: A positive integer.\n",
        " - $n_1$: A positive integer.\n",
        " - $n_2$: A positive integer.\n",
        "\n",
        " \n",
        " ----\n",
        "\n",
        "And returns the permutation vector $p$ such that for any matrix $A$ of appropriate dimensions.\n",
        "\n",
        "$(I_{k_1} \\otimes K_{n_1,k_2} \\otimes I_{n_2})A=A_p$\n",
        "\n",
        "Where $A_p$ is the matrix $A$ with $p$ applied to it's rows and $K_{n_1,k_2}$ is the $(n_1,k_2)$, commutation matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMel4jN_-e-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def permOfIkKkI(k1,k2,n1,n2):\n",
        "\n",
        "  # First we need the permutation represented by matrix K in vector format\n",
        "  permP = np.arange(n1*k2).reshape((n1, k2), order='F').ravel()\n",
        "\n",
        "  # Now we work out the permutation obtained by the first kronecker product (i.e. I kron K)\n",
        "  permKron1 = np.repeat(np.arange(k1),n1*k2)*n1*k2+np.tile(permP,k1)\n",
        "\n",
        "  # Now we work out the final permutation by appplying the second kronecker product (i.e. I kron K kron I)\n",
        "  p = np.repeat(permKron1,n2)*n2+np.tile(np.arange(n2),n1*k1*k2)\n",
        "\n",
        "  # Return the permutation\n",
        "  return(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLlfPcOa_Np5",
        "colab_type": "text"
      },
      "source": [
        "The below code tests and times the above function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlvUzHC2_L6A",
        "colab_type": "code",
        "outputId": "26fcb31c-d874-4654-f925-1ca967504dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "m = np.random.randint(1,10)\n",
        "n1=np.random.randint(1,10)\n",
        "n2=np.random.randint(1,10)\n",
        "k1=np.random.randint(1,10)\n",
        "k2=np.random.randint(1,10)\n",
        "\n",
        "print('Example Shapes:')\n",
        "print('m: ', m)\n",
        "print('k1, k2: ', k1, k2)\n",
        "print('n1, n2: ', n1, n2)\n",
        "\n",
        "testMat = np.random.randn(k1*k2*n1*n2,m)\n",
        "\n",
        "t1 = time.time()\n",
        "K = comMat2D(n1, k2).toarray()\n",
        "\n",
        "print(K.shape)\n",
        "IPI = np.kron(np.kron(np.eye(k1), K), np.eye(n2))\n",
        "print(IPI)\n",
        "print(IPI.shape)\n",
        "print(testMat.shape)\n",
        "result1 = IPI @ testMat\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "perm = permOfIkKkI(k1,k2,n1,n2)\n",
        "result2 = testMat[perm,:]\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "print(np.allclose(result1,result2))\n",
        "print(K.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example Shapes:\n",
            "m:  9\n",
            "k1, k2:  7 3\n",
            "n1, n2:  7 3\n",
            "(21, 21)\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "(441, 441)\n",
            "(441, 9)\n",
            "0.0072536468505859375\n",
            "0.0004546642303466797\n",
            "True\n",
            "(21, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qndbOyXjfZWY",
        "colab_type": "text"
      },
      "source": [
        "#### Convert blocked matrix to stacked matrix\n",
        "\n",
        "----\n",
        "This function takes as inputs:\n",
        "\n",
        "----\n",
        " - `A`: A 2D matrix of size $(m_1 \\times m_2)$.\n",
        " - `pA`: The size of the block partitions of $A$, e.g. if $A_{i,j}$ is of dimension $(n_1 \\times n_2)$ then ``pA=[n1, n2]``.\n",
        "\n",
        "----\n",
        "And returns as output:\n",
        "\n",
        "----\n",
        " - `As`: The matrix $A$ reshaped to have all blocks $A_{i,j}$ on top of one another. I.e. the below mapping has been performed:\n",
        "\n",
        "$$A = \\begin{bmatrix} A_{1,1} & A_{1,2} & ... & A_{1,l_2} \\\\ A_{2,1} & A_{2,2} & ... & A_{2,l_2} \\\\ \\vdots \\\\ A_{l_1,1} & A_{l_1,2} & ... & A_{l_1,l_2} \\end{bmatrix} \\rightarrow A_s = \\begin{bmatrix} A_{1,1} \\\\ A_{1,2} \\\\ \\vdots \\\\ A_{1,l_2} \\\\ A_{2,1} \\\\ \\vdots \\\\ A_{l_1,l_2} \\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu6a_dOufZly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def block2stacked2D(A, pA):\n",
        "\n",
        "  # Work out shape of A\n",
        "  m1 = A.shape[0]\n",
        "  m2 = A.shape[1]\n",
        "\n",
        "  # Work out shape of As\n",
        "  n1 = pA[0]\n",
        "  n2 = pA[1]\n",
        "  \n",
        "  # Change A to stacked form\n",
        "  As = A.reshape((m1//n1,n1,m2//n2,n2)).transpose(0,2,1,3).reshape(m1*m2//n2,n2)\n",
        "\n",
        "  return(As)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPt_DYxmf2B6",
        "colab_type": "text"
      },
      "source": [
        "Below is a demonstration/test of this function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXZUJB_ef2P7",
        "colab_type": "code",
        "outputId": "7fdca7d2-68c8-4d36-ca79-a5f1bf16e96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Random block sizes\n",
        "n1 = np.random.randint(2,6)\n",
        "n2 = np.random.randint(2,6)\n",
        "pA = np.array([n1,n2])\n",
        "\n",
        "# Random number of blocks\n",
        "l1 = np.random.randint(1,3)\n",
        "l2 = np.random.randint(1,3)\n",
        "\n",
        "# Shape of A\n",
        "m1 = l1*n1\n",
        "m2 = l2*n2\n",
        "\n",
        "# Create A\n",
        "A = np.random.randn(m1,m2)\n",
        "print(n1,n2,m1,m2)\n",
        "print(A.shape)\n",
        "# Print A\n",
        "print(A)\n",
        "print(block2stacked2D(A,pA))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 4 3 4\n",
            "(3, 4)\n",
            "[[ 2.21542127 -0.52650135 -0.03271491 -0.72991395]\n",
            " [ 0.50035739  1.49795226 -0.60384647  0.94698649]\n",
            " [ 1.83891815  1.03529662 -0.21601111  0.30875488]]\n",
            "[[ 2.21542127 -0.52650135 -0.03271491 -0.72991395]\n",
            " [ 0.50035739  1.49795226 -0.60384647  0.94698649]\n",
            " [ 1.83891815  1.03529662 -0.21601111  0.30875488]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yee09PD0gITc",
        "colab_type": "text"
      },
      "source": [
        "#### Convert blocked matrix to a stacked vector matrix\n",
        "\n",
        "The below function takes the following inputs:\n",
        "\n",
        "----\n",
        " - `mat`: An abritary matrix whose dimensions are multiples of `p[0]` and `p[1]` respectively.\n",
        " - `p`. The size of the chunks we are partitioning `mat` into.\n",
        "\n",
        "----\n",
        "And gives the following outputs:\n",
        "\n",
        "----\n",
        " - `vecb`: A matrix composed of each block of `mat`, converted to row vectors, stacked on top of one another. I.e. for an arbitrary matrix $A$ of appropriate dimensions, $vecb(A)$ is the result of the mapping;\n",
        "\n",
        " \n",
        "$$A = \\begin{bmatrix} A_{1,1} & A_{1,2} & ... & A_{1,l_2} \\\\ A_{2,1} & A_{2,2} & ... & A_{2,l_2} \\\\ \\vdots \\\\ A_{l_1,1} & A_{l_1,2} & ... & A_{l_1,l_2} \\end{bmatrix} \\rightarrow \\tilde{a} = \\begin{bmatrix} vec'(A_{1,1}) \\\\ vec'(A_{1,2}) \\\\ \\vdots \\\\ vec'(A_{1,l_2}) \\\\ vec'(A_{2,1}) \\\\ \\vdots \\\\ vec'(A_{l_1,l_2}) \\end{bmatrix}$$\n",
        "\n",
        "Where $A_{i,j}$ has dimensions $($ `p[0]` $\\times$ `p[1]` $)$ for all $i$ and $j$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlatzaAZgIhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Block vec with row-wise chunks of size n\n",
        "def mat2vecb2D(mat,p):\n",
        "\n",
        "  # Change to stacked block format, if necessary\n",
        "  if p[1]!=mat.shape[1]:\n",
        "    mat = block2stacked2D(mat,p)\n",
        "\n",
        "  # Get height of block.\n",
        "  n = p[0]\n",
        "  \n",
        "  # Work out shape of matrix.\n",
        "  m = mat.shape[0]\n",
        "  k = mat.shape[1]\n",
        "\n",
        "  # Convert to stacked vector format\n",
        "  vecb = mat.reshape(m//n, n, k).transpose((1, 0, 2)).reshape(n, m*k//n).transpose().reshape(m//n,n*k)\n",
        "\n",
        "  #Return vecb\n",
        "  return(vecb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jP4HbatgbEs",
        "colab_type": "text"
      },
      "source": [
        "The below code tests and outputs the above function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zaef1TcgbU8",
        "colab_type": "code",
        "outputId": "d9596fe5-fb83-4c75-e5e8-c0807364bcea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Random block sizes\n",
        "n1 = np.random.randint(2,4)\n",
        "n2 = np.random.randint(2,4)\n",
        "\n",
        "# Blocksize\n",
        "p = np.array([n1,n2])\n",
        "\n",
        "# Random number of blocks\n",
        "l1 = np.random.randint(2,4)\n",
        "l2 = np.random.randint(2,4)\n",
        "\n",
        "# Resultant matrix sizes\n",
        "m1 = l1*n1\n",
        "m2 = l2*n2\n",
        "\n",
        "# Random matrices\n",
        "A = np.random.randn(m1,m2)\n",
        "\n",
        "print(A)\n",
        "print(mat2vecb2D(A,p))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.59471889 -0.16395385 -2.96685959  0.38299481  1.41426412  0.77254921]\n",
            " [-0.22682522  1.19420201  1.4842787  -0.26310432  0.09563809  2.41971959]\n",
            " [-0.12669333 -0.42498082 -1.49403867  0.18342952 -0.1933991  -1.22022735]\n",
            " [-0.18524884 -0.99999577 -0.64308299  0.66144199 -1.30490375  1.63828227]\n",
            " [ 1.12973749 -1.24105313 -0.63562492 -0.53397306 -0.28808039 -0.23097332]\n",
            " [-0.1040141  -0.39748972 -0.27735959 -1.20313122 -1.94984221 -0.1960168 ]]\n",
            "[[-2.59471889 -0.22682522 -0.16395385  1.19420201]\n",
            " [-2.96685959  1.4842787   0.38299481 -0.26310432]\n",
            " [ 1.41426412  0.09563809  0.77254921  2.41971959]\n",
            " [-0.12669333 -0.18524884 -0.42498082 -0.99999577]\n",
            " [-1.49403867 -0.64308299  0.18342952  0.66144199]\n",
            " [-0.1933991  -1.30490375 -1.22022735  1.63828227]\n",
            " [ 1.12973749 -0.1040141  -1.24105313 -0.39748972]\n",
            " [-0.63562492 -0.27735959 -0.53397306 -1.20313122]\n",
            " [-0.28808039 -1.94984221 -0.23097332 -0.1960168 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tex5_YDWeNj",
        "colab_type": "text"
      },
      "source": [
        "#### Sum of Aij multiplied by Bij transpose\n",
        "\n",
        "This function takes in the following inputs:\n",
        "\n",
        "----\n",
        " - A: A 2D matrix of dimension $(m_1 \\times m_2)$.\n",
        " - B: A 2D matrix of dimension $(m_1' \\times m_2)$.\n",
        " - pA: The size of the block partitions of $A$, e.g. if $A_{i,j}$ is of dimension $(n_1 \\times n_2)$ then ``pA=[n1, n2]``.\n",
        " - pB: The size of the block partitions of $B$, e.g. if $B_{i,j}$ is of dimension $(n_1' \\times n_2)$ then ``pB=[n1', n2]``.\n",
        "\n",
        "----\n",
        "And gives the following output:\n",
        "\n",
        "----\n",
        " - S: The sum of the partitions of $A$ multiplied by the transpose of the partitions of $B$; i.e. \n",
        " \n",
        " $$\\sum_{j=1}^{l_1}\\sum_{i=1}^{l_2} A_{i,j}B_{i,j}'$$\n",
        "  \n",
        "  where $l_1:=\\frac{m_1}{n_1}=\\frac{m_1'}{n_1'}$ and $l_2:=\\frac{m_2}{n_2}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz5mHm5EWecD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sumAijBijt2D(A, B, pA, pB):\n",
        "  \n",
        "  # Work out second (the common) dimension of the reshaped A and B\n",
        "  nA = pA[0]\n",
        "  nB = pB[0]\n",
        "\n",
        "  # Work out the first (the common) dimension of reshaped A and B\n",
        "  mA = A.shape[0]*A.shape[1]//nA\n",
        "  mB = B.shape[0]*B.shape[1]//nB\n",
        "\n",
        "  # Check mA equals mB\n",
        "  if mA != mB:\n",
        "    raise Exception('Matrix dimensions incompatible.')\n",
        "\n",
        "  # Convert both matrices to stacked block format.\n",
        "  A = block2stacked2D(A,pA)\n",
        "  B = block2stacked2D(B,pB)\n",
        "\n",
        "  # Work out the sum\n",
        "  S = A.transpose().reshape((mA,nA)).transpose() @ B.transpose().reshape((mB,nB))\n",
        "\n",
        "  # Return result\n",
        "  return(S)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNMIdLT3WeoL",
        "colab_type": "text"
      },
      "source": [
        "Below is a test of the function to check it is outputting as expected. It is also timed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiGQGtoqWewu",
        "colab_type": "code",
        "outputId": "c95de800-d8c2-42c0-a31f-6fc3364dac7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Random number of blocks\n",
        "l1 = np.random.randint(1,3000)\n",
        "l2 = np.random.randint(1,3000)\n",
        "\n",
        "# Random blocksizes (the second dimension must be the same for both)\n",
        "n1 = np.random.randint(1,5)\n",
        "n1prime = np.random.randint(1,5)\n",
        "n2 = np.random.randint(1,5)\n",
        "\n",
        "# Save block sizes\n",
        "pA = np.array([n1,n2])\n",
        "pB = np.array([n1prime,n2])\n",
        "\n",
        "m1 = n1*l1\n",
        "m1prime = n1prime*l1\n",
        "m2 = n2*l2\n",
        "\n",
        "k=100\n",
        "l1 = m1//n1\n",
        "l2 = m2//n2\n",
        "\n",
        "# Create A\n",
        "A = np.random.randn(m1,m2)\n",
        "B = np.random.randn(m1prime,m2)\n",
        "\n",
        "# Calculation by summing\n",
        "t1 = time.time()\n",
        "\n",
        "# Initiate empty sum\n",
        "sumAB = np.zeros((n1,n1prime))\n",
        "for i in np.arange(m1//n1):\n",
        "  \n",
        "  for j in np.arange(m2//n2):\n",
        "\n",
        "    # Work out the row-wise chunks\n",
        "    Aij = A[n1*i:n1*(i+1),n2*j:n2*(j+1)]\n",
        "    Bij = B[n1prime*i:n1prime*(i+1),n2*j:n2*(j+1)]\n",
        "\n",
        "    # Perform the summation\n",
        "    sumAB = sumAB + Aij @ Bij.transpose()\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "print('Time (Summing):', t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "sumAB2 = sumAijBijt2D(A, B, pA, pB)\n",
        "t2=time.time()\n",
        "print('Time (Function):', t2-t1)\n",
        "\n",
        "print(np.allclose(sumAB,sumAB2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (Summing): 6.279120683670044\n",
            "Time (Function): 0.17411351203918457\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4z6QhhmXbcB",
        "colab_type": "text"
      },
      "source": [
        "#### Sum of Aij kron Bij\n",
        "\n",
        "This function takes in the following inputs:\n",
        "\n",
        "----\n",
        " - `A`: A 2D matrix of dimension $(m_1 \\times m_2)$.\n",
        " - `B`: A 2D matrix of dimension $(m_1 \\times m_2)$.\n",
        " - `p`: The size of the block partitions of $A$ and $B$, e.g. if $A_{i,j}$ and$B_{i,j}$ are of dimension $(n_1 \\times n_2)$ then ``pA=[n1, n2]``.\n",
        " - `perm` (optional): The permutation vector representing the matrix kronecker product $I_{n_2} \\otimes K_{n_2,n_1} \\otimes I_{n_1}$.\n",
        "\n",
        "----\n",
        "\n",
        "And gives the following output:\n",
        "\n",
        "----\n",
        "\n",
        " - S: The sum of the partitions of $A$ multiplied by the transpose of the partitions of $B$; i.e. \n",
        " \n",
        " $$\\sum_{j=1}^{l_1}\\sum_{i=1}^{l_2} A_{i,j} \\otimes B_{i,j}$$\n",
        "  \n",
        "  where $l_1:=\\frac{m_1}{n_1}$ and $l_2:=\\frac{m_2}{n_2}$.\n",
        "\n",
        "- `perm`: The permutation (same as input) used for calculation (useful for later computation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfPAIAVVXbpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sumAijKronBij2D(A, B, p, perm=None):\n",
        "\n",
        "  # Check dim A and B and pA and pB all same\n",
        "  n1 = p[0]\n",
        "  n2 = p[1]\n",
        "\n",
        "  # This matrix only needs be calculated once\n",
        "  if perm is None:\n",
        "    perm = permOfIkKkI(n2,n1,n2,n1) \n",
        "\n",
        "  # Convert to vecb format\n",
        "  atilde = mat2vecb2D(A,p)\n",
        "  btilde = mat2vecb2D(B,p)\n",
        "\n",
        "  # Multiply and convert to vector\n",
        "  vecba = mat2vec(btilde.transpose() @ atilde)\n",
        "\n",
        "  # Permute\n",
        "  S_noreshape = vecba[perm,:] \n",
        "\n",
        "  # Reshape to correct shape\n",
        "  S = S_noreshape.reshape(n2**2,n1**2).transpose()\n",
        "\n",
        "  return(S,perm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2hu_74-Xb2u",
        "colab_type": "text"
      },
      "source": [
        "The below code tests and times the above function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdNtt19uXcD9",
        "colab_type": "code",
        "outputId": "7945ca49-83a0-49b4-b5f3-293cdc383acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Random block sizes\n",
        "n1 = np.random.randint(2,10)\n",
        "n2 = np.random.randint(2,10)\n",
        "\n",
        "# Blocksize\n",
        "p = np.array([n1,n2])\n",
        "\n",
        "# Random number of blocks\n",
        "l1 = np.random.randint(2,30)\n",
        "l2 = np.random.randint(2,30)\n",
        "\n",
        "# Resultant matrix sizes\n",
        "m1 = l1*n1\n",
        "m2 = l2*n2\n",
        "\n",
        "# Random matrices\n",
        "A = np.random.randn(m1,m2)\n",
        "B = np.random.randn(m1,m2)\n",
        "\n",
        "# Sum version\n",
        "t1 = time.time()\n",
        "\n",
        "runningSum = np.zeros((n1**2,n2**2))\n",
        "# LHS calculation\n",
        "t1 = time.time()\n",
        "for i in np.arange(l1):\n",
        "  for j in np.arange(l2):\n",
        "\n",
        "    Aij = A[n1*i:n1*(i+1),n2*j:n2*(j+1)]\n",
        "    Bij = B[n1*i:n1*(i+1),n2*j:n2*(j+1)]\n",
        "\n",
        "    runningSum = runningSum + np.kron(Aij, Bij)\n",
        "\n",
        "t2 = time.time()\n",
        "print('Time (summing): ', t2-t1)\n",
        "\n",
        "# Now with function\n",
        "t1 = time.time()\n",
        "S, perm = sumAijKronBij2D(A, B, p)\n",
        "t2 = time.time()\n",
        "\n",
        "print('Time (function): ', t2-t1)\n",
        "print(np.allclose(S,runningSum))\n",
        "\n",
        "t1 = time.time()\n",
        "S, _ = sumAijKronBij2D(A, B, p, perm)\n",
        "t2 = time.time()\n",
        "\n",
        "print('Time (function, with perm): ', t2-t1)\n",
        "\n",
        "print(np.allclose(S,runningSum))\n",
        "#print(S)\n",
        "#print(runningSum)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (summing):  0.03720569610595703\n",
            "Time (function):  0.00376129150390625\n",
            "True\n",
            "Time (function, with perm):  0.0008482933044433594\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2byzJx5Kf5fS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFCU4gxkf5r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def blockInverse(matrix, blockSize, numBlocks):\n",
        "\n",
        "  invMatrix = scipy.sparse.csr_matrix((np.array([]), (np.array([]),np.array([]))),shape=matrix.shape)\n",
        "  \n",
        "  # For each level, invert the corresponding block on the diagonal\n",
        "  for i in range(numBlocks):\n",
        "    \n",
        "    # The block is nparams by nparams\n",
        "    blockInds = np.ix_(np.arange(i*blockSize,(i+1)*blockSize),np.arange(i*blockSize,(i+1)*blockSize))\n",
        "    \n",
        "    # Get the block\n",
        "    block = matrix[blockInds]\n",
        "    \n",
        "    # Replace it with it's inverse\n",
        "    invMatrix[blockInds]=scipy.sparse.linalg.inv(block)\n",
        "    \n",
        "  return(invMatrix)\n",
        "\n",
        "# Example - need to have loaded in data first\n",
        "\n",
        "# Get ZtZ just for the first grouping factor\n",
        "firstFactorIndices = np.ix_(np.arange(nlevels[0]*nparams[0]),np.arange(nlevels[0]*nparams[0]))\n",
        "ZtZ_f1 = ZtZ[firstFactorIndices]\n",
        "\n",
        "# Compute the block inverse for ZtZ_f1\n",
        "#t1 = time.time()\n",
        "#ZtZ_f1_inv = blockInverse(matrix=ZtZ_f1, blockSize=nparams[0], numBlocks=nlevels[0])\n",
        "#t2 = time.time()\n",
        "#blockInverse_time = t2-t1\n",
        "\n",
        "# Compare it to the inverse scipy would calculate\n",
        "#t1 = time.time()\n",
        "#ZtZ_f1_inv_sp = scipy.sparse.linalg.inv(ZtZ_f1)\n",
        "#t2 = time.time()\n",
        "#scipyInverse_time = t2-t1\n",
        "\n",
        "#print(blockInverse_time)\n",
        "#print(scipyInverse_time)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BdQ3jh7x71k",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77gBbWIAx8AZ",
        "colab_type": "code",
        "outputId": "6f32f964-ab0f-43f7-ad0b-07c03b66103b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def recursiveInverse(M, nparams, nlevels):\n",
        "  \n",
        "  # Check if we have a matrix we can partition into more than 1 block\n",
        "  if len(nparams) > 1:\n",
        "  \n",
        "    # Work out qc\n",
        "    qc = nparams[-1]*nlevels[-1]\n",
        "    # Make q\n",
        "    q = M.shape[0]\n",
        "\n",
        "    # Get A, B and C where M=[[A,B],[B',C]]\n",
        "    # A\n",
        "    A_inds = np.ix_(np.arange(0,(q-qc)),np.arange(0,(q-qc)))\n",
        "    A = M[A_inds]\n",
        "\n",
        "    # B\n",
        "    B_inds = np.ix_(np.arange(0,(q-qc)),np.arange((q-qc),q))\n",
        "    B = M[B_inds].toarray() # B is dense\n",
        "\n",
        "    # C\n",
        "    C_inds = np.ix_(np.arange((q-qc),q),np.arange((q-qc),q))\n",
        "    C = M[C_inds].toarray() # C is small and now only involved in dense mutliplys\n",
        "\n",
        "    # Recursive inverse A\n",
        "    if nparams[:-1].shape[0] > 1:\n",
        "\n",
        "      Ainv = recursiveInverse(A, nparams[:-1], nlevels[:-1]).toarray()\n",
        "\n",
        "    else:\n",
        "\n",
        "      #Ainv = blockInverse(A, nparams[0], nlevels[0]) - much slower\n",
        "      Ainv = scipy.sparse.linalg.inv(scipy.sparse.csc_matrix(A)).toarray()\n",
        "\n",
        "    # Schur complement\n",
        "    S = C-np.matmul(np.matmul(B.transpose(),Ainv),B)\n",
        "    Sinv = np.linalg.inv(S)\n",
        "\n",
        "    # Top Left Hand Side of inverse\n",
        "    TLHS = Ainv + np.matmul(np.matmul(np.matmul(np.matmul(Ainv,B),Sinv),B.transpose()),Ainv)\n",
        "\n",
        "\n",
        "    # Top Right Hand Side of inverse\n",
        "    TRHS = -np.matmul(np.matmul(Ainv,B),Sinv)\n",
        "\n",
        "\n",
        "    # Bottom Right Hand Side of inverse\n",
        "    BRHS = Sinv\n",
        "\n",
        "    # Join together\n",
        "    top = np.hstack((TLHS,TRHS))\n",
        "    bottom = np.hstack((TRHS.transpose(), BRHS))\n",
        "\n",
        "    # Make Minv\n",
        "    Minv = np.vstack((top, bottom))\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    # If we have only one block; invert it\n",
        "    Minv = scipy.sparse.linalg.inv(scipy.sparse.csc_matrix(M)).toarray() \n",
        "  \n",
        "  return(Minv)\n",
        "\n",
        "# Example\n",
        "t1 = time.time()\n",
        "ZtZinv_rec = recursiveInverse(scipy.sparse.csc_matrix(ZtZ), nparams, nlevels)\n",
        "t2 = time.time()\n",
        "inv_rec_time = t2-t1\n",
        "\n",
        "t1 = time.time()\n",
        "ZtZinv_sp = scipy.sparse.linalg.inv(scipy.sparse.csc_matrix(ZtZ))\n",
        "t2 = time.time()\n",
        "inv_sp_time = t2-t1\n",
        "\n",
        "t1 = time.time()\n",
        "ZtZinv_np = np.linalg.inv(ZtZ)\n",
        "t2 = time.time()\n",
        "inv_np_time = t2-t1\n",
        "\n",
        "\n",
        "print('Distance (norm) from identity (scipy)')\n",
        "print(np.linalg.norm(np.matmul(ZtZinv_sp.toarray(),ZtZ)-np.eye(ZtZ.shape[0])))\n",
        "print('Distance (norm) from identity (numpy)')\n",
        "print(np.linalg.norm(np.matmul(ZtZinv_np,ZtZ)-np.eye(ZtZ.shape[0])))\n",
        "print('Distance (norm) from identity (rec)')\n",
        "print(np.linalg.norm(np.matmul(ZtZinv_rec,ZtZ)-np.eye(ZtZ.shape[0])))\n",
        "\n",
        "print(inv_sp_time)\n",
        "print(inv_np_time)\n",
        "print(inv_rec_time)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance (norm) from identity (scipy)\n",
            "289.8902619901572\n",
            "Distance (norm) from identity (numpy)\n",
            "1955.403906774292\n",
            "Distance (norm) from identity (rec)\n",
            "381.4130003726553\n",
            "0.024462223052978516\n",
            "0.0003294944763183594\n",
            "0.03153562545776367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyCloufz0W3U",
        "colab_type": "text"
      },
      "source": [
        "#### Force symmetric\n",
        "\n",
        "The below function takes in a matrix $X$ and returns a symmetric matrix $X_s$ given by:\n",
        "\n",
        "$$X_s = (X+X^T)/2$$\n",
        "\n",
        "The effect of this is that if $X$ is expected to be symmetric but is not due to computational error, any antisymmetric errors will be resolved/reduced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR4xAjhO0W-f",
        "colab_type": "code",
        "outputId": "e10b7bbd-54e4-49b8-fc66-027f0c9c8f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numba\n",
        "@numba.jit\n",
        "def forceSym(x):\n",
        "  \n",
        "  # Force it to be symmetric\n",
        "  return((x+x.transpose())/2)\n",
        "\n",
        "#print(ZtZ-forceSym(ZtZ))\n",
        "\n",
        "t1 = time.time()\n",
        "ZtZ = forceSym(forceSym(ZtZ))\n",
        "print(time.time()-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "ZtZ = forceSym(forceSym(ZtZ))\n",
        "print(time.time()-t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.48226308822631836\n",
            "6.67572021484375e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPgPFpnOLxdG",
        "colab_type": "text"
      },
      "source": [
        "### Sum of square residuals\n",
        "\n",
        "The function below calculates the sum of the square residuals, $e^Te$, using the below formula:\n",
        "\n",
        "$$e^Te = (Y-X\\beta)^T(Y-X\\beta)$$ \n",
        "$$=Y^TY - 2Y^TX\\beta + \\beta^T X^TX \\beta$$\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `YtX`: $Y$ transpose multiplied by $X$ ($Y^TX$ in the above notation).\n",
        " - `YtY`: $Y$ transpose multiplied by $Y$ ($Y^TY$ in the above notation).\n",
        " - `XtX`: $X$ transpose multiplied by $X$ ($X^TX$ in the above notation).\n",
        " - `beta`: An estimate of the parameter vector ($\\beta$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        " - `ete`: The sum of square residuals ($e^Te$ in the above notation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK0i7TkgNNZD",
        "colab_type": "code",
        "outputId": "c1364f2b-4f1d-49dd-f7ee-312067a2a9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def ssr(YtX, YtY, XtX, beta):\n",
        "  \n",
        "  # Return the sum of squared residuals\n",
        "  return(YtY - 2*YtX @ beta + beta.transpose() @ XtX @ beta)\n",
        "\n",
        "t1 = time.time()\n",
        "ete = ssr(YtX, YtY, XtX, np.array([[1],[2],[3]]))\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00021457672119140625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JffLr-FTZ2Zs",
        "colab_type": "text"
      },
      "source": [
        "#### Get Factor Indices\n",
        "\n",
        "This function gives the indices of the columns of the $Z$ matrix which correspond to factor $k$ level $j$. \n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The grouping factor we need the columns of.\n",
        " - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - `nparams`: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `Ik`: The indices of the columns of $Z$ corresponding to factor $k$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJccybRtaFvS",
        "colab_type": "code",
        "outputId": "724a66cb-d80c-44fe-934a-6c6eb0989a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# k is zero indexed\n",
        "def fac_indices(k, nlevels, nparams):\n",
        "  \n",
        "  # Get indices for all factors\n",
        "  allInds = np.insert(np.cumsum(nlevels*nparams),0,0)\n",
        "\n",
        "  # Work out the first index\n",
        "  start = allInds[k]\n",
        "\n",
        "  # Work out the last index\n",
        "  end = allInds[k+1]\n",
        "\n",
        "  return(np.arange(start,end))\n",
        "\n",
        "t1 = time.time()\n",
        "print(fac_indices(0, nlevels, nparams))\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
            "0.0007023811340332031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO_68uYYxCvf",
        "colab_type": "text"
      },
      "source": [
        "#### Get Factor/Level Indices\n",
        "\n",
        "This function gives the indices of the columns of the $Z$ matrix which correspond to factor $k$ level $j$. \n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The grouping factor we need the columns of.\n",
        " - `j`: The level of the grouping factor $k$ which we are interested in.\n",
        " - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - `nparams`: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `Ikj`: The indices of the columns of $Z$ corresponding to factor $k$ level $j$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSrodNh0zI0_",
        "colab_type": "code",
        "outputId": "bbb952d3-57b6-4887-ef5a-2d4e1ec32cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit\n",
        "# k and j are both zero indexed\n",
        "def faclev_indices(k, j, nlevels, nparams):\n",
        "  \n",
        "  # Work out the starting point of the indices\n",
        "  start = np.concatenate((np.array([0]), np.cumsum(nlevels*nparams)))[k] + nparams[k]*j\n",
        "  \n",
        "  # work out the end point of the indices\n",
        "  end = start + nparams[k]\n",
        "  \n",
        "  return(np.arange(start, end))\n",
        "\n",
        "t1 = time.time()\n",
        "faclev_indices(0, 1, nlevels, nparams)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5273518562316895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYv59en2gpt3",
        "colab_type": "code",
        "outputId": "c7fc9b2d-4438-4c80-d801-3a5d67b2d95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t1 = time.time()\n",
        "faclev_indices(0, 1, nlevels, nparams)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.679794311523438e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENLuSjo07vTW",
        "colab_type": "text"
      },
      "source": [
        "### Initial Beta\n",
        "\n",
        "The below function returns the OLS estimator for $\\hat{\\beta}$, given by:\n",
        "\n",
        "$$\\hat{\\beta}_{OLS}=(X'X)^{-1}X'Y$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `XtX`: The design matrix transposed and multiplied by itself ($X'X$ in the above notation)\n",
        " - `XtY`: The design matrix transposed and multiplied by the response vector ($X'Y$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `beta`: The OLS estimate of $\\beta$ ($\\hat{\\beta}_{OLS}$ in the above notation).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ue2gIHo7veU",
        "colab_type": "code",
        "outputId": "55778a9d-2aca-46d2-bf50-0f274724b81e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def initBeta(XtX, XtY):\n",
        "  \n",
        "  # Get the beta estimator\n",
        "  beta = np.linalg.solve(XtX,XtY)\n",
        "  \n",
        "  # Return the result\n",
        "  return(beta)\n",
        "\n",
        "print(initBeta(XtX,XtY))\n",
        "print(np.linalg.inv(XtX) @ XtY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1591389 ]\n",
            " [3.83124154]\n",
            " [3.14595612]]\n",
            "[[0.1591389 ]\n",
            " [3.83124154]\n",
            " [3.14595612]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xeRsXZBJUGd",
        "colab_type": "text"
      },
      "source": [
        "#### Initial Sigma\n",
        "\n",
        "The function below returns an initial estimate for the Fixed Effects Variance, $\\sigma^2$. The estimator used is based on the suggested OLS estimator in Demidenko (2012) and is given by:\n",
        "\n",
        "$$\\hat{\\sigma}^2_{OLS}=\\frac{1}{n}(Y-X\\beta)^T(Y-X\\beta)$$\n",
        "$$=\\frac{1}{n}e^Te$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `ete`: The sum of square residuals ($e^Te$ in the above notation).\n",
        " - `n`: The total number of observations ($n$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `sigma2`: The OLS estimate of $\\sigma^2$ ($\\hat{\\sigma}^2_{OLS}$ in the above notation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_STdZ1mNLWbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initSigma2(ete, n):\n",
        "\n",
        "  # Return the OLS estimate of sigma\n",
        "  return(1/n*ete[0,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdtIeA0NNsZl",
        "colab_type": "text"
      },
      "source": [
        "#### Initial D_k\n",
        "\n",
        "The function below returns an initial estimate for the Random Effects Variance matrix for the $k^{th}$ grouping factor, $D_k$. The estimator used is an adaption of the suggested estimator in Demidenko (2012) and is given by:\n",
        "\n",
        "$$vec(\\hat{D}_{k})=\\bigg[\\sum_{i=1}^{l_k}\\sum_{j=1}^{l_k}(Z_{(k,i)}^TZ_{(k,j)}) \\otimes (Z_{(k,i)}^TZ_{(k,j)})\\bigg]^{-1}vec\\bigg(\\sum_{j=1}^{l_k}[\\hat{\\sigma}^{-2}_{OLS}Z_{(k,j)}^Tee^TZ_{(k,j)} - Z_{(k,j)}^TZ_{(k,j)}]\\bigg)$$\n",
        "\n",
        "Or:\n",
        "\n",
        "$$\\hat{D}_{k}=matrix\\bigg(\\bigg[\\sum_{i=1}^{l_k}\\sum_{j=1}^{l_k}(Z_{(k,i)}^TZ_{(k,j)}) \\otimes (Z_{(k,i)}^TZ_{(k,j)})\\bigg]^{-1}vec\\bigg(\\sum_{j=1}^{l_k}[\\hat{\\sigma}^{-2}_{OLS}Z_{(k,j)}^Tee^TZ_{(k,j)} - Z_{(k,j)}^TZ_{(k,j)}]\\bigg)\\bigg)$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The grouping factor we wish to estimate $D$ for ($k$ in the above notation)\n",
        " - `lk`: The number of levels belonging to grouping factor $k$ ($l_k$ in the above notation).\n",
        " - `ZtZ`: The $Z$ matrix transposed and then multiplied by itself ($Z^TZ$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z^Te=Z^T(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The OLS estimate of $\\sigma^2$ ($\\hat{\\sigma}^2_{OLS}$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `Dkest`: The inital estimate of $D_k$ ($\\hat{D}_k$ in the above notation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0J2CFTrNrhq",
        "colab_type": "code",
        "outputId": "46d12304-b22e-4d8a-9da2-8be325d24119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def initDk(k, lk, ZtZ, Zte, sigma2):\n",
        "  \n",
        "  # Initalize D to zeros\n",
        "  invSig2ZteetZminusZtZ = np.zeros((nparams[k],nparams[k]))\n",
        "  \n",
        "  # For each level j we need to add a term\n",
        "  for j in np.arange(nlevels[k]):\n",
        "    \n",
        "    Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "    # Work out Z_(k, j)'Z_(k, j)\n",
        "    ZkjtZkj = ZtZ[np.ix_(Ikj,Ikj)]\n",
        "    \n",
        "    # Work out Z_(k,j)'e\n",
        "    Zkjte = Zte[Ikj,:]\n",
        "    \n",
        "    if j==0:\n",
        "      \n",
        "      # Add first Z_(k,j)'Z_(k,j) kron Z_(k,j)'Z_(k,j)\n",
        "      ZtZkronZtZ = np.kron(ZkjtZkj,ZkjtZkj.transpose())\n",
        "      \n",
        "      # Add first \\sigma^{-2}Z'ee'Z - Z_(k,j)'Z_(k,j)\n",
        "      invSig2ZteetZminusZtZ = 1/sigma2*(Zkjte @ Zkjte.transpose()) - ZkjtZkj\n",
        "      \n",
        "    else:\n",
        "      \n",
        "      # Add next Z_(k,j)'Z_(k,j) kron Z_(k,j)'Z_(k,j)\n",
        "      ZtZkronZtZ = ZtZkronZtZ + np.kron(ZkjtZkj,ZkjtZkj.transpose())\n",
        "      \n",
        "      # Add next \\sigma^{-2}Z'ee'Z - Z_(k,j)'Z_(k,j)\n",
        "      invSig2ZteetZminusZtZ = invSig2ZteetZminusZtZ + 1/sigma2*(Zkjte @ Zkjte.transpose()) - ZkjtZkj\n",
        "  \n",
        "  # Work out the final term.\n",
        "  Dkest = vec2mat(np.linalg.inv(ZtZkronZtZ) @ mat2vec(invSig2ZteetZminusZtZ)) \n",
        "  \n",
        "  return(Dkest)\n",
        "\n",
        "Zte = ZtY-ZtX @ np.array([[1],[2],[3]])\n",
        "\n",
        "t1 = time.time()\n",
        "initDk(0, nlevels[0], ZtZ, Zte , 1)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "initDk(0, nlevels[0], ZtZ, Zte , 1)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0037517547607421875\n",
            "0.0031020641326904297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjypr01QTJh5",
        "colab_type": "text"
      },
      "source": [
        "#### Non-negative Definite D\n",
        "\n",
        "The below function takes in a covariance matrix $D$ and finds nearest projection onto the space of non-negative definite matrices $\\mathbb{D}_+$. It uses the following method taken from Demidenko (2012), page 105:\n",
        "\n",
        "If $D$ is non-negative definite and has eigenvalue decomposition $D=P\\Lambda P^T$ it's closest projection into $\\mathbb{D}_+$ is defined by the matrix below:\n",
        "\n",
        "$$\\hat{D}_+ = P\\Lambda_+P'$$\n",
        "\n",
        "Where $\\Lambda_+$ is defined by the elementwise maximum of $\\Lambda$ and 0; i.e. $\\Lambda_{+(i,j)} = max(\\Lambda_{+(i,j)},0)$.\n",
        "\n",
        "Note: This is not to be confused with the generalized inverse of the duplication matrix $\\mathcal{D}^+$.\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `D`: A square symmetric matrix.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `D_nnd`: The nearest projection of $D$ onto the space of non-negative definite matrices $\\mathbb{D}_+$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2rW_uOBTJ0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeDnnd(D):\n",
        "  \n",
        "  # Check if we have negative eigenvalues\n",
        "  if not np.all(np.linalg.eigvals(D)>0):\n",
        "  \n",
        "    # If we have negative eigenvalues\n",
        "    eigvals,eigvecs = np.linalg.eigh(D)\n",
        "    \n",
        "    # Work out elementwise max of lambda and 0\n",
        "    lamplus = np.diag(np.maximum(eigvals,0))\n",
        "    \n",
        "    # Work out D+\n",
        "    D_nnd = eigvecs @ lamplus @ np.linalg.inv(eigvecs)\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    # D is already non-negative in this case\n",
        "    D_nnd = D\n",
        "    \n",
        "  return(D_nnd)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWz8h5WUFn7R",
        "colab_type": "text"
      },
      "source": [
        "#### Log likelihood of $(\\beta, \\sigma^2, D)$\n",
        "\n",
        "This function returns the log likelihood of $(\\beta, \\sigma^2, D)$ which is given by the below equation:\n",
        "\n",
        "$$l(\\beta,\\sigma^2,D) = -\\frac{1}{2}\\bigg\\{ n\\text{ln}(\\sigma^2) + \\text{ln}|I+Z'ZD| + \\sigma^{-2}(e'e-e'ZD(I+Z'ZD)^{-1}Z'e)\\bigg\\}$$\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `n`: The total number of observations.\n",
        " - `ZtZ`: The $Z$ matrix transposed and then multiplied by Z ($Z'Z$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z'e=Z'(Y-X\\beta)$ in the above notation).\n",
        " - `ete`: The OLS residuals transposed and then multiplied by themselves ($e'e=(Y-X\\beta)'(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The fixed effects variance ($\\sigma^2$ in the above notation).\n",
        " - `DinvIplusZtZD`: The product $D(I+Z'ZD)^{-1}$.\n",
        " - `D`: The random effects variance-covariance matrix ($D$ in the above notation)\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `llh`: The log likelihood of $(\\beta, \\sigma^2, D)$ ($l(\\beta,\\sigma^2,D)$ in the above notation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oaXHL55Fnlv",
        "colab_type": "code",
        "outputId": "dc77d4dd-6948-4f6e-bf39-d1bbdc53f686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def llh(n, ZtZ, Zte, ete, sigma2, DinvIplusZtZD,D):\n",
        "  \n",
        "  # Work out the log likelihood\n",
        "  llh = -0.5*(n*np.log(sigma2) + np.log(np.linalg.det(np.eye(ZtZ.shape[0]) + ZtZ @ D)) + (1/sigma2)*(ete - forceSym(Zte.transpose() @ DinvIplusZtZD @ Zte)))\n",
        "  \n",
        "  # Return result\n",
        "  return(llh)\n",
        "\n",
        "Ddict = dict()\n",
        "print(RFXVar_REst)\n",
        "for k in np.arange(len(nparams)):\n",
        "  \n",
        "  Ddict[k] = RFXVar_REst[np.ix_(np.arange(2*k,2*(k+1)),np.arange(2*k,2*(k+1)))]#makeDnnd(initDk(k, nlevels[k], ZtZ, Zte, sigma2))#\n",
        "  print(Ddict[k])\n",
        "\n",
        "# Matrix version\n",
        "D = np.array([])\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  for j in np.arange(nlevels[i]):\n",
        "    \n",
        "    if i == 0 and j == 0:\n",
        "\n",
        "      D = Ddict[i]\n",
        "\n",
        "    else:\n",
        "\n",
        "      D = scipy.linalg.block_diag(D, Ddict[i])\n",
        "\n",
        "beta = beta_True\n",
        "q = Z.shape[1]\n",
        "sigma2 = 1\n",
        "Zte = ZtY - ZtX @ beta\n",
        "ete = ssr(YtX, YtY, XtX, beta)\n",
        "\n",
        "DinvIplusZtZD = D @ np.linalg.inv(np.eye(q) + ZtZ @ D)\n",
        "t1 = time.time()\n",
        "loglh = llh(n, ZtZ, Zte, ete, sigma2, DinvIplusZtZD,D)\n",
        "t2 = time.time()\n",
        "\n",
        "print(loglh)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.24022707  0.36034323  0.          0.        ]\n",
            " [ 0.36034323  5.0719078   0.          0.        ]\n",
            " [ 0.          0.         20.68631165 -0.79595202]\n",
            " [ 0.          0.         -0.79595202  0.21015464]]\n",
            "[[1.24022707 0.36034323]\n",
            " [0.36034323 5.0719078 ]]\n",
            "[[20.68631165 -0.79595202]\n",
            " [-0.79595202  0.21015464]]\n",
            "[[-683.03796665]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70shU6hKlDMR",
        "colab_type": "text"
      },
      "source": [
        "#### Derivative of $l$ with respect to $\\beta$\n",
        "\n",
        "The below function calculates the derivative of the log likelihood with respect to $\\beta$. This is given by the following equation:\n",
        "\n",
        "$$\\frac{\\delta l}{\\delta \\beta} = \\sigma^{-2}X'(I+ZDZ')^{-1}(Y-X\\beta)$$\n",
        "$$ = \\sigma^{-2}X'(I-ZD(I+Z'ZD)^{-1}Z')(Y-X\\beta)$$\n",
        "$$ = \\sigma^{-2}X'(Y-X\\beta)-X'ZD(I+Z'ZD)^{-1}Z'(Y-X\\beta) $$\n",
        "$$ = \\sigma^{-2}X'e-X'ZD(I+Z'ZD)^{-1}Z'e$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `XtZ`: The $X$ matrix transposed and then multiplied by Z ($X^TZ$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z^Te=Z^T(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The fixed effects variance ($\\sigma^2$ in the above notation).\n",
        " - `DinvIplusZtZD`: The product $D(I+Z'ZD)^{-1}$.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `dldb`: The derivative of $l$ with respect to $\\beta$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX6LfLOBlDVn",
        "colab_type": "code",
        "outputId": "05f965ed-5665-4eef-cd5d-11290719c7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "def get_dldB(sigma2, Xte, XtZ, DinvIplusZtZD, Zte):\n",
        "  \n",
        "  # Return the derivative\n",
        "  return(1/sigma2*(Xte - (XtZ @ DinvIplusZtZD @ Zte)))\n",
        "\n",
        "### Test example\n",
        "\n",
        "p = X.shape[1]\n",
        "beta = np.random.randn(p,1)\n",
        "\n",
        "sigma2=1.1\n",
        "D = np.array([])\n",
        "q=Z.shape[1]\n",
        "n=Z.shape[0]\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  for j in np.arange(nlevels[i]):\n",
        "    \n",
        "    if i == 0 and j == 0:\n",
        "\n",
        "      D = initDk(i, nlevels[i], ZtZ, Zte, sigma2)\n",
        "\n",
        "    else:\n",
        "\n",
        "      D = scipy.linalg.block_diag(D, initDk(i, nlevels[i], ZtZ, Zte, sigma2))\n",
        "      \n",
        "IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "DinvIplusZtZD = D @ np.linalg.inv(IplusZtZD)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "dldb1 = (sigma2)**(-1)*(X.transpose() @ np.linalg.inv(np.eye(n) + Z @ D @ Z.transpose()) @ (Y - X @ beta))\n",
        "\n",
        "Xte = XtY- XtX @ beta\n",
        "\n",
        "Zte = ZtY- ZtX @ beta\n",
        "\n",
        "DinvIplusZtZD = D @ np.linalg.inv(np.eye(q) + ZtZ @ D)\n",
        "\n",
        "dldb2 = get_dldB(sigma2, Xte, XtZ, DinvIplusZtZD, Zte)\n",
        "\n",
        "print(dldb1)\n",
        "print(dldb2)\n",
        "\n",
        "\n",
        "print(dldb2-dldb1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 3)\n",
            "[[2.92522147e-01]\n",
            " [1.91760962e+03]\n",
            " [2.65428220e+03]]\n",
            "[[2.92522147e-01]\n",
            " [1.91760962e+03]\n",
            " [2.65428220e+03]]\n",
            "[[-2.01555217e-10]\n",
            " [ 1.43553734e-07]\n",
            " [ 1.07038431e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pL8p641GAgxF"
      },
      "source": [
        "#### Derivative of $l$ with respect to $\\sigma^2$\n",
        "\n",
        "The below function calculates the derivative of the log likelihood with respect to $\\beta$. This is given by the following equation:\n",
        "\n",
        "$$\\frac{\\delta l}{\\delta \\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4}(Y-X\\beta)'(I+ZDZ')^{-1}(Y-X\\beta)$$\n",
        "$$  = -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4}e'(I+ZDZ')^{-1}e$$\n",
        "$$  = -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4}e'(I-ZD(I+ZZ'D)^{-1}Z')e$$\n",
        "$$  = -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4}(e'e-e'ZD(I+ZZ'D)^{-1}Z'e)$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `n`: The number of observations.\n",
        " - `ete`: The OLS residuals transposed and then multiplied by themselvess ($e^Te=(Y-X\\beta)^T(Y-X\\beta)$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z^Te=Z^T(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The fixed effects variance ($\\sigma^2$ in the above notation).\n",
        " - `DinvIplusZtZD`: The product $D(I+Z'ZD)^{-1}$.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `dldsigma2`: The derivative of $l$ with respect to $\\sigma^2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R0T-_zfJAhRK",
        "outputId": "4792343b-1ae1-4a14-e9cb-bc2099a68e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def get_dldsigma2(n, ete, Zte, sigma2, DinvIplusZtZD):\n",
        "  \n",
        "  # Return the bottom expression in the above derivation\n",
        "  return(-n/(2*sigma2) + 1/(2*(sigma2**2))*(ete - forceSym(Zte.transpose() @ DinvIplusZtZD @ Zte)))\n",
        "\n",
        "\n",
        "# Toy example - recalculate the required inputs\n",
        "Zte = Z.toarray().transpose() @ (Y - X @ beta)\n",
        "ete = (Y - X @ beta).transpose() @ (Y - X @ beta)\n",
        "DinvIplusZtZD = D @ np.linalg.inv(np.eye(q) + ZtZ @ D)\n",
        "\n",
        "# Time the code\n",
        "t1 = time.time()\n",
        "dldsigma2_1 = get_dldsigma2(n, ete, Zte, sigma2, DinvIplusZtZD)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "\n",
        "dldsigma2_2 = -n/(2*sigma2) + 1/(2*(sigma2**2))*(Y - X @ beta).transpose() @ np.linalg.inv(np.eye(n) + (Z @ D @ Z.transpose())) @ (Y - X @ beta)\n",
        "\n",
        "\n",
        "ZtZ = Z.toarray().transpose() @ Z.toarray()\n",
        "\n",
        "# Cannot test against n by n inversion as n by n inversion is extremely bad\n",
        "print(np.amax(np.eye(n) - Z.toarray() @ D @ np.linalg.inv(np.eye(q) + ZtZ @ D) @ Z.toarray().transpose()-np.linalg.inv(np.eye(n) + (Z.toarray() @ D @ Z.toarray().transpose()))))\n",
        "\n",
        "tmp1 = (Y - X @ beta).transpose() @ np.linalg.inv(np.eye(n) + (Z.toarray() @ D @ Z.toarray().transpose())) @ (Y - X @ beta)\n",
        "\n",
        "tmp2 = (Y - X @ beta).transpose() @ (np.eye(n) - Z.toarray() @ D @ np.linalg.inv(np.eye(q) + ZtZ @ D) @ Z.toarray().transpose()) @ (Y - X @ beta)\n",
        "\n",
        "#print(tmp1)\n",
        "#print(tmp2)\n",
        "print(tmp2-tmp1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0001361370086669922\n",
            "2.7351480260361105e-10\n",
            "[[-6.94179107e-07]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0yUC5yE1qin",
        "colab_type": "text"
      },
      "source": [
        "#### Derivative of $l$ with respect to $D_k$\n",
        "\n",
        "The below function calculates the derivative of the log likelihood with respect to $D_k$, the random effects covariance matrix for factor $k$. This is given by the following equation:\n",
        "\n",
        "$$\\frac{\\delta l}{\\delta D_k} = \\frac{1}{2}\\sum_{j=1}^{l_k}(T_{(k,j)}u)(T_{(k,j)}u)'-\\frac{1}{2}\\sum_{j=1}^{l_k}T_{(k,j)}T_{(k,j)}'$$\n",
        "\n",
        "Where $T_{(i,j)}=Z'_{(i,j)}(I+ZDZ')^{-\\frac{1}{2}}$ and $u=\\sigma^{-1}(I+ZDZ')^{-\\frac{1}{2}}(Y-X\\beta)\\sim N(0,\\mathbb{I})$.\n",
        "\n",
        "$$= \\frac{1}{2\\sigma^2}\\sum_{j=1}^{l_k}Z'_{(k,j)}(I+ZDZ')^{-1}ee'(I+ZDZ')^{-1}Z_{(k,j)} - \\frac{1}{2}\\sum_{j=1}^{l_k}Z'_{(k,j)}(I+ZDZ')^{-1}Z_{(k,j)}$$\n",
        "\n",
        "$$= \\frac{1}{2\\sigma^2}\\sum_{j=1}^{l_k}Z'_{(k,j)}(I-ZD(I+Z'ZD)^{-1}Z')ee'(I-ZD(I+Z'ZD)^{-1}Z')'Z_{(k,j)} - \\frac{1}{2}\\sum_{j=1}^{l_k}Z'_{(k,j)}(I-ZD(I+Z'ZD)^{-1})Z_{(k,j)}$$\n",
        "\n",
        "$$= \\frac{1}{2\\sigma^2}\\sum_{j=1}^{l_k}(Z'_{(k,j)}e-Z'_{(k,j)}ZD(I+Z'ZD)^{-1}Z'e)(Z'_{(k,j)}e-Z'_{(k,j)}ZD(I+Z'ZD)^{-1}Z'e)' - \\frac{1}{2}\\sum_{j=1}^{l_k}Z'_{(k,j)}Z_{(k,j)}-Z'_{(k,j)}ZD(I+Z'ZD)^{-1}Z'Z_{(k,j)}$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The factor we wish to estimate the derivative of the covariance matrix of.\n",
        " - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - `nparams`: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " - `ZtZ`: The $Z$ matrix transposed and then multiplied by itself ($Z^TZ$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z^Te=Z^T(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The fixed effects variance ($\\sigma^2$ in the above notation).\n",
        " - `DinvIplusZtZD`: The product $D(I+Z'ZD)^{-1}$.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `dldD`: The derivative of $l$ with respect to $D_k$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D43Adi61quy",
        "colab_type": "code",
        "outputId": "9edeb8d8-b52f-4eda-fd60-7c40927e23fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def get_dldDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD, ZtZmat=None, mode = 'original'):\n",
        "\n",
        "  if mode=='original':\n",
        "    # Initalize the derivative to zeros\n",
        "    dldDk = np.zeros((nparams[k],nparams[k]))\n",
        "\n",
        "    # For each level j we need to add a term\n",
        "    for j in np.arange(nlevels[k]):\n",
        "\n",
        "      # Get the indices for the kth factor jth level\n",
        "      Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "      # Get (the kj^th columns of Z)^T multiplied by Z\n",
        "      Z_kjtZ = ZtZ[Ikj,:]\n",
        "      Z_kjte = Zte[Ikj,:]\n",
        "\n",
        "      # Get the first term of the derivative\n",
        "      Z_kjtVinve = Z_kjte - (Z_kjtZ @ DinvIplusZtZD @ Zte)\n",
        "      firstterm = 1/sigma2 * forceSym(Z_kjtVinve @ Z_kjtVinve.transpose())\n",
        "      \n",
        "      # Get (the kj^th columns of Z)^T multiplied by (the kj^th columns of Z)\n",
        "      Z_kjtZ_kj = ZtZ[np.ix_(Ikj,Ikj)]\n",
        "      secondterm = forceSym(Z_kjtZ_kj) - forceSym(Z_kjtZ @ DinvIplusZtZD @ Z_kjtZ.transpose())\n",
        "      #print('TT')\n",
        "      #print(secondterm)\n",
        "      \n",
        "      if j == 0:\n",
        "        \n",
        "        # Start a running sum over j\n",
        "        dldDk = firstterm - secondterm\n",
        "        \n",
        "      else:\n",
        "      \n",
        "        # Add these to the running sum\n",
        "        dldDk = dldDk + firstterm - secondterm\n",
        "        \n",
        "      #print(j)\n",
        "      #print(dldDk)\n",
        "\n",
        "    # Halve the sum (the coefficient of a half was not included in the above)\n",
        "    dldDk = forceSym(dldDk/2)\n",
        "\n",
        "  else:\n",
        "    \n",
        "    # We only need calculate this once across all iterations\n",
        "    if ZtZmat is None:\n",
        "\n",
        "      # Instantiate to zeros\n",
        "      ZtZmat = np.zeros(nparams[k],nparams[k])\n",
        "\n",
        "      for j in np.arange(nlevels[k]):\n",
        "\n",
        "        # Get the indices for the kth factor jth level\n",
        "        Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "        # Work out R_(k, j)\n",
        "        ZtZterm = ZtZ[np.ix_(Ikj,Ikj)]\n",
        "\n",
        "        # Add together\n",
        "        ZtZmat = ZtZmat + ZtZterm\n",
        "\n",
        "    # Get the indices for the factors \n",
        "    Ik = fac_indices(k, nlevels, nparams)\n",
        "\n",
        "    # Work out lk\n",
        "    lk = nlevels[k]\n",
        "\n",
        "    # Work out block size\n",
        "    qk = nparams[k]\n",
        "    p = np.array([qk,1])\n",
        "\n",
        "    # Work out the second term in TT'\n",
        "    secondTerm = sumAijBijt2D(ZtZ[Ik,:] @ DinvIplusZtZD, ZtZ[Ik,:], p, p)\n",
        "\n",
        "    # Obtain RkSum=sum (TkjTkj')\n",
        "    RkSum = ZtZmat - secondTerm\n",
        "\n",
        "    # Work out T_ku*sigma\n",
        "    TuSig = Zte[Ik,:] - (ZtZ[Ik,:] @ DinvIplusZtZD @ Zte)\n",
        "\n",
        "    # Obtain Sum Tu(Tu)'\n",
        "    TuuTSum = sumAijBijt2D(TuSig, TuSig, p, p)/sigma2\n",
        "\n",
        "    # Work out dldDk\n",
        "    dldDk = 0.5*(forceSym(TuuTSum - RkSum))\n",
        "\n",
        "  # Store it in the dictionary\n",
        "  return(dldDk,ZtZmat)\n",
        "\n",
        "IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "DinvIplusZtZD = D @ np.linalg.inv(IplusZtZD)\n",
        "\n",
        "ZtZ = Z.toarray().transpose() @ Z.toarray()\n",
        "Zte = Z.toarray().transpose() @ (Y - X @ beta)\n",
        "\n",
        "k=0\n",
        "sigma2=0.5\n",
        "Zte = ZtY - ZtX @ beta\n",
        "\n",
        "D = np.eye(D.shape[0])\n",
        "\n",
        "DinvIplusZtZD = D @ np.linalg.inv(np.eye(q) + ZtZ @ D)\n",
        "\n",
        "t1 = time.time()\n",
        "dldDk,_ = get_dldDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "dldDk3, ZtZmat = get_dldDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD, ZtZmat=None, mode='new')\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "dldDk4,_ = get_dldDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD, ZtZmat, mode='new')\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "sqrtinvIplusZDZt = forceSym(scipy.linalg.sqrtm(np.eye(n) - Z @ DinvIplusZtZD @ Z.transpose()))\n",
        "for j in np.arange(nlevels[k]):\n",
        "\n",
        "  Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "  \n",
        "  #print(Zte[Ikj,:] - (Z[:,Ikj].transpose() @ (Y - X @ beta)))\n",
        "  \n",
        "  Z_kjt = Z[:,Ikj].transpose()\n",
        "  Tkj = Z_kjt @ sqrtinvIplusZDZt\n",
        "\n",
        "  u = 1/np.sqrt(sigma2)*sqrtinvIplusZDZt @ (Y - X @ beta)\n",
        "  \n",
        "\n",
        "  Tkju = Tkj @ u\n",
        "\n",
        "  TkjuTkjut = Tkju @ Tkju.transpose()\n",
        "  \n",
        "  TkjTkjt = Tkj @ Tkj.transpose()\n",
        "\n",
        "  \n",
        "  if j == 0:\n",
        "    \n",
        "    sum1 = TkjuTkjut\n",
        "    sum2 = TkjTkjt\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    sum1 = sum1 + TkjuTkjut\n",
        "    sum2 = sum2 + TkjTkjt\n",
        "    \n",
        "  \n",
        "dldDk2 = 0.5*(sum1-sum2)\n",
        "print(np.allclose(dldDk,dldDk2))\n",
        "print(np.allclose(dldDk2,dldDk3))\n",
        "print(np.allclose(dldDk3,dldDk4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.002299785614013672\n",
            "0.0013098716735839844\n",
            "0.0005180835723876953\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-i38jdBJ8RR",
        "colab_type": "text"
      },
      "source": [
        "#### Covariance of $\\frac{\\delta l}{\\delta \\beta}$ \n",
        "\n",
        "The below function calculates the covariance between the derivative of the log likelihood with respect to $\\beta$, given by the below formula:\n",
        "\n",
        "$$\\text{cov}\\bigg(\\frac{\\delta l(\\theta | y)}{\\delta \\beta}\\bigg) = \\sigma^{-2} X'(I+ZDZ')^{-1}X$$\n",
        "$$= \\sigma^{-2} X'(I-ZD(I+Z'ZD)^{-1}Z')X$$\n",
        "$$= \\sigma^{-2} (X'X-X'ZD(I+Z'ZD)^{-1}Z'X)$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `XtZ`: $X$ transpose multiplied by $Z$.\n",
        " - `XtX`: $X$ transpose multiplied by $X$.\n",
        " - `ZtZ`: $Z$ transpose multiplied by $Z$.\n",
        " - `DinvIplusZtZD`: $D(I+Z'ZD)^{-1}$ in the above notation.\n",
        " - `sigma2`: The fixed effects variance ($\\sigma^2$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `covdldbeta`: The covariance of the derivative of the log likelihood with respect to $\\beta$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH4TsQPIJ8ZI",
        "colab_type": "code",
        "outputId": "391441fa-93c3-419d-a65c-f90369bf1e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def get_covdldbeta(XtZ, XtX, ZtZ, DinvIplusZtZD, sigma2):\n",
        "  \n",
        "  # Return the covariance of the derivative\n",
        "  return((1/sigma2)*(XtX - forceSym(XtZ @ DinvIplusZtZD @ XtZ.transpose())))\n",
        "\n",
        "## test\n",
        "\n",
        "IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "DinvIplusZtZD = D @ np.linalg.inv(IplusZtZD)\n",
        "\n",
        "t1 = time.time()\n",
        "covdldbeta_1 = get_covdldbeta(XtZ, XtX, ZtZ, DinvIplusZtZD, sigma2)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "\n",
        "covdldbeta_2 = sigma2**(-1) * (X.transpose() @ np.linalg.inv(np.eye(n) + Z.toarray() @ D @ Z.toarray().transpose()) @ X)\n",
        "\n",
        "#print(covdldbeta_1)\n",
        "#print(covdldbeta_2)\n",
        "\n",
        "# Inverting the n by n is (perhaps obviously) awful though... this was just a\n",
        "# rough check... see below how far out from the identity the inversion mutliplied\n",
        "# by the original matrix is\n",
        "#print(np.linalg.inv(np.eye(n) + Z.toarray() @ D @ Z.toarray().transpose()) @ (np.eye(n) + Z.toarray() @ D @ Z.toarray().transpose()))\n",
        "\n",
        "#print(np.linalg.inv(IplusZtZD) @ IplusZtZD)\n",
        "#print(D)\n",
        "print('solve vs inv')\n",
        "#print((np.linalg.solve(IplusZtZD, D) @ IplusZtZD)-D)\n",
        "#print(DinvIplusZtZD)\n",
        "#print(np.linalg.solve(IplusZtZD, D)-DinvIplusZtZD)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00016427040100097656\n",
            "solve vs inv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh61qPojq_xg",
        "colab_type": "text"
      },
      "source": [
        "#### Covariance of $\\frac{\\delta l}{\\delta \\text{vech}(D_{k})}$ and $\\frac{\\delta l}{\\delta \\sigma^2}$\n",
        "\n",
        "The below function calculates the covariance between the derivative of the log likelihood with respect to $\\text{vech}(D_{k})$ and the derivative with respect to $\\sigma^2$.\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The number of the first factor ($k$ in the above notation).\n",
        " - `sigma2`: The fixed effects variance ($\\sigma^2$ in the above notation).\n",
        " - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - `nparams`: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " - `ZtZ`: $Z$ transpose multiplied by $Z$.\n",
        " - `DinvIplusZtZD`: $D(I+Z'ZD)^{-1}$ in the above notation.\n",
        " - `invDupMatdict`: A dictionary of inverse duplication matrices such that `invDupMatdict[k]` = $\\mathcal{D}_k^+$.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `covdldDdldsigma2`: The covariance between the derivative of the log likelihood with respect to $\\text{vech}(D_{k_1})$ and the derivative with respect to $\\sigma^2$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEx5GJJkq_8-",
        "colab_type": "code",
        "outputId": "32c5f2d6-3bb6-4651-d5a5-e9b0cbf7a795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "def get_covdldDkdsigma2(k, sigma2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict, ZtZmat=None,mode='original'):\n",
        "  \n",
        "  if mode=='original':\n",
        "\n",
        "    # Sum of R_(k, j) over j\n",
        "    RkSum = np.zeros(nparams[k],nparams[k])\n",
        "\n",
        "    for j in np.arange(nlevels[k]):\n",
        "\n",
        "      # Get the indices for the kth factor jth level\n",
        "      Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "      # Work out R_(k, j)\n",
        "      Rkj = ZtZ[np.ix_(Ikj,Ikj)] - forceSym(ZtZ[Ikj,:] @ DinvIplusZtZD @ ZtZ[:,Ikj])\n",
        "\n",
        "      # Add together\n",
        "      RkSum = RkSum + Rkj\n",
        "\n",
        "  else:\n",
        "\n",
        "    # We only need calculate this once across all iterations\n",
        "    if ZtZmat is None:\n",
        "\n",
        "      # Instantiate to zeros\n",
        "      ZtZmat = np.zeros(nparams[k],nparams[k])\n",
        "\n",
        "      for j in np.arange(nlevels[k]):\n",
        "\n",
        "        # Get the indices for the kth factor jth level\n",
        "        Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "        # Work out R_(k, j)\n",
        "        ZtZterm = ZtZ[np.ix_(Ikj,Ikj)]\n",
        "\n",
        "        # Add together\n",
        "        ZtZmat = ZtZmat + ZtZterm\n",
        "\n",
        "    # Get the indices for the factors \n",
        "    Ik = fac_indices(k, nlevels, nparams)\n",
        "\n",
        "    # Work out lk\n",
        "    lk = nlevels[k]\n",
        "\n",
        "    # Work out block size\n",
        "    q = np.sum(nlevels*nparams)\n",
        "    qk = nparams[k]\n",
        "    p = np.array([qk,q])\n",
        "\n",
        "    # Work out the second term\n",
        "    secondTerm = sumAijBijt2D(ZtZ[Ik,:] @ DinvIplusZtZD, ZtZ[Ik,:], p, p)\n",
        "\n",
        "    # Obtain ZtZmat\n",
        "    RkSum = ZtZmat - secondTerm\n",
        "\n",
        "  # Multiply by duplication matrices and save\n",
        "  covdldDdldsigma2 = 1/(2*sigma2) * invDupMatdict[k] @ mat2vec(RkSum)\n",
        "  \n",
        "  return(covdldDdldsigma2,ZtZmat)\n",
        "\n",
        "\n",
        "\n",
        "invDupMatdict = dict()\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  invDupMatdict[i] = invDupMat(nparams[i])\n",
        "\n",
        "print(ZtZ)\n",
        "print(sigma2)\n",
        "\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "covdldDdldsigma2_1,_=get_covdldDkdsigma2(k, sigma2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict,ZtZmat=None,mode='original')\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "covdldDdldsigma2_2,ZtZmat=get_covdldDkdsigma2(k, sigma2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict,ZtZmat=None,mode='new')\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "covdldDdldsigma2_3,_=get_covdldDkdsigma2(k, sigma2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict,ZtZmat=ZtZmat,mode='new')\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "print(np.allclose(covdldDdldsigma2_3,covdldDdldsigma2_2))\n",
        "print(np.allclose(covdldDdldsigma2_2,covdldDdldsigma2_1))\n",
        "print(np.allclose(covdldDdldsigma2_1,covdldDdldsigma2_3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5.00000000e+01 -3.53848226e+01  0.00000000e+00 ... -1.89673372e+01\n",
            "   1.60000000e+01 -4.77010601e+01]\n",
            " [-3.53848226e+01  2.12177714e+04  0.00000000e+00 ...  5.72911850e+02\n",
            "  -9.70764641e+01  7.68081988e+02]\n",
            " [ 0.00000000e+00  0.00000000e+00  5.00000000e+01 ...  2.00888087e+01\n",
            "   1.90000000e+01 -8.31505044e+01]\n",
            " ...\n",
            " [-1.89673372e+01  5.72911850e+02  2.00888087e+01 ...  3.07902515e+04\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 1.60000000e+01 -9.70764641e+01  1.90000000e+01 ...  0.00000000e+00\n",
            "   3.45000000e+02  8.14148559e+01]\n",
            " [-4.77010601e+01  7.68081988e+02 -8.31505044e+01 ...  0.00000000e+00\n",
            "   8.14148559e+01  3.27603629e+04]]\n",
            "0.5\n",
            "0.0021965503692626953\n",
            "0.0014600753784179688\n",
            "0.0009067058563232422\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-p5bOy4K-u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### Covariance of $\\frac{\\delta l}{\\delta \\text{vech}(D_{k_1})}$ and $\\frac{\\delta l}{\\delta \\text{vech}(D_{k_2})}$\n",
        "\n",
        "The below function calculates the covariance between the derivative of the log likelihood with respect to $\\text{vech}(D_{k_1})$ and the derivative with respect to $\\text{vech}(D_{k_2})$.\n",
        "\n",
        "$$\\text{cov}\\bigg(\\frac{\\delta l(\\theta | y)}{\\delta \\text{vech}(D_{k_2})},\\frac{\\delta l(\\theta | y)}{\\delta \\text{vech}(D_{k_2})}\\bigg)=\\frac{1}{2}\\mathcal{D}_{k_1}^+\\sum_{j=1}^{l_{k_2}}\\sum_{i=1}^{l_{k_1}}(R_{(k_1,k_2,i,j)}\\otimes R_{(k_1,k_2, i,j)})\\mathcal{D}_{k_2}^{+'}$$\n",
        "\n",
        "\n",
        "\n",
        "Where $R_{(k_1,k_2,i,j)}=Z_{(k_1,i)}'(I+ZDZ')^{-1}Z_{(k_2,j)}=Z_{(k_1,i)}'Z_{(k_2,j)} - Z_{(k_1,i)}'ZD(I+Z'ZD)^{-1}Z_{(k_2,j)}$.\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k1`: The number of the first factor ($k_1$ in the above notation).\n",
        " - `k2`: The number of the second factor ($k_2$ in the above notation).\n",
        " - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - `nparams`: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " - `ZtZ`: $Z$ transpose multiplied by $Z$.\n",
        " - `DinvIplusZtZD`: $D(I+Z'ZD)^{-1}$ in the above notation.\n",
        " - `invDupMatdict`: A dictionary of inverse duplication matrices such that `invDupMatdict[k]` = $\\mathcal{D}_k^+$\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `covdldDk1dldk2`: The covariance between the derivative of the log likelihood with respect to $\\text{vech}(D_{k_1})$ and the derivative with respect to $\\text{vech}(D_{k_2})$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoAsQQtM4LLs",
        "colab_type": "code",
        "outputId": "c8cf6aa8-8c9e-4817-fe3f-ce7a7293dce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict, perm=None, mode='original'):\n",
        "  \n",
        "  if mode=='original':\n",
        "\n",
        "    # Sum of R_(k1, k2, i, j) kron R_(k1, k2, i, j) over i and j \n",
        "    for i in np.arange(nlevels[k1]):\n",
        "\n",
        "      for j in np.arange(nlevels[k2]):\n",
        "        \n",
        "        # Get the indices for the k1th factor jth level\n",
        "        Ik1i = faclev_indices(k1, i, nlevels, nparams)\n",
        "        Ik2j = faclev_indices(k2, j, nlevels, nparams)\n",
        "        \n",
        "        # Work out R_(k1, k2, i, j)\n",
        "        Rk1k2ij = ZtZ[np.ix_(Ik1i,Ik2j)] - (ZtZ[Ik1i,:] @ DinvIplusZtZD @ ZtZ[:,Ik2j])\n",
        "        \n",
        "        # Work out Rk1k2ij kron Rk1k2ij\n",
        "        RkRt = np.kron(Rk1k2ij,Rk1k2ij)\n",
        "        \n",
        "        # Add together\n",
        "        if (i == 0) and (j == 0):\n",
        "        \n",
        "          RkRtSum = RkRt\n",
        "        \n",
        "        else:\n",
        "          \n",
        "          RkRtSum = RkRtSum + RkRt\n",
        "\n",
        "  else:\n",
        "\n",
        "    # Get the indices for the factors \n",
        "    Ik1 = fac_indices(k1, nlevels, nparams)\n",
        "    Ik2 = fac_indices(k2, nlevels, nparams)\n",
        "\n",
        "    # Work out R_(k1,k2)\n",
        "    Rk1k2 = ZtZ[np.ix_(Ik1,Ik2)] - (ZtZ[Ik1,:] @ DinvIplusZtZD @ ZtZ[:,Ik2])\n",
        "\n",
        "    # Work out block sizes\n",
        "    p = np.array([nparams[k1],nparams[k2]])\n",
        "\n",
        "    # Obtain permutation\n",
        "    RkRtSum,perm=sumAijKronBij2D(Rk1k2, Rk1k2, p, perm)\n",
        "\n",
        "    \n",
        "  # Multiply by duplication matrices and save\n",
        "  covdldDk1dldk2 = 1/2 * invDupMatdict[k1] @ RkRtSum @ invDupMatdict[k2].transpose()\n",
        "  \n",
        "  # Return the result\n",
        "  return(covdldDk1dldk2,perm)\n",
        "\n",
        "\n",
        "# Example\n",
        "\n",
        "# Check against alternative expression\n",
        "Ztmp = Z.toarray()\n",
        "\n",
        "IplusZDZt = np.eye(n) + Z.toarray() @ D @ Z.toarray().transpose()\n",
        "\n",
        "invIplusZDZt = np.linalg.inv(IplusZDZt)\n",
        "\n",
        "DinvIplusZtZD = D @ np.linalg.inv(np.eye(q) + Z.toarray().transpose() @ Z.toarray() @ D)\n",
        "\n",
        "invhalfIplusZDZt = scipy.linalg.sqrtm(np.linalg.inv(IplusZDZt))\n",
        "\n",
        "\n",
        "invDupMatdict = dict()\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  invDupMatdict[i] = invDupMat(nparams[i])\n",
        "  \n",
        "k1 = 0\n",
        "k2 = 0\n",
        "\n",
        "t1 = time.time()\n",
        "examplecov,_ = get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict,perm=None,mode='original')\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "examplecov, perm = get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict,perm=None,mode='new')\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "examplecov, perm = get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict,perm=perm,mode='new')\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "for j in np.arange(nlevels[k1]):\n",
        "  \n",
        "  Ikj = faclev_indices(k1, j, nlevels, nparams)\n",
        "\n",
        "  Tkj = Z[:,Ikj].transpose() @ invhalfIplusZDZt \n",
        "  \n",
        "  if j == 0:\n",
        "    \n",
        "    sumTkT = np.kron(Tkj,Tkj)\n",
        "  \n",
        "  else:\n",
        "    \n",
        "    sumTkT = np.kron(Tkj,Tkj) + sumTkT\n",
        "\n",
        "    \n",
        "for j in np.arange(nlevels[k2]):\n",
        "  \n",
        "  Ikj = faclev_indices(k2, j, nlevels, nparams)\n",
        "\n",
        "  Tkj = Z[:,Ikj].transpose() @ invhalfIplusZDZt \n",
        "  \n",
        "  Tkjt = Tkj.transpose()\n",
        "  \n",
        "  if j == 0:\n",
        "    \n",
        "    sumTtkTt = np.kron(Tkjt,Tkjt)\n",
        "  \n",
        "  else:\n",
        "    \n",
        "    sumTtkTt = np.kron(Tkjt,Tkjt) + sumTtkTt\n",
        "    \n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "for i in np.arange(nlevels[k1]):\n",
        "  \n",
        "  for j in np.arange(nlevels[k2]):\n",
        "  \n",
        "    \n",
        "    Ik1i = faclev_indices(k1, i, nlevels, nparams)\n",
        "    Ik2j = faclev_indices(k2, j, nlevels, nparams)\n",
        "\n",
        "    Tk1iTk2jt = Z[:,Ik1i].transpose() @ invIplusZDZt @ Z[:,Ik2j]\n",
        "\n",
        "    if i==0 and j == 0:\n",
        "\n",
        "      sumTTtkTTt = np.kron(Tk1iTk2jt,Tk1iTk2jt)\n",
        "\n",
        "    else:\n",
        "\n",
        "      sumTTtkTTt = np.kron(Tk1iTk2jt,Tk1iTk2jt) + sumTTtkTTt\n",
        "\n",
        "    \n",
        "\n",
        "print(np.allclose(1/2 * invDupMatdict[k1] @ sumTkT @ sumTtkTt @ invDupMatdict[k2].transpose(), examplecov))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.049247026443481445\n",
            "0.001379251480102539\n",
            "0.0011448860168457031\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze-tnNcl6cmK",
        "colab_type": "text"
      },
      "source": [
        "## Fisher Scoring implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC2U0nts6sO_",
        "colab_type": "text"
      },
      "source": [
        "The below function is the \"one-voxel\" implementation of Fisher Scoring.\n",
        "\n",
        "---\n",
        "\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **ZtX**: Z transpose multiplied by X.\n",
        " - **ZtY**: Z transpose multiplied by Y.\n",
        " - **XtX**: X transpose multiplied by X.\n",
        " - **ZtZ**: Z transpose multiplied by Z.\n",
        " - **XtY**: X transpose multiplied by Y.\n",
        " - **YtX**: Y transpose multiplied by X.\n",
        " - **YtZ**: Y transpose multiplied by Z.\n",
        " - **XtZ**: X transpose multiplied by Z.\n",
        " - **YtY**: Y transpose multiplied by Y.\n",
        " - **nlevels**: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - **nparams**: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " - **tol**: The tolerance for convergence.\n",
        " \n",
        " \n",
        "---\n",
        "\n",
        "The following outputs are given by this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **paramVec**: A vector containing the $\\beta$, $\\sigma^2$ and $D$ estimates for the mixed model.\n",
        " - **bvals**: A vector of b values for the mixed model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nj_W4Ls6btZ",
        "colab_type": "code",
        "outputId": "f6b5012f-9e8a-4762-94ce-cc70e6ea1c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def FS(XtX, XtY, ZtX, ZtY, ZtZ, XtZ, YtZ, YtY, YtX, nlevels, nparams, tol, n):\n",
        "  \n",
        "  # Useful scalars\n",
        "  # ------------------------------------------------------------------------------\n",
        "\n",
        "  # Number of factors, r\n",
        "  r = len(nlevels)\n",
        "\n",
        "  # Number of random effects, q\n",
        "  q = np.sum(np.dot(nparams,nlevels))\n",
        "\n",
        "  # Number of fixed effects, p\n",
        "  p = XtX.shape[0]\n",
        "\n",
        "  # Initial estimates\n",
        "  # ------------------------------------------------------------------------------\n",
        "\n",
        "  # Inital beta\n",
        "  beta = initBeta(XtX, XtY)\n",
        "\n",
        "  # Work out e'e\n",
        "  ete = ssr(YtX, YtY, XtX, beta)\n",
        "\n",
        "  # Initial sigma2\n",
        "  sigma2 = initSigma2(ete, n)\n",
        "\n",
        "  Zte = ZtY - (ZtX @ beta)\n",
        "\n",
        "  # Inital D\n",
        "  # Dictionary version\n",
        "  Ddict = dict()\n",
        "  for k in np.arange(len(nparams)):\n",
        "\n",
        "    Ddict[k] = makeDnnd(initDk(k, nlevels[k], ZtZ, Zte, sigma2))\n",
        "    \n",
        "  # Matrix version\n",
        "  D = np.array([])\n",
        "  for i in np.arange(len(nparams)):\n",
        "\n",
        "    for j in np.arange(nlevels[i]):\n",
        "\n",
        "      if i == 0 and j == 0:\n",
        "\n",
        "        D = Ddict[i]\n",
        "\n",
        "      else:\n",
        "\n",
        "        D = scipy.linalg.block_diag(D, Ddict[i])\n",
        "\n",
        "  # Duplication matrices\n",
        "  # ------------------------------------------------------------------------------\n",
        "  invDupMatdict = dict()\n",
        "  for i in np.arange(len(nparams)):\n",
        "\n",
        "    invDupMatdict[i] = invDupMat(nparams[i])\n",
        "\n",
        "  # Index variables\n",
        "  # ------------------------------------------------------------------------------\n",
        "  # Work out the total number of paramateres\n",
        "  tnp = np.int32(p + 1 + np.sum(nparams*(nparams+1)/2))\n",
        "\n",
        "  # Indices for submatrics corresponding to Dks\n",
        "  FishIndsDk = np.int32(np.cumsum(nparams*(nparams+1)/2) + p + 1)\n",
        "  FishIndsDk = np.insert(FishIndsDk,0,p+1)\n",
        "  #print('inds',FishIndsDk)\n",
        "\n",
        "  Zte = ZtY - (ZtX @ beta)\n",
        "\n",
        "  # Inverse of (I+Z'ZD) multiplied by DIplusDZtZ \n",
        "  IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "  DinvIplusZtZD = forceSym(D @ scipy.sparse.linalg.inv(scipy.sparse.csc_matrix(IplusZtZD)))\n",
        "\n",
        "  # Step size lambda\n",
        "  lam = 1\n",
        "  \n",
        "  # Initial log likelihoods\n",
        "  llhprev = np.inf\n",
        "  llhcurr = -np.inf\n",
        "\n",
        "  # Miscelanous matrices that only need be computed once.\n",
        "  # ------------------------------------------------------------------------------\n",
        "\n",
        "  # This will hold the matrices: Sum_j^{l_k} Z_{i,j}'Z_{i,j}\n",
        "  ZtZmatdict = dict()\n",
        "  for k in np.arange(len(nparams)):\n",
        "    ZtZmatdict[k] = None\n",
        "\n",
        "  # This will hold the permutations needed for the covariance between the\n",
        "  # derivatives with respect to k1 and k2\n",
        "  permdict = dict()\n",
        "  for k1 in np.arange(len(nparams)):\n",
        "    for k2 in np.arange(len(nparams)):\n",
        "      permdict[str(k1)+str(k2)] = None\n",
        "  \n",
        "  counter = 0\n",
        "  while np.abs(llhprev-llhcurr)>tol:\n",
        "    \n",
        "    #print('nit', counter)\n",
        "    counter = counter+1\n",
        "    \n",
        "    # Change current likelihood to previous\n",
        "    llhprev = llhcurr\n",
        "\n",
        "    # Matrices needed later by many calculations:\n",
        "    # ----------------------------------------------------------------------------\n",
        "    # X transpose e and Z transpose e\n",
        "    Xte = XtY - (XtX @ beta)\n",
        "    Zte = ZtY - (ZtX @ beta)\n",
        "\n",
        "    # Inverse of (I+Z'ZD) multiplied by D\n",
        "    IplusZtZD = np.eye(q) + (ZtZ @ D)\n",
        "    DinvIplusZtZD = forceSym(D @ scipy.sparse.linalg.inv(scipy.sparse.csc_matrix(IplusZtZD)))\n",
        "\n",
        "    # Sum of squared residuals\n",
        "    ete = ssr(YtX, YtY, XtX, beta)\n",
        "\n",
        "    # Derivatives\n",
        "    # ----------------------------------------------------------------------------\n",
        "\n",
        "    # Derivative wrt beta\n",
        "    dldB = get_dldB(sigma2, Xte, XtZ, DinvIplusZtZD, Zte)\n",
        "\n",
        "    # Derivative wrt sigma^2\n",
        "    dldsigma2 = get_dldsigma2(n, ete, Zte, sigma2, DinvIplusZtZD)\n",
        "    \n",
        "    # For each factor, factor k, work out dl/dD_k\n",
        "    dldDdict = dict()\n",
        "    for k in np.arange(len(nparams)):\n",
        "      # Store it in the dictionary\n",
        "      if ZtZmatdict[k] is None:\n",
        "        dldDdict[k],ZtZmatdict[k] = get_dldDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD,ZtZmat=None,mode='new')\n",
        "      else:\n",
        "        dldDdict[k],_ = get_dldDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD,ZtZmat=ZtZmatdict[k],mode='new')\n",
        "\n",
        "    # Covariances\n",
        "    # ----------------------------------------------------------------------------\n",
        "\n",
        "    # Covariance of dl/dsigma2\n",
        "    covdldsigma2 = n/(2*(sigma2**2))\n",
        "\n",
        "    # Construct the Fisher Information matrix\n",
        "    # ----------------------------------------------------------------------------\n",
        "    FisherInfoMat = np.zeros((tnp,tnp))\n",
        "\n",
        "    # Add dl/dbeta covariance\n",
        "    FisherInfoMat[np.ix_(np.arange(p),np.arange(p))] = get_covdldbeta(XtZ, XtX, ZtZ, DinvIplusZtZD, sigma2)\n",
        "\n",
        "    # Add dl/dsigma2 covariance\n",
        "    FisherInfoMat[p,p] = covdldsigma2\n",
        "\n",
        "    # Add dl/dsigma2 dl/dD covariance\n",
        "    for k in np.arange(len(nparams)):\n",
        "\n",
        "      # Assign to the relevant block\n",
        "      if ZtZmatdict[k] is None:\n",
        "        covdldDksigma2,ZtZmatdict[k] = get_covdldDkdsigma2(k, sigma2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict, ZtZmat=None,mode='new')\n",
        "      else:\n",
        "        covdldDksigma2,_ = get_covdldDkdsigma2(k, sigma2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict, ZtZmat=ZtZmatdict[k],mode='new')\n",
        "\n",
        "      FisherInfoMat[p, FishIndsDk[k]:FishIndsDk[k+1]] = covdldDksigma2.reshape(FishIndsDk[k+1]-FishIndsDk[k])\n",
        "      FisherInfoMat[FishIndsDk[k]:FishIndsDk[k+1],p] = FisherInfoMat[p, FishIndsDk[k]:FishIndsDk[k+1]].transpose()\n",
        "\n",
        "    # Add dl/dD covariance\n",
        "    for k1 in np.arange(len(nparams)):\n",
        "\n",
        "      for k2 in np.arange(k1+1):\n",
        "\n",
        "        IndsDk1 = np.arange(FishIndsDk[k1],FishIndsDk[k1+1])\n",
        "        IndsDk2 = np.arange(FishIndsDk[k2],FishIndsDk[k2+1])\n",
        "\n",
        "        # Get covariance between D_k1 and D_k2 \n",
        "        if permdict[str(k1)+str(k2)] is None:\n",
        "          FisherInfoMat[np.ix_(IndsDk1, IndsDk2)],_ = get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict,perm=None,mode='new')\n",
        "        else:\n",
        "          FisherInfoMat[np.ix_(IndsDk1, IndsDk2)],_ = get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict,perm=permdict[str(k1)+str(k2)],mode='new')\n",
        "\n",
        "        FisherInfoMat[np.ix_(IndsDk2, IndsDk1)] = FisherInfoMat[np.ix_(IndsDk1, IndsDk2)].transpose()\n",
        "\n",
        "    paramVector = np.concatenate((beta, np.array([[sigma2]])))\n",
        "    derivVector = np.concatenate((dldB, dldsigma2))\n",
        "\n",
        "    for k in np.arange(len(nparams)):\n",
        "\n",
        "      paramVector = np.concatenate((paramVector, mat2vech(Ddict[k])))\n",
        "      derivVector = np.concatenate((derivVector, mat2vech(dldDdict[k])))\n",
        "\n",
        "    FisherInfoMat = forceSym(FisherInfoMat)\n",
        "\n",
        "    paramVector = paramVector + lam*(np.linalg.inv(FisherInfoMat) @ derivVector)\n",
        "    \n",
        "    if sigma2<0:\n",
        "\n",
        "      sigspos[z]=1\n",
        "      sigma2 = np.maximum(sigma2,1e-6)\n",
        "\n",
        "    #print(paramVector)\n",
        "    beta = paramVector[0:p]\n",
        "    sigma2 = paramVector[p:(p+1)][0,0]\n",
        "\n",
        "    for k in np.arange(len(nparams)):\n",
        "\n",
        "      Ddict[k] = makeDnnd(vech2mat(paramVector[FishIndsDk[k]:FishIndsDk[k+1]]))\n",
        "      \n",
        "    for i in np.arange(len(nparams)):\n",
        "\n",
        "      for j in np.arange(nlevels[i]):\n",
        "\n",
        "\n",
        "        if i == 0 and j == 0:\n",
        "\n",
        "          D = Ddict[i]\n",
        "\n",
        "        else:\n",
        "\n",
        "          D = scipy.linalg.block_diag(D, Ddict[i])\n",
        "\n",
        "    # Update the step size\n",
        "    llhcurr = llh(n, ZtZ, Zte, ete, sigma2, DinvIplusZtZD,D)[0,0]\n",
        "    if llhprev>llhcurr:\n",
        "      lam = lam/2\n",
        "      \n",
        "  bvals = DinvIplusZtZD @ Zte\n",
        "  \n",
        "  return(paramVector, bvals)\n",
        "\n",
        "t1 = time.time()\n",
        "paramVec, bvals = FS(XtX, XtY, ZtX, ZtY, ZtZ, XtZ, YtZ, YtY, YtX, nlevels, nparams, 1e-6, n)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "paramVec, bvals = FS(XtX, XtY, ZtX, ZtY, ZtZ, XtZ, YtZ, YtY, YtX, nlevels, nparams, 1e-6, n)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "print(\"Predicted time on nifti of size 100x100x100 (in hours): \", 100*100*100*(t2-t1)/(60*60))\n",
        "\n",
        "\n",
        "\n",
        "print(\"U estimates (R)\")\n",
        "print(pd.read_csv('/Data/BLMM-testdata/estd_b.csv',header=None).values.reshape(23,2))\n",
        "print(\"U estimates (FS)\")\n",
        "print(bvals.reshape(23,2))\n",
        "print(\"U true\")\n",
        "print(pd.read_csv('/Data/BLMM-testdata/true_b.csv',header=None).values.reshape(23,2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.179828405380249\n",
            "0.9709312915802002\n",
            "Predicted time on nifti of size 100x100x100 (in hours):  269.7031365500556\n",
            "U estimates (R)\n",
            "[[-0.16266309 -4.21724427]\n",
            " [ 1.41643004  1.41243783]\n",
            " [ 1.59527575 -1.58921871]\n",
            " [ 1.57314783  0.40497904]\n",
            " [ 1.29727291  0.93796984]\n",
            " [-1.20537013  2.19715236]\n",
            " [-0.62177368 -1.1845146 ]\n",
            " [-0.8982196  -1.34761407]\n",
            " [ 0.2105669   2.5381855 ]\n",
            " [-0.57561587 -3.43679857]\n",
            " [ 1.33808317  0.10724134]\n",
            " [-1.20676845 -2.43712662]\n",
            " [ 0.64262693  1.33629341]\n",
            " [-0.9916963  -0.08043681]\n",
            " [ 1.44782818  2.19618068]\n",
            " [-1.25815704  4.3074814 ]\n",
            " [ 0.27424557  0.87149959]\n",
            " [-0.78704685 -3.16062475]\n",
            " [-1.48916827 -0.24116661]\n",
            " [-0.47444214  3.13847411]\n",
            " [ 1.80633411  0.64368738]\n",
            " [ 2.06756827 -0.15742136]\n",
            " [-7.37272861  0.43752657]]\n",
            "U estimates (FS)\n",
            "[[-0.16277237 -4.21724426]\n",
            " [ 1.41631016  1.41243782]\n",
            " [ 1.59515855 -1.58921869]\n",
            " [ 1.5730278   0.40497904]\n",
            " [ 1.29715167  0.93796983]\n",
            " [-1.20549151  2.19715239]\n",
            " [-0.62188845 -1.18451457]\n",
            " [-0.8983342  -1.34761406]\n",
            " [ 0.21044476  2.53818554]\n",
            " [-0.57572665 -3.43679866]\n",
            " [ 1.33796518  0.10724135]\n",
            " [-1.20688117 -2.43712659]\n",
            " [ 0.64250659  1.33629342]\n",
            " [-0.99181298 -0.08043681]\n",
            " [ 1.44770551  2.19618072]\n",
            " [-1.25828042  4.30748132]\n",
            " [ 0.27412685  0.87149954]\n",
            " [-0.78715787 -3.16062473]\n",
            " [-1.48928447 -0.24116662]\n",
            " [-0.47456435  3.13847416]\n",
            " [ 1.78155856  0.64368706]\n",
            " [ 2.04279921 -0.15742126]\n",
            " [-7.39750587  0.43752703]]\n",
            "U true\n",
            "[[-0.19301143 -4.22666242]\n",
            " [ 1.43735476  1.40883489]\n",
            " [ 1.34711832 -1.58788242]\n",
            " [ 1.81825209  0.3910735 ]\n",
            " [ 1.25654173  0.94063103]\n",
            " [-1.22775617  2.19293973]\n",
            " [-0.79408731 -1.19281546]\n",
            " [-0.9898057  -1.35221872]\n",
            " [-0.03319243  2.53178969]\n",
            " [-0.65604937 -3.43139032]\n",
            " [ 1.42910277  0.11018046]\n",
            " [-0.96244844 -2.43071144]\n",
            " [ 0.70088294  1.33487455]\n",
            " [-1.3137399  -0.07784482]\n",
            " [ 1.45666816  2.19521647]\n",
            " [-1.3663195   4.30629966]\n",
            " [ 0.22757187  0.87208539]\n",
            " [-0.89571743 -3.14622337]\n",
            " [-1.51292639 -0.23242295]\n",
            " [-0.5588196   3.15054584]\n",
            " [ 1.85205881  0.64080503]\n",
            " [ 2.10133112 -0.1570577 ]\n",
            " [-7.27154738  0.44280999]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nazpuh-A5vx",
        "colab_type": "text"
      },
      "source": [
        "# Scaling up the computation (Random field)\n",
        "\n",
        "This section has several implemented ideas for scaling up the computation to compute several similar models at once. For simplicity it is assumed here that X and Z are the same across voxels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQqn-irnDVbw",
        "colab_type": "text"
      },
      "source": [
        "### Toy dataset (for a random field)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q70VwMBhDZpG",
        "colab_type": "text"
      },
      "source": [
        "#### Matrix Dimensions\n",
        "\n",
        "Below are the matrix dimensions used for **one voxel** in this example. If the model has form:\n",
        "\n",
        "$$Y=X\\beta+Zb+\\epsilon$$ With $\\epsilon \\sim N(0,\\sigma^2I_n)$ and $b \\sim N(0,\\sigma^2D)$, then the dimensions of each matrix are as follows:\n",
        "\n",
        " - $Y$: $(n \\times 1)$\n",
        " - $X$: $(n \\times p)$\n",
        " - $\\beta$: $(p \\times 1)$\n",
        " - $Z$: $(n \\times q)$\n",
        " - $b$: $(q \\times 1)$\n",
        " - $\\epsilon$: $(n \\times 1)$\n",
        " - $D$: $(p\\times p)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmvGEtodDXRF",
        "colab_type": "code",
        "outputId": "f86862d0-1618-4f1f-ab65-c410e27c33bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Number of factors, random integer between 1 and 3\n",
        "r = 2#np.random.randint(2,4)#np.random.randint(1,4)\n",
        "print(\"Number of grouping factors for random effects:\")\n",
        "print(r)\n",
        "\n",
        "# Number of levels, random number between 2 and 8\n",
        "nlevels = np.random.randint(2,8,size=(r))\n",
        "# Let the first number of levels be a little larger (typically like subjects)\n",
        "nlevels[0] = np.random.randint(2,35,size=1)\n",
        "nlevels = np.sort(nlevels)[::-1]\n",
        "print(\"Number of levels for each factor:\")\n",
        "print(nlevels)\n",
        "\n",
        "# Number of parameters, random number between 1 and 5\n",
        "nparams = np.random.randint(1,6,size=(r))\n",
        "print(\"Number of parameters for each factor:\")\n",
        "print(nparams)\n",
        "\n",
        "# Dimension of D\n",
        "print(\"Dimension of D, q:\")\n",
        "q = np.sum(nlevels*nparams)\n",
        "print(q)\n",
        "\n",
        "# Number of fixed effects, random number between 6 and 30\n",
        "p = np.random.randint(6,31)\n",
        "print(\"Number of fixed effects:\")\n",
        "print(p)\n",
        "\n",
        "# Number of subjects, n\n",
        "n = 1000\n",
        "print(\"Number of subjects:\")\n",
        "print(n)\n",
        "\n",
        "# Voxel dimensions\n",
        "dimv = [30,30,30]\n",
        "nv = np.prod(dimv)\n",
        "print(\"Number of voxels:\")\n",
        "print(nv)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of grouping factors for random effects:\n",
            "2\n",
            "Number of levels for each factor:\n",
            "[14  5]\n",
            "Number of parameters for each factor:\n",
            "[2 5]\n",
            "Dimension of D, q:\n",
            "53\n",
            "Number of fixed effects:\n",
            "11\n",
            "Number of subjects:\n",
            "1000\n",
            "Number of voxels:\n",
            "27000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NvSqz2ADc7X",
        "colab_type": "text"
      },
      "source": [
        "#### Fixed Effects matrix (X)\n",
        "\n",
        "For simplicity, in this example $X$ is the same for all voxels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4689w6FrDaDO",
        "colab_type": "code",
        "outputId": "f9fe3b0c-6464-411f-97a7-7589b3102355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Initialize empty x\n",
        "X = np.zeros((n,p))\n",
        "\n",
        "# First column is intercept\n",
        "X[:,0] = 1\n",
        "\n",
        "# Rest of the columns we will make random noise \n",
        "X[:,1:] = np.random.randn(n*(p-1)).reshape((n,(p-1)))\n",
        "\n",
        "# Image of the last 20 rows of X\n",
        "imshow(X[-20:-1,:])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8ed753dc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKoAAAD4CAYAAAB8MH1+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/z0A4I8aMI70AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQLC39CYDqa7",
        "colab_type": "text"
      },
      "source": [
        "#### Random Effects matrix (Z)\n",
        "\n",
        "For simplicity, in this example $Z$ is the same for all voxels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyZSa63dDi8Z",
        "colab_type": "code",
        "outputId": "9490f3fa-7329-488b-984f-28774ace9902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "import sparse\n",
        "# We need to create a block of Z for each level of each factor\n",
        "for i in np.arange(r):\n",
        "  \n",
        "  Zdata_factor = np.random.randn(n,nparams[i])\n",
        "  \n",
        "  if i==0:\n",
        "    \n",
        "    #The first factor should be block diagonal, so the factor indices are grouped\n",
        "    factorVec = np.repeat(np.arange(nlevels[i]), repeats=np.floor(n/max(nlevels[i],1)))\n",
        "    \n",
        "    if len(factorVec) < n:\n",
        "      \n",
        "      # Quick fix incase rounding leaves empty columns\n",
        "      factorVecTmp = np.zeros(n)\n",
        "      factorVecTmp[0:len(factorVec)] = factorVec\n",
        "      factorVecTmp[len(factorVec):n] = nlevels[i]-1\n",
        "      factorVec = np.int64(factorVecTmp)\n",
        "      \n",
        "    \n",
        "    # Crop the factor vector - otherwise have a few too many\n",
        "    factorVec = factorVec[0:n]\n",
        "    \n",
        "    # Give the data an intercept\n",
        "    Zdata_factor[:,0]=1\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    # The factor is randomly arranged across subjects\n",
        "    factorVec = np.random.randint(0,nlevels[i],size=n) \n",
        "  \n",
        "  # Build a matrix showing where the elements of Z should be\n",
        "  indicatorMatrix_factor = np.zeros((n,nlevels[i]))\n",
        "  indicatorMatrix_factor[np.arange(n),factorVec] = 1\n",
        "  \n",
        "  # Need to repeat for each parameter the factor has \n",
        "  indicatorMatrix_factor = np.repeat(indicatorMatrix_factor, nparams[i], axis=1)\n",
        "  \n",
        "  # Enter the Z values\n",
        "  indicatorMatrix_factor[indicatorMatrix_factor==1]=Zdata_factor.reshape(Zdata_factor.shape[0]*Zdata_factor.shape[1])\n",
        "  \n",
        "  # Make sparse\n",
        "  Zfactor = scipy.sparse.csr_matrix(indicatorMatrix_factor)\n",
        "\n",
        "  # Put all the factors together\n",
        "  if i == 0:\n",
        "    Z = Zfactor\n",
        "  else:\n",
        "    Z = scipy.sparse.hstack((Z, Zfactor))\n",
        "\n",
        "\n",
        "Z2 = sparse.COO.from_scipy_sparse(Z)\n",
        "\n",
        "# Create an image of Z\n",
        "imshow(Z.toarray(), \\\n",
        "       interpolation='nearest', vmin=-5, vmax=5, aspect='auto')\n",
        "\n",
        "print(nlevels)\n",
        "print(nparams)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14  5]\n",
            "[2 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhmFEkP8P3zxSiEewPiEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRsq7mmwD4uG",
        "colab_type": "text"
      },
      "source": [
        "#### Smooth random beta\n",
        "Smooth random beta image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH2F-3D8Doqr",
        "colab_type": "code",
        "outputId": "22f36fe9-a689-4550-f333-28d831d12f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# Random 4D matrix (unsmoothed)\n",
        "beta_us = np.random.randn(nv*p).reshape(dimv[0],dimv[1],dimv[2],p)*20\n",
        "beta_us[10:15,10:15,10:15,3] = beta_us[10:15,10:15,10:15,3] + 100\n",
        "\n",
        "t1 = time.time()\n",
        "# Some random affine, not important for this simulation\n",
        "affine = np.diag([1, 1, 1, 1])\n",
        "beta_us_nii = nib.Nifti1Image(beta_us, affine)\n",
        "\n",
        "# Smoothed beta nifti\n",
        "beta_s_nii = nilearn.image.smooth_img(beta_us_nii, 5)\n",
        "\n",
        "# Final beta\n",
        "beta = beta_s_nii.get_fdata()\n",
        "\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "# Show unsmoothed\n",
        "imshow(beta_us[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.014941215515136719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f8ed74d8198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAD6CAYAAAB5wlaZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOmURkRhRpywiEiPqlEVEYuT/A3nogL+0tkNFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_jmFhBhD6tL",
        "colab_type": "code",
        "outputId": "506cf64c-2316-4db5-ff48-76005b8bd8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Show smoothed\n",
        "imshow(beta[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f8ed73f3128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAD5CAYAAACAhzbGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAfCUlEQVR4nO3dfYwcd3kH8O+zs7u392Y7jsG4SSBA\nIyQUtUl7Cq1AbXhrA0UNVGpE/kBBRTWViAQSUkvhD+gflWjLS5GKkI7GIkjhJSqkRG1KCFGkFKmk\ncdIoJDGUlDhg49hxHPvO97a7s9/+sWt0BN88z92OZ+Ym34+18t3ub2d+Ozv37Oxvnnl+RhIiIlKs\nRtkdEBF5MVLwFREpgYKviEgJFHxFREqg4CsiUgIFXxGREjTHebKZXQfgcwASAP9M8pNZ7Tu7OpzZ\nNzPOKgEAKc1t0x34L63fS9w21vXX1ei5TWCp83gg4y/wskH/JYXaBDYf0PQ73UgGfn8Cq2LfP05o\nrPkbKFn115Ws9v1GXf9N58B/7dZwXle75S5j0PLfUDYDO0+Apf67ZYPAOxpos7h87CTJl0T6tZE/\nfOM0nzvl/PEBeOjRtbtJXjfOujZry8HXzBIAnwfwVgBHADxoZneSfGKj58zsm8Ef3frHW13lLyz1\n226bny3ucts8c+wit037qL/zTx3zd+zO89l/iEnP3xnTduBDZ9Zvs3aR32Z1jx840ov9ADS1w492\nDHyqrJya9Nf1lP9e7f6R/4c4+8Pn3TZ8+qjbZrC05LZpTE1nPm6X7nOXsXbpTr/NrrGOs36huezv\nF+0Ff79oLPtt7nn4b54OdSrDc6dS/PfdL3fbJft+vGfcdW3WOMMO1wB4kuRPSHYBfA3A9fl0S0Rk\nfAQwCPwrwzgfh5cA+Nm6348AeN143RERyQ9B9Oh/2ylDPt9FMpjZfgD7AWD6ZdlfsURE8lbWka1n\nnGGHowAuW/f7paP7fgnJeZJzJOc6uzpjrE5EZHMIIqV/K8M4wfdBAFeY2SvNrA3g3QDuzKdbIiL5\nGIDurQxbHnYg2TezmwHcjWGq2QGSj2c9ZyVt4YfPvzRzuY1AzlUv9VNrFpYCR9ndQPpSmk+KDp1V\nseGvZ5AE2gRSiiJpZAy0aTQDZ76b/nhbK9BmsCuQEbHPfz/PdANpWeZnwcxM+Rk3zWfPuG28lLVI\n1cHGmr/9krVIOprbJJQSWSUEkJYUXD1jjfmSvAvAXTn1RUQkd2Ud2Xou+Ak3EZGyEEAvhzFdM+sA\nuB/ABIZx819IfnycZSr4ikhtEcxr2GENwJtInjWzFoDvmdl/kPz+Vheo4Csi9UUgcEW0v5jh4PvZ\n0a+t0W2sJauwjojU1vAKN/8WYWaJmT0C4ASAe0g+ME7fFHxFpMYMaeAGYI+ZHVx32//CJZFMSV6F\n4TUN15jZleP0TMMOIlJbwxNuoXTRkyTnQsskT5vZfQCuA/DYVvtWaPDtdxM883MnhzKftFqgHygF\nuRI48I+M6kQW4+TxshFYUaSkZKgvgTaBdXnVEIFYDu+eKb/6V6TNyWm/gtrJHTvcNmu7/Rze1d2z\nbpsdT024bTrHzmY36PnlLZMVv0JY0vHzfNPJSA602ySUs45Aznoehnm+46/LzF4CoDcKvJMYVnP8\nu3GWqSNfEam1QezI17MPwK2jUroNALeT/LdxFqjgKyK1ldeRL8lHAVw99oLWUfAVkdoiDGlF8woU\nfEWk1nIadsidgq+I1BZh6EYmLSyBgq+I1NbwIgsNOwCpITmdvcq8UqVi0wEHmiT5TGzplXFMQjMg\n+31Juv5yksgsvyt+m/6qf0TR6/ttppp+p18xdcpt09jpb5+ndlzstnl82p+0cqHhz8KdrAXKTjql\nT5vPOaloAKwfmCU5cBlXpBwpWn4bGwRmBY/McJyTPE64XQg68hWR2iINaehorXgKviJSawMd+YqI\nFGt4wq2aYa6avRIRyYFOuImIlCRVnq+ISLF0hdtmRD6kmn6aCgMz69IvOoVeI5A2E6iglqxmt0m6\ngVlq/QJXaC0Ftk1OlanY8nefxUl/FunlHX5K1mQgF29va8Ft0zK/ytqJHX7FsiPTU26btB34o49U\nAMtBOuH3pTedz+zYaSAdjZG0tpwMlO0gIlKsYWEdBV8RkUIRhp4uLxYRKRYJXWQhIlI800UWIiJF\nI3TkKyJSilqecDOzwwAWAaQA+u7snw1g0MlOhYqkiNmkny7UmfRTkxoNf12rK34aVBd+zlrSzd4B\nIpXGJhb9NLLmqt8mkG0VqoIVmTl0pe1vm6NTO902eycX3TZJoNML/Um3zVK35a8rMPlqcyWQPria\nvZ9a33+zBoGZTNOO36Y7G0gjm4i0cZtg0CrmJBhhtS6m/kaSJ3NYjohIroZTx1fzC341eyUikgur\nbD3fcQdDCOA7ZvaQme3Po0MiInkhhle4ebcyjHvk+waSR83spQDuMbMfkrx/fYNRUN4PAMnuXWOu\nTkRkc2p55Evy6Oj/EwDuAHDNedrMk5wjOZfM+FOviIjkhbTKHvluea1mNm1ms+d+BvAHAB7Lq2Mi\nIuMannBL3FsZxhl22AvgDjM7t5yvkPx2Lr0SEclFDedwI/kTAL+5uScB8FIxA8MzzbZfW3Hn9Irb\nZrrtz5p7uu2XRDzVDcziu5idO9paDJTzC+SNtpYDuaW9QJvU32FDE0Qn/rZZaPklHB9N/BmFn531\nh7UW1gLv57M73DYzJ/33q3PK308bC85+2g1Max0QmhU8GX8WbgAYBEpKpn4qdS6GJ9yqOearVDMR\nqbVaXuEmIlJldb/CTUSksjSBpohIwUigN6hm8K1mr0REcjAcdhg/z9fMLjOz+8zsCTN73Mw+OG7f\ndOQrIrWW0xVufQAfJvnw6PqGh8zsHpJPbHWBhQZfS4H289mfMv0pf0P1mn6Zx7VJP42s0wykAgXe\nN2sEZgx2UmsiZfjSdmCW5EBpyuaKX3qxEShlGMlfYqDcIZv+bngK/qXpZ2an3Tbpmp/61v65nwc1\nddx/zyeeW3Xb2LLTZhAoscrIzNeBcqSRNEX/zwpN/2WjtRyqWTq2vFLNSB4DcGz086KZHQJwCYDt\nEXxFRIpl0cuH95jZwXW/z5OcP+8SzS4HcDWAB8bpmYKviNRacA63k+5kEADMbAbANwB8iOTCOP1S\n8BWR2hpmO+RTu8HMWhgG3ttIfnPc5Sn4ikht5XWRhQ2L2NwC4BDJz4y9QCjVTERqbjCaPj7rFvB6\nAO8B8CYze2R0e/s4/dKRr4jUVo7ZDt9DqOxXXKHBt9EDpn6e3aY34x+Mr/b9VKDT5qcdrc36Lz8N\nVPeiMzMxMNwJMtfjF9sKzS5rgat5ItXIkjU/FSgyU3J7wW8TqYKFwCSI/TOBNLJAqtTUcb8/k8/5\n1caSpcDKPBN+WiUDMwFHKtlNLATS2gIZYq2zfppic8lP88xLWcXSPTryFZHaIg19BV8RkeKpqpmI\nSMFUTF1EpCQKviIiBVMxdRGRkgTzeAtXaPBNusTs0ew0lLUdkVQpv81y4qforPQDZ0GTQF7WIDDx\nYCd7OYFsNfQn/TbpZGDyQqeyHAC0FwIV1LqRiTjdJqFqWu1AOlqkoluy5vdn4nQgzW4pUvUtUO1u\nMrucHaf9HMT+jJ96GZkcM5KOFnndrbN+Gl5jOYc0vAAS6Fe0mLqOfEWk1jTsICJSMI35ioiUhAq+\nIiLF0wk3EZGCkRrzFREpgSFVtoOISPG27ZivmR0A8A4AJ0heObpvN4CvA7gcwGEAN5B83l1WSrSf\nd/L76Ofn9qb9jdkKlF8cTAZKQU76eY3WCeR8TmfnPjKQT9wP5BN3F/ycz/5UoJRmIK82UoIwIlR0\nKrAqC1QpbPgpqLDA2xkZRmTb386cyH6/+jv9aa3XdgXe804gzzfwuiOzIA96gWl7Bn6f81Dl2g6R\n3f5LAK57wX0fAXAvySsA3Dv6XUSkWjgc9/VuZXCDL8n7AZx6wd3XA7h19POtAN6Zc79ERHKR0zRC\nudvqmO9eksdGPz8DYO9GDc1sP4D9ADAxsXOLqxMR2TxW+ITb2L0iSWTMkkNynuQcybl2y5/aR0Qk\nT9t22GEDx81sHwCM/j+RX5dERPJDmnsrw1aD750Abhr9fBOAb+XTHRGR/AyPbKsZfCOpZl8FcC2A\nPWZ2BMDHAXwSwO1m9j4ATwO4IbQ2Ao1+ds6Qpf53gFAqUKQ7TX9drSk/N2lmetVtc9HUSubjF3eW\n3GVE/HThIrfN8abfxgIzRFtgp20E0r8iaVBpoJzmIHIGI3C40Vv1+9Ob8VdmAz9NjI3sdXV3+uuJ\nlGGNzI4dmZk4bftpZP1ACmejV0yqGVDdVDP3nSV54wYPvTnnvoiI5K6sMV2PrnATkdoiDIOKZjso\n+IpIrVX0wFfBV0RqjNu4toOIyLZW0UNfBV8RqTUd+QJAw5BOZq8y7fiD4wO/8BkGrcDH3YSfszY7\nk50iBgCv2OkWdMMVs89mPv7KiezHo/6n/XK3zf1Lft5W/1Sg8tlZf6eOVCyLpEH1p/z3M7ScQOob\nzX9dNvBTrtKJwPZxmvSm/Q3Y3RFI1Qtsm8gRYqSiYKxyXDGHowQwCFQDLEM1TwOKiOSBGH7CebcA\nMztgZifM7LE8uqbgKyK1lmNthy/hV8vrbpmCr4jUGwO3yGLOX153y3TCTURqrLzaDR4FXxGpt9iR\n7R4zO7ju93mS8xemQ0MKviJSXwQYy3Y4SXLuQndnvUKD76BpWH5pdp5YJJWlNxOYHDOQamYNv027\n6aej7Wz7Vc32tU9nPv5rLT9dbRAYot/V8lPjWi0/36pf5De1wLoi8y2mnXwm9IycCrHAH3S/E5hI\n0llMf8pfRKTNoO3v65Fv55HKZ5E20QyDfFRz2EEn3ESk3nI64TYqr/tfAF5jZkdGJXW3TMMOIlJv\nOV3PkVFed0sUfEWkvs5dZFFBCr4iUmsqpi4iUoaK1nZQ8BWRWjMd+YqIFGwT2QxFKzT4pi1gaV92\ndlskn7MfmMk2MsbOrp+Hubji1+I73pl12xxtZ88Y3ApMyTwI1Gc8seb3ZXXV38iRsoCRNkk3kF+a\n+G9WshLI7W762ycyY3UkATOyD6aR0qcT2f2JlNIcdALbOPK6I4eIkW/woTZFRcR41bKi6chXROpN\nR74iIiXI68LHnCn4ikh9Kc9XRKQcynYQESlDRYOvCuuIiJTAPfI1swMA3gHgBMkrR/d9AsCfAzg3\n5e5HSd7lLYtNoLtr653djGQt0OiMn2q2NPDr9f1fz1/Owlp2ytpT0xe7y2gEvj/9dCE7pQ0AegsT\nbpvJ1UD6VyCNrLnit4nNdhvoz1okHS0wM3HgSCkyjJgGUsB6O52zQTv9jdPq+CVCG4HyqRZ44ZHl\ntBI/bbLR8M+C/dRtEVPVYYfIke+XcP5J4z5L8qrRzQ28IiKFI4aXF3u3ErjBN+9J40RECpVTPd+8\njTPme7OZPTqay97/risiUgKjfyvDVoPvFwC8GsBVAI4B+PRGDc1sv5kdNLOD6dLSFlcnIrJFdTry\nJXmcZEpyAOCLAK7JaDtPco7kXDI9vdV+iohsTZ2Cr5ntW/fruwA8lk93RETyExlyKGvYIZJq9lUA\n12I4r/0RAB8HcK2ZXYXhZ8ZhAO/Pq0OB4l4wP7MmVAWruRyYgTawnP6Sn2p29Ex2etcz0zvdZUTS\nc3qr/nUzyYLf36TrNgldMx9JI2uu+AtqBd6r9Iy/rrTlL4eBS48is2ynkep7U9k7/OxOfzbq2Y6f\nVzkI5MYx0CYJ7IPtQKrZRBL4I87Ldi2mvsGkcbdcgL6IiOSuqnm+urxYROpNwVdEpGAljul6FHxF\npN4UfEVEimcVLaauqmYiIiXQka+I1JuGHYY5vK1Fp00g/S9UgnAQmdE1kNcYKK3YDOUCZ7cZTPhv\nxSAJlHAMlF6M5DeH5r0KfG8KTLgc+lqYrPmNmsuB/vgpzkgnArMg5/S6zJlVeKrt7+xTLb/NWt/f\nv1YDbQapvwEjWbWR8qi50Ak3EZGSKPiKiJRAwVdEpFgGZTuIiBQvx8I6Znadmf3IzJ40s4+M2zUF\nXxGptxxKSppZAuDzAN4G4LUAbjSz147TLQVfEam3fOr5XgPgSZI/IdkF8DUA14/TrULHfBt9oPNc\n9isNjc9EZpcNfKykE4F0NAuU4gusq+mU62NgtmU28pl5N5LOF1lO2g70J1BWMZKblARSxELlSFnc\n2ZfIDMeedODvXCu9VqCN/6e+stZ224TKTiaBEqGBspN5ySnV7BIAP1v3+xEArxtngTrhJiL1Fgu+\ne8zs4Lrf50nOX5gODSn4ikh9MZztcJLkXMbjRwFctu73S0f3bZnGfEWk3vIZ830QwBVm9kozawN4\nN4A7x+mWjnxFpNbyGPMl2TezmwHcDSABcIDk4+MsU8FXROotp3OsJO8CcFc+S1PwFZE6K3FqeE/h\nVc0mFrJHvyNpW4NANbJ+J5AiFkhfGvhZPKHZbr10qlAFrEgqVWQ5Oe2Mg8DrjrwPkeVYoFpbI7J9\nAm1i+0UgzS7wXnA1e2VnFv1cvUYgtasfSDVLu/mcAmo0/f50A23yYFBVMxGRUij4ioiUQcFXRKQE\nCr4iIgXTTBYiIiVR8BURKV5Vi6m7wdfMLgPwZQB7MfwMmSf5OTPbDeDrAC4HcBjADSSfH7dDkcpd\n/YlIqpm/rjSQBpVO+MuJpJq5KXSBT+fIxKEhkapwkYpckZSsSOpgoDpaRCjNLlLRLTD5akSy6rdp\nPZ+9EftrgbJwjUB/B4HUOH8pYMvfyIPA32eRqjrsEEns6wP4MMnXAvgdAB8YFRH+CIB7SV4B4N7R\n7yIi1RGp61BScHaDL8ljJB8e/bwI4BCGtS2vB3DrqNmtAN55oTopIrJlFQ2+mxrzNbPLAVwN4AEA\ne0keGz30DIbDEiIilVGLK9zMbAbANwB8iOSCrZvhgSTNzv8SzWw/gP0A0J7cNV5vRUQ2Ka8x/LyF\nLuY2sxaGgfc2kt8c3X3czPaNHt8H4MT5nktynuQcybnWxEwefRYRidnOY742PMS9BcAhkp9Z99Cd\nAG4a/XwTgG/l3z0RkfHkNXV83iLDDq8H8B4APzCzR0b3fRTAJwHcbmbvA/A0gBsuTBdFRMZQzVEH\nP/iS/B42TgF882ZWxgTozmQfbKf+BKq55eeGykVGclkjeb7J+LM2R2aORU4zE0dKe0a2TWhdOaWF\nRrZhI/C6Gt1ATmzqv7DW2cBMv866IqUrI9svNJt3x39NfefvFwAGbf+NMOfvIU/b/oSbiMi2pOAr\nIlKw+OzFhVPwFZHaqkWer4jItsRqRl8FXxGpNR35iogUTbMXDw2awOrFTmpNTjMKh+rj5SSUTuU9\nHkntCrSxwOuObONIGlmkPxGhUpCRkyaRlKtISl/kryIwm3Kkz8lK9uPNJX/niqwnMuN3bzYw03Qg\nFTRQvRJJYMblvOiEm4hICRR8RUSKRuiEm4hIGXTCTUSkDAq+IiLF0kUWIiJlICtbTL3Q4MsG0Muj\nnnpgW1oaaJNTilPkvW3kULorMvNu6CtWJCUrsGcMWv7KIi+7EanE1o9UGvOXE0mPi8x8HRE54vJm\npG6u+K+7seKvKAlUYYvMIh15ryJpeIWqZuyNzWQhIrJdFVFM3cz+1MweN7OBmc1FnqPgKyL1RQy/\nmnq38T0G4E8A3B99gsZ8RaTeChh2IHkIACxyiemIgq+I1JqyHUREShDMdthjZgfX/T5Pcv6XlmP2\nXQAvO89zP0Zy0xMIK/iKSH3Fq5qdJJl5oozkW/Lo0jnFB19nQ0TShZK1QJtuoC+RghuRiQcDlZ68\nKmGhtLdISlYkNS4ycWhk6Cqy9+Q0EWfkLyjyuiJt0slACt1EPtVaGqvZG6h1xt+AE6cDE3Wu5lB6\nD0CjF0j56/p97q0WE3qGF1lUc9xB2Q4iUm+DwG1MZvYuMzsC4HcB/LuZ3e09R8MOIlJrRRz5krwD\nwB2beY6Cr4jUl2ayEBEpg2o7iIiUo6In3BR8RaS+WN1phNxsBzO7zMzuM7MnRoUjPji6/xNmdtTM\nHhnd3n7huysiskmkfytB5Mi3D+DDJB82s1kAD5nZPaPHPkvyU9GVNVKgvZDdJpKP2ArM6NoKlNmL\nSFt+XmM6EZj1NYc836SX02sKlA7szQTaBMo8Rma7jeT5Dpr+a4/k56Y7/ETyzq5Vt83u2SW3Tavh\nv6lnVrLrV54+Ne0uI53wN3L7TD7lIkN5+Mt+BmvKyBTkOanmqIMffEkeA3Bs9POimR0CcMmF7piI\nSB5sUM1xh01dZGFmlwO4GsADo7tuNrNHzeyAmV2Uc99ERMZDFHKRxVaEg6+ZzQD4BoAPkVwA8AUA\nrwZwFYZHxp/e4Hn7zeygmR3sr/hf1URE8mIgjP6tDKHga2YtDAPvbSS/CQAkj5NMSQ4AfBHANed7\nLsl5knMk55qT/viViEiuKnrCLZLtYABuAXCI5GfW3b9vXbN3YVjJXUSkWioafCPZDq8H8B4APzCz\nR0b3fRTAjWZ2FYajKocBvP+C9FBEZKvOjflWUCTb4Xs4/3y3d212ZdYHOqeyt0Qkjaxzyq8XmSxE\nakr6BpP+51N/ym8zaDtfMkLl/Py9KFRS0usLgN6036Y747fpT/n96U0H0tpmA2ltgTKPkTSyK176\nrNvmNbPH3TY7mytumxPd2czHH5/el/k4ABxuXuy2WWtNuG2aZ/33M5KO1lwOpLWtFVdQsarZDrrC\nTURqrLxhBY+Cr4jUF6HgKyJSimqOOij4iki9VXUaIQVfEak3BV8RkYKRQFrNcYdCg68NiPbZ7A3R\nPu3nsrROnPXXdXrRbcNACkoyNem3mfXbDDrZVZyYRNJ8AqlmvUDZqYB22y811pn2K1N1d/q72Mpu\nf12DQHU5NvwjnJlJf+rry6efc9v89vRht83LmmfcNguT2VXNLm7lc0n+U9zjtunDr47WWvD308TP\n5kMzjUyPnRMd+YqIlEDBV0SkYASgOdxERIpGgBrzFREpFqETbiIipdCYr4hICRR8ASPQcCaBbHT9\nVClb9SuWcWnZb5MG0rICbYIV6bP70g68FZFUsxV/29iqn27VCHxVSzp+alLz7IzbBvBT9bqz/vax\nwISezcR/PyPpXZe1/HS0VzX9fRDInlF2uuG/Vwv97HQ1ADjtTNQJAKeWdrltWouBlMhAQcFIOlo+\nVFhHRKR4BKCSkiIiJdCRr4hI0XR5sYhI8Qiwonm+xc3lISJShgH925jM7B/M7Idm9qiZ3WFm7tlL\nBV8RqbdiZi++B8CVJH8DwP8C+GvvCQq+IlJf5DDbwbuNvRp+h+S5kozfB3Cp95zCx3zp5LsWKvKJ\nFxmsjyzHacPAZrHIR2VgR+Kyn2TJZT9H1Vr+7pMEvtK1ZgP5wit+2clIni8DG7plfi7wtPXcNnsS\nP3+5Zdmva5V+WcpXTfqzLT86dYnb5lRrh9smtJ8G0ucTJ98/V8VnO/wZgK97jXTCTURqjLGLqYA9\nZnZw3e/zJOfXNzCz7wJ42Xme+zGS3xq1+RiAPoDbvBUq+IpIfcVLSp4kOZe5KPItWY+b2XsBvAPA\nm0n/cFvBV0TqrYBUMzO7DsBfAvh9kpHryhV8RaS+CIDFFFP/JwATAO6x4Xmt75P8i6wnKPiKSH2x\nmGLqJH99s89R8BWRWguecCucBcaF81uZ2bMAnl531x4AJwvrQD7U5wtvu/UXUJ8vhFeQfMk4CzCz\nb2P4Oj0nSV43zro2q9Dg+ysrNzvonWGsGvX5wttu/QXUZ9k8XeEmIlICBV8RkRKUHXzn/SaVoz5f\neNutv4D6LJtU6piviMiLVdlHviIiL0qlBV8zu87MfmRmT5rZR8rqx2aY2WEz+4GZPfKCIhyVYWYH\nzOyEmT227r7dZnaPmf149P9FZfZxvQ36+wkzOzrazo+Y2dvL7ON6ZnaZmd1nZk+Y2eNm9sHR/VXe\nxhv1ubLb+cWglGEHM0swLDj8VgBHADwI4EaSTxTemU0ws8MA5khWNjfSzH4PwFkAXyZ55ei+vwdw\niuQnRx90F5H8qzL7ec4G/f0EgLMkP1Vm387HzPYB2EfyYTObBfAQgHcCeC+qu4036vMNqOh2fjEo\n68j3GgBPkvwJyS6ArwG4vqS+1ArJ+wGcesHd1wO4dfTzrRj+4VXCBv2tLJLHSD48+nkRwCEAl6Da\n23ijPkuJygq+lwD42brfj2B77AwE8B0ze8jM9pfdmU3YS/LY6OdnAOwtszNBN4/mwzpQpa/w65nZ\n5QCuBvAAtsk2fkGfgW2wnetKJ9w25w0kfwvA2wB8YPSVeVsZ1RmteorLFwC8GsBVAI4B+HS53flV\nZjYD4BsAPkRyYf1jVd3G5+lz5bdznZUVfI8CuGzd75eO7qs0kkdH/58AcAeGwyfbwfHRuN+58b8T\nJfcnE8njJFMO5/z+Iiq2nc2shWEQu43kN0d3V3obn6/PVd/OdVdW8H0QwBVm9kozawN4N4A7S+pL\niJlNj05WwMymAfwBgMeyn1UZdwK4afTzTQC+VWJfXOeC2Mi7UKHtbMNirbcAOETyM+sequw23qjP\nVd7OLwalXWQxSmv5RwAJgAMk/7aUjgSZ2aswPNoFhqU4v1LFPpvZVwFci2Elp+MAPg7gXwHcDuDl\nGFaVu4FkJU5ybdDfazH8KkwAhwG8f914aqnM7A0A/hPADwCcKxT7UQzHUKu6jTfq842o6HZ+MdAV\nbiIiJdAJNxGREij4ioiUQMFXRKQECr4iIiVQ8BURKYGCr4hICRR8RURKoOArIlKC/wd4uUuwE05V\n4QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FrGMBAwEP8e",
        "colab_type": "text"
      },
      "source": [
        "#### Smooth random b\n",
        "Smooth random b image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CadvEVzeEM7F",
        "colab_type": "code",
        "outputId": "22fe5331-4322-49e1-f8c7-2b678caf286d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Random 4D matrix (unsmoothed)\n",
        "b_us = np.random.randn(nv*q).reshape(dimv[0],dimv[1],dimv[2],q)*20\n",
        "\n",
        "# Some random affine, not important for this simulation\n",
        "affine = np.diag([1, 1, 1, 1])\n",
        "b_us_nii = nib.Nifti1Image(b_us, affine)\n",
        "\n",
        "# Smoothed beta nifti\n",
        "b_s_nii = nilearn.image.smooth_img(b_us_nii, 5)\n",
        "\n",
        "# Final beta\n",
        "b = b_s_nii.get_fdata()\n",
        "\n",
        "# Show unsmoothed\n",
        "imshow(b_us[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8ed73d9b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD5CAYAAAA+0W6bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCNew36kESqR",
        "colab_type": "code",
        "outputId": "4b51ee50-6b05-47e0-b3cc-01c06efb13ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Show smoothed\n",
        "imshow(b[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8ed7336320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD5CAYAAAA+0W6bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbsElEQVR4nO3dW4ik93nn8d9Tbx27+jgHjUcny3Zk\nlqwhcnYQCzGLlpDgDQHZNyK6CFoIK1/EbAy5WONc2DcBs8ROcrEY5LWIAo4Ts7bXuvBu4jUBJxCM\nxkZYsrUbG2UkzXlGc+pjHZ+96NLuWOmafp7pk/7t7weEemqefvv/1lv1dE31r5+/ubsAAOWpHfQC\nAAB3hwYOAIWigQNAoWjgAFAoGjgAFIoGDgCFqu/kk83sw5L+VFIl6b+6+2fvVF/Ndb1+dCl28Fo8\n3livj8O1lcVrJcndwrXDcfz74ThRq0TSs1bFz69ZH8UPLKldG4RrLX63aTCuwrX9Ubx2lLh2mfVK\n+cdR1Mjjj4vhIH5fWD9+grVhuHRT5q5I3M+JyyfLPEcS51fr5a6z9fvhWh/Gn3/Lun7V3Y+//fa7\nbuBmVkn6L5J+TdJZSS+Y2fPu/uNpn1M/uqR3/cF/DB2/mos3i2OLK+HaxfZ6uFaSNoaNcO3VlW64\ndm2lFV9E4sHZme2Fa99z9Fr8wJJ+Ye5KuLaVeJacW18M155didcu95rh2kbiG58kzbXi93Om2d/Y\n6IRrL12M3xets/HHcedy7rtZtRF/gI7jy9CoGV9H1Y+voXM1fj3mzqyFayWp9k/nw7Wjq2+Ga/+X\n/7fXtvx64SP8c49K+qm7v+rufUl/KenxHRwPAJCwkwZ+n6Q3bvvz2cltAIB9sOc/xDSzp83stJmd\nHi2v7vWXA4CfGztp4OckPXDbn++f3PYz3P0Zdz/l7qequfh7xACAO9tJA39B0sNm9h4za0r6LUnP\n786yAADbuesUirsPzezjkv5amzHCZ939R3f8pJGpWolFnzIBt2sWf2W/spFIf0jq9+NRrcFKPPVg\nq/G7PpNYW9uIr/cnw3itJL25PhOubVXxK9hLRAM3+vEYQ62WSBskUiWSdHLmZri2U8UTVc1qIVx7\nbSZ+PcbN+P2Wie9tfsIe1SbWMa7Hi0etRDR4NhGbkdRcil+/1LNvSgBsRzlwd/+WpG/t5BgAgLvD\nb2ICQKFo4ABQKBo4ABSKBg4AhaKBA0ChaOAAUKgdxQizbCw1lmPfM2yYyGoO4t+HBokxtZJU24gf\nu7USX3N9LTHqNJEDH7US98X13OW/NBuflOfNxKIb8dp6K54vX1qIj2440VkO10rSv+heCtcu1OMT\n7WareB79XHc+XHuzEc+MZ2frZka5ZngiKD1K/HpHLzGytzaM/26HJI2r4LhsSY2js/EDT8mB8woc\nAApFAweAQtHAAaBQNHAAKBQNHAAKRQMHgELta4xQLllwr9tEmko2in8fstxG7Km4XyO+t7KqXjx7\nlYlpjRqJjWDXc3Gx0Wo81zWcSeyu3o3HCMf1eG0zMdL2ROtWuFaS3t26Gq7t1uIP5pvDeNyvWY+f\nX3pEbMYejYjNRAOH3fgiBon0Xn8u9xp3/Vh80VVi0239w9Y38wocAApFAweAQtHAAaBQNHAAKBQN\nHAAKRQMHgELta4zQK6m/GIyBJXJPtUQ0sLaRy1NV/XhtJqKYGIimcS2+5nEimTTObbitcSMe1crU\neiseDWy1gzlUSfOtjXDtbD23K32l+Jr7ibF6K4nsXH8YP24mipqNHHqii4za8YMP5hLRwKX4k8/a\n8dr+OHdnrPUzkeadZzt5BQ4AhaKBA0ChaOAAUCgaOAAUigYOAIWigQNAoXYUIzSzM5KWJY0kDd39\n1B3rm2PV7o9t8DrsxZc2Xk7k4ca571mWiBFlpqeNm5njxuNUmdpxO7HxsCR14vGrRmcQrp3rxLOa\nx2b3ZqPiUSbXKen8IL557UYir/n6+pH4cfuJx30iRpiJokrSILEJcn8ucdzF+OOte0/icTEff1x0\nG4kccdI4kdd8bcrtu5ED/7fuHp+tCQDYFbyFAgCF2mkDd0l/Y2bfN7Ond2NBAICYnb6F8iF3P2dm\n90j6tpn9b3f/7u0Fk8b+tCTVjy3s8MsBAN6yo1fg7n5u8v/Lkr4h6dEtap5x91Pufqqa7+7kywEA\nbnPXDdzMumY299bHkn5d0su7tTAAwJ3t5C2UE5K+YZsRorqkv3D3/7krqwIAbOuuG7i7vyrplzKf\n02oM9f53XQnVXlqJB0bftPg200PPzVAddRKjXDvxXHU1F89Jz3TjY1G7rXhudaYRX4MkLTTXE7Xx\nNc/V47WtWnycbEZmjKskXenHH3PX+/Gd5s+vxH9O1NuIB7YzMfdhJ14rSdaO1w4W4s+R+kL8sXz/\n4o1w7b9cuBCuva8VP64kzdTiY4lriRm//2PaMcJHAAC8o9DAAaBQNHAAKBQNHAAKRQMHgELRwAGg\nUPu6K33DRjrZuRWqXR/G4363WvEcU382txN0rRmPPR1fXAnXvn8pFqeUpPs68SjTQhWP+rVryRhh\nFRsFLEmLidqGxaOBN0bxSN7r/WPh2n9cvSdcK0lvrMTHyd5Yi+fyVtfj0cBRL7ErfT0eWRvOJmbP\nSvIqMe54IX6tl2bjj+Vj7fg42aONxOjZxs1wrSTN1eJrblp8XO40vAIHgELRwAGgUDRwACgUDRwA\nCkUDB4BC0cABoFD7GiOUpGFwLFpmx+aqikf9Gu3cNLu5RJQpEw38pfk3wrX3NuIxwkwkr225GOHR\nKh6TPJ6IMzYSW6afT8QILw3jk/1uJCYGStLlW/FphGu3MuP6Eq+pxvHniDcTMcJmMt6WiNq2ZuPT\n+mYTkzUzbo7isc7zg8XUsedq8WvdIEYIAD+/aOAAUCgaOAAUigYOAIWigQNAoWjgAFCofY0RjmXq\njXb/S2ZihJbYSFSS2o14LC8Tfbw6iG/a3BvHJzNmoklL9fhUNknqJjZsnbH4NMK5Wnyq3prH15C5\nL3rD3OMys6Gw1hNTA0eJaGAj8Vhuxe+LKlErSe12PI46245fv049fty1xPTS19aOhGsv1ObDtZLU\nqeJr3o0NunkFDgCFooEDQKFo4ABQKBo4ABSKBg4AhaKBA0ChaOAAUKhtw69m9qyk35R02d0/MLnt\niKS/kvSQpDOSnnD369sdqyZXtx4bEdltxEdJrjRa4dqNQS7vu7IRP/ZPhsfDta/ePJpaR1Szimd4\n75+Nj6mVpN5iPGt7vIpnzNuJvHZN8Zx0Jgde1eK/SyDlf59gTyTWUGvEz6/TyY1xne9shGvnmvEc\neLuK56T74/jzenUQf05nterxNc8Ee+GdRF6B/5mkD7/ttk9K+o67PyzpO5M/AwD20bYN3N2/K+na\n225+XNJzk4+fk/SRXV4XAGAbd/se+Al3vzD5+KKkE9MKzexpMzttZqc3bsT/qQUAuLMd/xDT3V2a\nvieWuz/j7qfc/VR7MbG1FADgju62gV8ys5OSNPn/5d1bEgAg4m4b+POSnpp8/JSkb+7OcgAAUZEY\n4VckPSbpmJmdlfRpSZ+V9FUz+x1Jr0l6IvLFmrWh7m3HomuZ0ayrg/hoz7VePAonSasr8bd9fC0e\nZarW4t87bRi/L0adeFzs4j3xkbbS5jjgqIVEjHDcOheu3fD4fTz2+H0824jH2ySpnYjarWzE1+z9\nxGuqd8hvcVSJOGMmGpiJ2WUemxuW6wEZ7cQI3Mzo2Wm2fWS5+5NT/upXd/zVAQB37R3yPRwAkEUD\nB4BC0cABoFA0cAAoFA0cAAq1r7vS122sY/WVUG1mwmCzthiuHQziO4RLkl2PRxQ7l+LfD9vXEpPk\nEmmj/lxih/f1bvzAkn5Yvzdc263iEbCbc/F1tBJ3xrVh/Lh1y00j7Lbi59frxGNrAyUibol46bgX\nf1ys1+KPeUlqJCZgziamES4lIoeZx1utFb/WmYmWUi4a2M48safgFTgAFIoGDgCFooEDQKFo4ABQ\nKBo4ABSKBg4AhdrXGGFGLTHhLDOJbJSMEdZX4sduvxlf88yVeJSp6sdr6+vx8xs3ct+/V7vxWN4L\n9QfCtZc24lMRF5vr4dphYhrhrf7ebTZS1ePXb5DZLHmUmGjZi9eOMhMRJd1KTA5t1uOxvPlmfAev\nY81YPFmSlupr4dq5KreL2EwtsWkzMUIA+PlFAweAQtHAAaBQNHAAKBQNHAAKRQMHgELRwAGgUPua\nAx/LwruKDzyRZ07kUD1Ru/kJ8dJMhDe1BIuvOTMVtR6PVEuSmtfi3++Xq3i2+5WVeAa72YqPGK2q\n+J1Rq+XGyY4SGezUCONB/LjVWqJ2I/m4TxgkcuNXE8etJ65JZoxrqxZ/DGVz4FVyLPFO8QocAApF\nAweAQtHAAaBQNHAAKBQNHAAKRQMHgEJtm+kzs2cl/aaky+7+gcltn5H0HyRdmZR9yt2/td2x3E2D\ncSxGWCkRIarHI0TNdm6E42A2vkN3bynz/TBem5k6OU5sah68FP9PJorWfDMenRutxGt7zXhW05uJ\nSFcjGf/KXOpB/H6rrcbvi8ZyfBGN5XCpkhuxp0Yu9watcO350WK4tj+K32/L8/E13GjPhGslaT6R\nzc3EGaeJPAL+TNKHt7j9j939kcl/2zZvAMDu2raBu/t3JV3bh7UAABJ28h74x83sh2b2rJkt7dqK\nAAAhd9vAvyDpfZIekXRB0uemFZrZ02Z22sxOr17v3+WXAwC83V01cHe/5O4jdx9L+qKkR+9Q+4y7\nn3L3U92l+A8EAQB3dlcN3MxO3vbHj0p6eXeWAwCIisQIvyLpMUnHzOyspE9LeszMHtHmrL4zkj4W\n+WI18/BOzPP1+BSwk51b4dqVxXiESJLODuPxpNVafKpefz4evcrE97IRsJTEtMX6aub84scdN+LH\nHbXiteN27rVMZqhlrR8vbizHa1vX42to3YhfvKqfG6uZuZ/rG/H7eX0Yf65eSUxxXO/Hs7ZXu7Ph\nWkmaacTfJs5MW5x6jO0K3P3JLW7+0o6/MgBgR/hNTAAoFA0cAApFAweAQtHAAaBQNHAAKBQNHAAK\nta+70lca6Uh9JVS7UK2Fj7tQj9dmxj1K0myzF659YyY+/nL5Vidc21+LX6ZqNbFT+Xpup/JMfWZS\npiVix554yZE5u2x+3saJbHciE9+8GV9D+1pi5PKb8ROsr+fGnI5a8d+VqA3jj+VxFb/Y4yqe7V6x\n+IjYwSB+bpLUbMbvuyrzwJ+CV+AAUCgaOAAUigYOAIWigQNAoWjgAFAoGjgAFGpfY4QNG+l4PTb6\ntWvxsYwNi0d3Hm5dDNdK0kPtN8O1L8/cG6796ezxcO2lW3Ph2tUb8XiiW+7yW2r6ZWbearx01I5H\nr0atxA729Vykq5bYXMpGidG6vfg6Guvx2kw0sJaMESrxuKj6ichhbPL0Zm0iBjpKrHeciItu1ice\nzLswTpZX4ABQKBo4ABSKBg4AhaKBA0ChaOAAUCgaOAAUan+nEdpYR2urodojia3KF1PfhnLTCO+r\n4uPhopMWJWm+Hj+/l2rxeOIbiTTc2jA+lU2ShuNEBCw+HC41YXDUiUevPFGrWi5GOLb4fTFuxI89\nbsRja8PEbvCDmcREy3rudd2wE78v+rPxYw+7iTV049e6MRvPgB6Zj086laS5Vnx6aSORffzRlNt5\nBQ4AhaKBA0ChaOAAUCgaOAAUigYOAIWigQNAobbNFpnZA5L+XNIJSS7pGXf/UzM7IumvJD0k6Yyk\nJ9z9+p2OVZNrJjhibCax4eesNcO1jUT8S5Ia9XgsaKQL4dqBx9exPoqf38Ywnt8738+lSAceX8d4\nEH9t4FUiwteOR6+qVnKn4oRRYkrdqB2/Lwaz8TXUhok1NOPXOjd1UhrGB2CqdyS+5o1j8YXUjsaf\np/ceiU1ElaSHF66EayXp3Z349NKFKh5p/uspt0ceWUNJv+/uvyjpX0v6XTP7RUmflPQdd39Y0ncm\nfwYA7JNtG7i7X3D3H0w+Xpb0iqT7JD0u6blJ2XOSPrJXiwQA/HOp98DN7CFJH5T0PUkn3P2t9wwu\navMtFgDAPgk3cDOblfQ1SZ9w9595E8ndXZvvj2/1eU+b2WkzO33j2s53oAAAbAo1cDNraLN5f9nd\nvz65+ZKZnZz8/UlJl7f6XHd/xt1PufupxSOEXgBgt2zbUc3MJH1J0ivu/vnb/up5SU9NPn5K0jd3\nf3kAgGki2aJfkfTbkl4ysxcnt31K0mclfdXMfkfSa5Ke2JslAgC2sm0Dd/e/1/Qtxn91d5fz/yU2\n59bNcWYH+9wu0wNP7BKeCNAeqeKjZ+9t3QjXXp6JB4lvbbTCtZJ0cxR/C2yc2H3cEqNc6634jumN\nZrx2lDg3SRo34uc3asXPLzfhNzFONjGaNfvrfaPEw6g/nxituxi/fkfm4mNfH5y7Fq79V3NnwrWS\n9Ej79XDtvfV4DvwTU27nTWkAKBQNHAAKRQMHgELRwAGgUDRwACgUDRwACrWvu9K7TIPgFuRXxvEZ\nlX3FI12ZMa5Zo8T26gOP3/Xt4AheSerW45HKTjN+XElaqcfHs/ooHnHLxAgztRnjxHhYKXd+mSUn\nHhYadeIHHiVGvmafIolpxxp144+hWjNe20w8NmcTz5Ej9XjcV5LuT0QD768nZgdPwStwACgUDRwA\nCkUDB4BC0cABoFA0cAAoFA0cAAq1rzHCsUyrwZ3Nr43iEZtzg6Vw7c3cuDdViQmDrUTcL+PaMD5K\nbn0U35V+MMrlxcbjxE7zw0RtImeXGRroiWjgcJDMzvXjC7FBIlKZ2LQqE/fL1I7ruajmOP6Qy71k\nTCyjP4yfYOY5sjbOTexcTjxHVsYbqWNvhVfgAFAoGjgAFIoGDgCFooEDQKFo4ABQKBo4ABRqX2OE\nfa/rjcHRUO3Z/pHwcV9dPxauvTlIjGWTVE/kuuYb8VhQpxafiHZrGF/zjV68dr2fyX/lNirWMDHd\nL7HRdGZo4LgWL/ZeLkZY68Vf+9Tie/OmonOZyYXjRmIz4UTt5joS9RavdU88LhLxveVBPBp4vh+P\nKEvSTxKbla95fLPyaXgFDgCFooEDQKFo4ABQKBo4ABSKBg4AhaKBA0Chtm3gZvaAmf2tmf3YzH5k\nZr83uf0zZnbOzF6c/Pcbe79cAMBbIknSoaTfd/cfmNmcpO+b2bcnf/fH7v5H0S+2OmrpH279Qqj2\n4sZc9LC6uDofru0Nc9H3Vj0e4j3WWQ3Xzjfju1f3x/E1D8bJsagZme3VM/+2S2SDUzKh8cQu85JS\neW1lsuuZbHcrke3uJObUNhK1kqzKPC7itfVGfKd5SzyG1oaxkdaSdL63GK6VpEYi9H9lGO9b0utb\n3rrtw8XdL0i6MPl42cxekXRf4isDAPZA6j1wM3tI0gclfW9y08fN7Idm9qyZ5X5lCQCwI+EGbmaz\nkr4m6RPufkvSFyS9T9Ij2nyF/rkpn/e0mZ02s9Pr13e+AwUAYFOogZtZQ5vN+8vu/nVJcvdL7j5y\n97GkL0p6dKvPdfdn3P2Uu5/qLLV3a90A8HMvkkIxSV+S9Iq7f/6220/eVvZRSS/v/vIAANNEfub9\nK5J+W9JLZvbi5LZPSXrSzB7R5s/jz0j62J6sEACwpUgK5e+1dRDqW9kvttxv6e/OvTdUu9FL7K7e\n27upuK1OfKf5WiLK1KzicaN2FV/DUmstXJvdlT4T1eolrt84sdV8Jr03HiZ+Rp+NMqaigYm4XzMx\nbrUbj9k1uvHxxa1WZv5t7nGRGfuaMUoc91Yv/lbu67VcNiOz43233ksdeyv8JiYAFIoGDgCFooED\nQKFo4ABQKBo4ABSKBg4AhdrXXenH/Uor/7QQqrV4QkpVYupcJqYlSRsL8WOvd+IRomYtfoIPdq6H\nayuLT5K7fya3K/bFjfj0tDc3uuHalX58OtxqL167thbffXxkuUhlYsP01LPME1MDOwvx0RT3zMd3\nS59v5UZe9BNx1JuJCN/yerx2fSP+3MvU3kysQZKutOOP+5lGPB48Da/AAaBQNHAAKBQNHAAKRQMH\ngELRwAGgUDRwACjUvsYIa32pezb2PSMT0xrHU0EazsRrJanfikekRok442Ijvqnx+9sXwrXvqt8M\n12544o6T9EbnaLj2zMaxcO1ra0fCtecsFkOVpI1EXGyUHUaY2PfXM0MRm/F46UI3/hh6cO5auPZI\nMz7RUpJuDjrh2rVBPAbaT0wZHdyMR0ZtEH+eDhq5B8babHwdzeTUx63wChwACkUDB4BC0cABoFA0\ncAAoFA0cAApFAweAQtHAAaBQ+5sDH0mt67Fc5TixsmEnnuv0KjMHVLJhrj4qsyP1g414hve9jVvh\n2kEy+zxfy40ZjVofxbPB13vxIH+tljjB1HzY3LjjzA72quJrnm3Gd5o/3oyPk11q5HLgw3FuFG/4\nuIkceLUcX0OV2Aw+8zsmkjRM/H7ARmfnr595BQ4AhaKBA0ChaOAAUCgaOAAUigYOAIWigQNAocw9\nmSXbyRczuyLptS3+6pikq/u2kP11mM9N4vxKx/mV4d3ufvztN+5rA5/GzE67+6mDXsdeOMznJnF+\npeP8ysZbKABQKBo4ABTqndLAnznoBeyhw3xuEudXOs6vYO+I98ABAHnvlFfgAICkA23gZvZhM/s/\nZvZTM/vkQa5lL5jZGTN7ycxeNLPTB72enTKzZ83sspm9fNttR8zs22b2k8n/lw5yjTsx5fw+Y2bn\nJtfwRTP7jYNc490yswfM7G/N7Mdm9iMz+73J7Yfi+t3h/A7F9ZvmwN5CMbNK0j9K+jVJZyW9IOlJ\nd//xgSxoD5jZGUmn3P0w5FBlZv9G0oqkP3f3D0xu+8+Srrn7ZyffhJfc/T8d5Drv1pTz+4ykFXf/\no4Nc206Z2UlJJ939B2Y2J+n7kj4i6d/rEFy/O5zfEzoE12+ag3wF/qikn7r7q+7el/SXkh4/wPVg\nG+7+XUlvH07+uKTnJh8/p80nTZGmnN+h4O4X3P0Hk4+XJb0i6T4dkut3h/M71A6ygd8n6Y3b/nxW\nh+8Od0l/Y2bfN7OnD3oxe+SEu1+YfHxR0omDXMwe+biZ/XDyFkuRbzHczswekvRBSd/TIbx+bzs/\n6ZBdv9vxQ8y99SF3/2VJ/07S707+iX5o+eb7cYct1vQFSe+T9IikC5I+d7DL2Rkzm5X0NUmfcPef\n2b7pMFy/Lc7vUF2/tzvIBn5O0gO3/fn+yW2Hhrufm/z/sqRvaPNto8Pm0uT9x7feh7x8wOvZVe5+\nyd1H7j6W9EUVfA3NrKHN5vZld//65OZDc/22Or/DdP22cpAN/AVJD5vZe8ysKem3JD1/gOvZVWbW\nnfwwRWbWlfTrkl6+82cV6XlJT00+fkrSNw9wLbvureY28VEVeg3NzCR9SdIr7v752/7qUFy/aed3\nWK7fNAf6izyTSM+fSKokPevuf3hgi9llZvZebb7qljY3j/6L0s/PzL4i6TFtTni7JOnTkv67pK9K\nelCbkyafcPcifxA45fwe0+Y/v13SGUkfu+0942KY2Yck/Z2klyS9tfXup7T5PnHx1+8O5/ekDsH1\nm4bfxASAQvFDTAAoFA0cAApFAweAQtHAAaBQNHAAKBQNHAAKRQMHgELRwAGgUP8XQ/HgSINoqRgA\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5n048xZEW-d",
        "colab_type": "text"
      },
      "source": [
        " #### Y vector (New response)\n",
        " \n",
        "Generate response for the whole field."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jadlKZcEUxx",
        "colab_type": "code",
        "outputId": "78567b0b-a522-4705-cf2d-7e87b9665135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "# Reshape X\n",
        "X = X.reshape(1, X.shape[0], X.shape[1])\n",
        "\n",
        "# Reshape beta\n",
        "beta = beta.reshape(beta.shape[0]*beta.shape[1]*beta.shape[2],beta.shape[3],1)\n",
        "beta_True = beta\n",
        "\n",
        "# Reshape Z (note: This step is slow because of the sparse to dense conversion;\n",
        "# it could probably be made quicker but this is only for one simulation at current)\n",
        "Ztmp = Z.toarray().reshape(1, Z.shape[0], Z.shape[1])\n",
        "\n",
        "# Reshape b\n",
        "b = b.reshape(b.shape[0]*b.shape[1]*b.shape[2],b.shape[3],1)\n",
        "\n",
        "print(X.shape)\n",
        "print(Ztmp.shape)\n",
        "print(beta.shape)\n",
        "print(b.shape)\n",
        "\n",
        "# Generate Y\n",
        "Y = np.matmul(X,beta)+np.matmul(Ztmp,b) + np.random.randn(n,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1000, 11)\n",
            "(1, 1000, 53)\n",
            "(27000, 11, 1)\n",
            "(27000, 53, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V1oJXx2EcEX",
        "colab_type": "text"
      },
      "source": [
        "Check Y looks reasonable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk8lqtsbEZ1J",
        "colab_type": "code",
        "outputId": "89ed92e4-3749-4d05-893d-c82e0361a3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "print(Y.shape)\n",
        "\n",
        "Y_imageformat = Y.reshape((dimv[0],dimv[1],dimv[2],n))\n",
        "\n",
        "imshow(Y_imageformat[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27000, 1000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8ed7310c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD5CAYAAAA+0W6bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFIoCDgCFooADQKEo4ABQqP8BWgrGsERx+RsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N-oRTM1EhCb",
        "colab_type": "text"
      },
      "source": [
        "#### Transpose products\n",
        "\n",
        "Calculate X'Y, X'Z, X'Y, Y'Y, Y'Z, Y'X Z'Z, Z'X and Z'Y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px75KQpHEe7u",
        "colab_type": "code",
        "outputId": "b0a367c3-f0a3-4d3e-8bf3-0e8ccc4ba55f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# X'Z\\Z'X\n",
        "XtZ = np.matmul(X.transpose(0,2,1),Ztmp)\n",
        "ZtX = XtZ.transpose(0,2,1)\n",
        "\n",
        "# Z'Y\\Y'Z\n",
        "YtZ = np.matmul(Y.transpose(0,2,1),Ztmp)\n",
        "ZtY = YtZ.transpose(0,2,1)\n",
        "\n",
        "# Y'X/X'Y\n",
        "YtX = np.matmul(Y.transpose(0,2,1),X)\n",
        "XtY = YtX.transpose(0,2,1)\n",
        "\n",
        "# YtY\n",
        "YtY = np.matmul(Y.transpose(0,2,1),Y)\n",
        "\n",
        "# ZtZ\n",
        "ZtZ = np.matmul(Ztmp.transpose(0,2,1),Ztmp)\n",
        "\n",
        "# X'X\n",
        "XtX = np.matmul(X.transpose(0,2,1),X)\n",
        "\n",
        "\n",
        "print(XtZ.shape)\n",
        "print(ZtX.shape)\n",
        "\n",
        "print(XtY.shape)\n",
        "print(YtX.shape)\n",
        "\n",
        "print(YtZ.shape)\n",
        "print(ZtY.shape)\n",
        "\n",
        "print(XtX.shape)\n",
        "\n",
        "print(YtY.shape)\n",
        "\n",
        "print(ZtZ.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 11, 53)\n",
            "(1, 53, 11)\n",
            "(27000, 11, 1)\n",
            "(27000, 1, 11)\n",
            "(27000, 1, 53)\n",
            "(27000, 53, 1)\n",
            "(1, 11, 11)\n",
            "(27000, 1, 1)\n",
            "(1, 53, 53)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUHZxjFvEmih",
        "colab_type": "text"
      },
      "source": [
        "### Demonstration: Time taken just looping\n",
        "\n",
        "This is a demonstration showing how long FS takes when doing each voxel seperately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TokOi5r2Ej2T",
        "colab_type": "code",
        "outputId": "0e88381c-ae52-4523-9baa-e01275a8cb9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Initialize empty estimates\n",
        "beta_est = np.zeros(beta.shape)\n",
        "print(beta.shape)\n",
        "\n",
        "demo = False\n",
        "if demo:\n",
        "  \n",
        "  # Initialize temporary X'X, X'Z, Z'X and Z'Z\n",
        "  XtZtmp = XtZ[0,:,:]\n",
        "  ZtXtmp = ZtX[0,:,:]\n",
        "  ZtZtmp = ZtZ[0,:,:]\n",
        "  XtXtmp = XtX[0,:,:]\n",
        "\n",
        "  print(type(ZtZ))\n",
        "\n",
        "  t1 = time.time()\n",
        "  for i in np.arange(beta.shape[0]):\n",
        "\n",
        "    print(i)\n",
        "\n",
        "    XtYtmp = XtY[i,:,:]\n",
        "    ZtYtmp = ZtY[i,:,:] \n",
        "    YtYtmp = YtY[i,:,:] \n",
        "    YtZtmp = YtZ[i,:,:]\n",
        "    YtXtmp = YtX[i,:,:]\n",
        "\n",
        "    param_est,bvals = FS(XtXtmp, XtYtmp, ZtXtmp, ZtYtmp, ZtZtmp, XtZtmp, YtZtmp, YtYtmp, YtXtmp, nlevels, nparams, 1e-6, n)\n",
        "\n",
        "    # Get current beta\n",
        "    beta_est[i,:,:] = param_est[0:beta.shape[1]]\n",
        "\n",
        "  t2 = time.time()\n",
        "  print(\"Time taken in seconds for this example:\")\n",
        "  print(t2-t1)\n",
        "  print(\"Estimated time taken for this example on a nifti of size (100x100x100), in hours:\")\n",
        "  print(100*100*100*(t2-t1)/(nv*60*60))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27000, 11, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJnJ524uFbV1",
        "colab_type": "code",
        "outputId": "cf66d388-da76-4660-9123-3a6212c0ea26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "print(\"True beta (3)\")\n",
        "beta_map=beta.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "beta_est_map=beta_est.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "# Show true beta, 3rd x-slice, 3rd parameter\n",
        "imshow(beta_map[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True beta (3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f8ed72a7e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAD5CAYAAACAhzbGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIodupfkRONO",
        "colab_type": "code",
        "outputId": "46f166b7-bc3b-4ef8-f09f-663c46220a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print(\"Estimated beta (3)\")\n",
        "\n",
        "# Show estimated beta, 3rd x-slice, 3rd parameter\n",
        "imshow(beta_est_map[3,:,:,3].reshape(dimv[0],dimv[1]), vmin=-3, vmax=3, \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated beta (3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f8ed76055f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAD8CAYAAADQSqd1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJxbStAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUapPX6JdyPG",
        "colab_type": "text"
      },
      "source": [
        "**Note:** Result is roughly similar... but lots of local minima disrupting the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3pBWlFqeRZx",
        "colab_type": "text"
      },
      "source": [
        "### Scaled up Helper Functions\n",
        "\n",
        "This section contains the Nifti-equivalent functions to those given *helper functions* for an individual voxel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlYTkC9Qgg3l",
        "colab_type": "text"
      },
      "source": [
        "#### Initial beta (broadcasted)\n",
        "\n",
        "The below function returns the OLS estimator for several voxels at once, where the OLS estimator for a given voxel, $\\hat{\\beta}$, is given by:\n",
        "\n",
        "$$\\hat{\\beta}_{OLS}=(X'X)^{-1}X'Y$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `XtX`: The design matrices transposed and multiplied by themselves ($X'X$ in the above notation)\n",
        " - `XtY`: The design matrices transposed and multiplied by the response vectors ($X'Y$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `beta`: The OLS estimates of $\\beta$ ($\\hat{\\beta}_{OLS}$ in the above notation).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QDdV-iTggJz",
        "colab_type": "code",
        "outputId": "efd5a2c4-dc6b-4bb6-cf9d-e0fbb0b08491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def initBeta_broadcasted(XtX, XtY):\n",
        "  \n",
        "  # Get the beta estimator\n",
        "  beta = np.linalg.solve(XtX,XtY)\n",
        "  \n",
        "  # Return the result\n",
        "  return(beta)\n",
        "\n",
        "print(initBeta(XtX,XtY))\n",
        "print(np.linalg.inv(XtX) @ XtY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-0.84343553]\n",
            "  [ 0.12088461]\n",
            "  [ 0.71867051]\n",
            "  ...\n",
            "  [ 2.8935947 ]\n",
            "  [-0.67459789]\n",
            "  [-3.08122112]]\n",
            "\n",
            " [[-1.15673532]\n",
            "  [ 0.19642787]\n",
            "  [ 0.02968513]\n",
            "  ...\n",
            "  [ 2.36591741]\n",
            "  [-1.12653006]\n",
            "  [-3.83697017]]\n",
            "\n",
            " [[-1.51847724]\n",
            "  [ 0.36027867]\n",
            "  [-1.05392769]\n",
            "  ...\n",
            "  [ 1.65868609]\n",
            "  [-1.6253267 ]\n",
            "  [-4.65289381]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.3159518 ]\n",
            "  [-4.31100121]\n",
            "  [-0.08756585]\n",
            "  ...\n",
            "  [ 3.92723822]\n",
            "  [ 1.89555932]\n",
            "  [ 2.2944746 ]]\n",
            "\n",
            " [[ 0.5566827 ]\n",
            "  [-4.47989404]\n",
            "  [ 0.02129297]\n",
            "  ...\n",
            "  [ 3.65367182]\n",
            "  [ 2.48438265]\n",
            "  [ 1.54267973]]\n",
            "\n",
            " [[ 0.77725834]\n",
            "  [-4.48429482]\n",
            "  [ 0.08583648]\n",
            "  ...\n",
            "  [ 3.34941247]\n",
            "  [ 2.76242843]\n",
            "  [ 0.91854611]]]\n",
            "[[[-0.84343553]\n",
            "  [ 0.12088461]\n",
            "  [ 0.71867051]\n",
            "  ...\n",
            "  [ 2.8935947 ]\n",
            "  [-0.67459789]\n",
            "  [-3.08122112]]\n",
            "\n",
            " [[-1.15673532]\n",
            "  [ 0.19642787]\n",
            "  [ 0.02968513]\n",
            "  ...\n",
            "  [ 2.36591741]\n",
            "  [-1.12653006]\n",
            "  [-3.83697017]]\n",
            "\n",
            " [[-1.51847724]\n",
            "  [ 0.36027867]\n",
            "  [-1.05392769]\n",
            "  ...\n",
            "  [ 1.65868609]\n",
            "  [-1.6253267 ]\n",
            "  [-4.65289381]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.3159518 ]\n",
            "  [-4.31100121]\n",
            "  [-0.08756585]\n",
            "  ...\n",
            "  [ 3.92723822]\n",
            "  [ 1.89555932]\n",
            "  [ 2.2944746 ]]\n",
            "\n",
            " [[ 0.5566827 ]\n",
            "  [-4.47989404]\n",
            "  [ 0.02129297]\n",
            "  ...\n",
            "  [ 3.65367182]\n",
            "  [ 2.48438265]\n",
            "  [ 1.54267973]]\n",
            "\n",
            " [[ 0.77725834]\n",
            "  [-4.48429482]\n",
            "  [ 0.08583648]\n",
            "  ...\n",
            "  [ 3.34941247]\n",
            "  [ 2.76242843]\n",
            "  [ 0.91854611]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA6sxYqhWDmg",
        "colab_type": "text"
      },
      "source": [
        "### Block to stacked matrix (3D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20sksbbhVuYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def block2stacked3D(A, pA):\n",
        "\n",
        "  # Work out shape of A\n",
        "  v = A.shape[0] # (Number of voxels)\n",
        "  m1 = A.shape[1]\n",
        "  m2 = A.shape[2]\n",
        "\n",
        "  # Work out shape of As\n",
        "  n1 = pA[0]\n",
        "  n2 = pA[1]\n",
        "  \n",
        "  # Change A to stacked form\n",
        "  As = A.reshape((v,m1//n1,n1,m2//n2,n2)).transpose(0,1,3,2,4).reshape(v,m1*m2//n2,n2)\n",
        "\n",
        "  return(As)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG3wjSmwXJMj",
        "colab_type": "text"
      },
      "source": [
        "The below code checks the above function against it's 2D counterpart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Gim8jhWI_a",
        "colab_type": "code",
        "outputId": "e7b78461-d391-48f5-8593-c461637df65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Random block sizes\n",
        "n1 = np.random.randint(2,60)\n",
        "n2 = np.random.randint(2,60)\n",
        "pA = np.array([n1,n2])\n",
        "\n",
        "# Number of voxels \n",
        "v = 100\n",
        "\n",
        "# Random number of blocks\n",
        "l1 = np.random.randint(1,31)\n",
        "l2 = np.random.randint(1,31)\n",
        "\n",
        "# Shape of A\n",
        "m1 = l1*n1\n",
        "m2 = l2*n2\n",
        "\n",
        "# Create A\n",
        "A = np.random.randn(v,m1,m2)\n",
        "print(v,n1,n2,m1,m2)\n",
        "print(A.shape)\n",
        "\n",
        "# Some index, i\n",
        "i = 6\n",
        "\n",
        "# Print A\n",
        "print(np.allclose(block2stacked3D(A,pA)[i,:,:],block2stacked2D(A[i,:,:],pA)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 7 41 56 902\n",
            "(100, 56, 902)\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMNad1EKXaO5",
        "colab_type": "text"
      },
      "source": [
        "### Convert Blocked matrix to stacked vector format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8niyem7XmEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Block vec with row-wise chunks of size n\n",
        "def mat2vecb3D(mat,p):\n",
        "\n",
        "  # Change to stacked block format, if necessary\n",
        "  if p[1]!=mat.shape[2]:\n",
        "    mat = block2stacked3D(mat,p)\n",
        "\n",
        "  # Get height of block.\n",
        "  n = p[0]\n",
        "  \n",
        "  # Work out shape of matrix.\n",
        "  v = mat.shape[0]\n",
        "  m = mat.shape[1]\n",
        "  k = mat.shape[2]\n",
        "\n",
        "  # Convert to stacked vector format\n",
        "  vecb = mat.reshape(v,m//n, n, k).transpose((0,2, 1, 3)).reshape(v,n, m*k//n).transpose((0,2,1)).reshape(v,m//n,n*k)\n",
        "\n",
        "  #Return vecb\n",
        "  return(vecb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kzFHAmUXk3I",
        "colab_type": "text"
      },
      "source": [
        "The below code tests the above function against it's 2D counterpart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIBiYD7TXmyt",
        "colab_type": "code",
        "outputId": "75b35ef0-a877-45a1-aa40-d6f4f02be2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Random block sizes\n",
        "n1 = np.random.randint(2,4)\n",
        "n2 = np.random.randint(2,4)\n",
        "\n",
        "# Number of voxels\n",
        "v = 100\n",
        "\n",
        "# Blocksize\n",
        "p = np.array([n1,n2])\n",
        "\n",
        "# Random number of blocks\n",
        "l1 = np.random.randint(2,4)\n",
        "l2 = np.random.randint(2,4)\n",
        "\n",
        "# Resultant matrix sizes\n",
        "m1 = l1*n1\n",
        "m2 = l2*n2\n",
        "\n",
        "# Random matrices\n",
        "A = np.random.randn(v,m1,m2)\n",
        "\n",
        "# Random index i\n",
        "i = 9\n",
        "\n",
        "print(np.allclose(mat2vecb3D(A,p)[i,:,:],mat2vecb2D(A[i,:,:],p)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24iy9fSWaGb-",
        "colab_type": "text"
      },
      "source": [
        "### Block sum of Aij Bij transpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-y1N0XIaXhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sumAijBijt3D(A, B, pA, pB):\n",
        "  \n",
        "  # Number of voxels\n",
        "  v = A.shape[0]\n",
        "\n",
        "  # Work out second (the common) dimension of the reshaped A and B\n",
        "  nA = pA[0]\n",
        "  nB = pB[0]\n",
        "\n",
        "  # Work out the first (the common) dimension of reshaped A and B\n",
        "  mA = A.shape[1]*A.shape[2]//nA\n",
        "  mB = B.shape[1]*B.shape[2]//nB\n",
        "\n",
        "  # Check mA equals mB\n",
        "  if mA != mB:\n",
        "    raise Exception('Matrix dimensions incompatible.')\n",
        "\n",
        "  # Convert both matrices to stacked block format.\n",
        "  A = block2stacked3D(A,pA)\n",
        "  B = block2stacked3D(B,pB)\n",
        "\n",
        "  # Work out the sum\n",
        "  S = A.transpose((0,2,1)).reshape((v,mA,nA)).transpose((0,2,1)) @ B.transpose((0,2,1)).reshape((v,mB,nB))\n",
        "\n",
        "  # Return result\n",
        "  return(S)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DGRplj8dc-f",
        "colab_type": "text"
      },
      "source": [
        "The below code tests the 3D function above against it's 2D counterpart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vZLTBZjddJQ",
        "colab_type": "code",
        "outputId": "fb814a05-6f24-46fc-ec9e-99c3c9531878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Random number of blocks\n",
        "l1 = np.random.randint(1,300)\n",
        "l2 = np.random.randint(1,300)\n",
        "\n",
        "# Random blocksizes (the second dimension must be the same for both)\n",
        "n1 = np.random.randint(1,5)\n",
        "n1prime = np.random.randint(1,5)\n",
        "n2 = np.random.randint(1,5)\n",
        "\n",
        "# Number of voxels\n",
        "v = 61\n",
        "\n",
        "# Save block sizes\n",
        "pA = np.array([n1,n2])\n",
        "pB = np.array([n1prime,n2])\n",
        "\n",
        "m1 = n1*l1\n",
        "m1prime = n1prime*l1\n",
        "m2 = n2*l2\n",
        "\n",
        "k=100\n",
        "l1 = m1//n1\n",
        "l2 = m2//n2\n",
        "\n",
        "# Create A\n",
        "A = np.random.randn(v,m1,m2)\n",
        "B = np.random.randn(v,m1prime,m2)\n",
        "\n",
        "# index i\n",
        "i = 24\n",
        "\n",
        "sumAB = sumAijBijt2D(A[i,:,:], B[i,:,:], pA, pB)\n",
        "sumAB2 = sumAijBijt3D(A, B, pA, pB)[i,:,:]\n",
        "\n",
        "print(np.allclose(sumAB,sumAB2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7gpsuCTnUee",
        "colab_type": "text"
      },
      "source": [
        "#### Matrix to Vector (broadcasted)\n",
        "\n",
        "This function takes in a stack of matrices and returns the corresponding vectorized forms of those matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IziwYuRbnUuG",
        "colab_type": "code",
        "outputId": "d605b137-248f-4837-fa31-ee0b26a1b38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "def mat2vec_broadcasted(matrix):\n",
        "  \n",
        "  #Return vectorised matrix\n",
        "  return(matrix.transpose(0,2,1).reshape(matrix.shape[0],matrix.shape[1]*matrix.shape[2],1))\n",
        "\n",
        "# Example:\n",
        "matrix = np.random.randn(4,3,3)\n",
        "print(matrix)\n",
        "print(mat2vec_broadcasted(matrix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 1.12152257 -0.53891485 -0.79545757]\n",
            "  [-0.44217089 -0.32010966 -0.95993104]\n",
            "  [-0.25283493 -0.0387094   0.38020377]]\n",
            "\n",
            " [[ 1.57829504 -0.29963826 -0.05018347]\n",
            "  [ 0.43797271 -0.4446755  -0.26737488]\n",
            "  [-1.76171449 -1.68142624  0.14159867]]\n",
            "\n",
            " [[-0.46632936 -1.3517203  -0.13465773]\n",
            "  [-0.48191413 -0.62318696 -0.74503883]\n",
            "  [ 0.27666878  0.35333285  0.02270484]]\n",
            "\n",
            " [[ 0.41791691  0.90898366  1.01505147]\n",
            "  [-0.94352414  0.38345845  0.70748432]\n",
            "  [-2.1325694  -1.42764497  0.35452556]]]\n",
            "[[[ 1.12152257]\n",
            "  [-0.44217089]\n",
            "  [-0.25283493]\n",
            "  [-0.53891485]\n",
            "  [-0.32010966]\n",
            "  [-0.0387094 ]\n",
            "  [-0.79545757]\n",
            "  [-0.95993104]\n",
            "  [ 0.38020377]]\n",
            "\n",
            " [[ 1.57829504]\n",
            "  [ 0.43797271]\n",
            "  [-1.76171449]\n",
            "  [-0.29963826]\n",
            "  [-0.4446755 ]\n",
            "  [-1.68142624]\n",
            "  [-0.05018347]\n",
            "  [-0.26737488]\n",
            "  [ 0.14159867]]\n",
            "\n",
            " [[-0.46632936]\n",
            "  [-0.48191413]\n",
            "  [ 0.27666878]\n",
            "  [-1.3517203 ]\n",
            "  [-0.62318696]\n",
            "  [ 0.35333285]\n",
            "  [-0.13465773]\n",
            "  [-0.74503883]\n",
            "  [ 0.02270484]]\n",
            "\n",
            " [[ 0.41791691]\n",
            "  [-0.94352414]\n",
            "  [-2.1325694 ]\n",
            "  [ 0.90898366]\n",
            "  [ 0.38345845]\n",
            "  [-1.42764497]\n",
            "  [ 1.01505147]\n",
            "  [ 0.70748432]\n",
            "  [ 0.35452556]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KryF-ftSgqU3",
        "colab_type": "text"
      },
      "source": [
        "#### Sum of Aij kron Bij"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2wzk5AXgqd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sumAijKronBij3D(A, B, p, perm=None):\n",
        "\n",
        "  # Check dim A and B and pA and pB all same\n",
        "  n1 = p[0]\n",
        "  n2 = p[1]\n",
        "\n",
        "  # Number of voxels\n",
        "  v = A.shape[0]\n",
        "\n",
        "  # This matrix only needs be calculated once\n",
        "  if perm is None:\n",
        "    perm = permOfIkKkI(n2,n1,n2,n1) \n",
        "\n",
        "  # Convert to vecb format\n",
        "  atilde = mat2vecb3D(A,p)\n",
        "  btilde = mat2vecb3D(B,p)\n",
        "\n",
        "  # Multiply and convert to vector\n",
        "  vecba = mat2vec_broadcasted(btilde.transpose((0,2,1)) @ atilde)\n",
        "\n",
        "  # Permute\n",
        "  S_noreshape = vecba[:,perm,:] \n",
        "\n",
        "  # Reshape to correct shape\n",
        "  S = S_noreshape.reshape(v,n2**2,n1**2).transpose((0,2,1))\n",
        "\n",
        "  return(S,perm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW_YdVvCiN-N",
        "colab_type": "text"
      },
      "source": [
        "The below code tests the above function against it's 2D counterpart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HXjXKqCiONz",
        "colab_type": "code",
        "outputId": "058566fa-ac5d-49a6-bbe4-6fa605f4a991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Random block sizes\n",
        "n1 = np.random.randint(2,10)\n",
        "n2 = np.random.randint(2,10)\n",
        "\n",
        "# Number of voxels \n",
        "v = 37\n",
        "\n",
        "# Blocksize\n",
        "p = np.array([n1,n2])\n",
        "\n",
        "# Random number of blocks\n",
        "l1 = np.random.randint(2,30)\n",
        "l2 = np.random.randint(2,30)\n",
        "\n",
        "# Resultant matrix sizes\n",
        "m1 = l1*n1\n",
        "m2 = l2*n2\n",
        "\n",
        "# Random matrices\n",
        "A = np.random.randn(v,m1,m2)\n",
        "B = np.random.randn(v,m1,m2)\n",
        "\n",
        "# Index i\n",
        "i = 17\n",
        "\n",
        "# Now with function\n",
        "S,_ = sumAijKronBij2D(A[i,:,:], B[i,:,:], p)\n",
        "S2,_ = sumAijKronBij3D(A, B, p)\n",
        "S2 = S2[i,:,:]\n",
        "\n",
        "print(np.allclose(S,S2))\n",
        "#print(S)\n",
        "#print(runningSum)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FZyyQAEh3mp",
        "colab_type": "text"
      },
      "source": [
        "### Sum of square residuals (broadcasted)\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "The function below calculates the sum of the square residuals, $e^Te$, using the below formula:\n",
        "\n",
        "$$e^Te = (Y-X\\beta)^T(Y-X\\beta)$$ \n",
        "$$=Y^TY - 2Y^TX\\beta + \\beta^T X^TX \\beta$$\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `YtX`: $Y$ transpose multiplied by $X$ ($Y^TX$ in the above notation).\n",
        " - `YtY`: $Y$ transpose multiplied by $Y$ ($Y^TY$ in the above notation).\n",
        " - `XtX`: $X$ transpose multiplied by $X$ ($X^TX$ in the above notation).\n",
        " - `beta`: An estimate of the parameter vector ($\\beta$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        " - `ete`: The sum of square residuals ($e^Te$ in the above notation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFycwRkYeklg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ssr_broadcasted(YtX, YtY, XtX, beta):\n",
        "  \n",
        "  # Return the sum of squared residuals\n",
        "  return(YtY - 2*YtX @ beta + beta.transpose((0,2,1)) @ XtX @ beta)\n",
        "\n",
        "print(ssr_broadcasted(YtX,YtY,XtX,initBeta(XtX,XtY)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOvNqJPojgGp",
        "colab_type": "text"
      },
      "source": [
        "#### Initial Sigma (Broadcasted)\n",
        "\n",
        "The function below returns an initial estimate for the Fixed Effects Variance, $\\sigma^2$. The estimator used is based on the suggested OLS estimator in Demidenko (2012) and is given by:\n",
        "\n",
        "$$\\hat{\\sigma}^2_{OLS}=\\frac{1}{n}(Y-X\\beta)^T(Y-X\\beta)$$\n",
        "$$=\\frac{1}{n}e^Te$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `ete`: The sum of square residuals ($e^Te$ in the above notation).\n",
        " - `n`: The total number of observations ($n$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `sigma2`: The OLS estimate of $\\sigma^2$ ($\\hat{\\sigma}^2_{OLS}$ in the above notation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY1ILWTLjnKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initSigma2_broadcasted(ete, n):\n",
        "\n",
        "  # Return the OLS estimate of sigma\n",
        "  return(1/n*ete[:,0,0])\n",
        "\n",
        "print(initSigma2_broadcasted(ssr_broadcasted(YtX,YtY,XtX,initBeta(XtX,XtY)),n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAURtA0rlZVL",
        "colab_type": "text"
      },
      "source": [
        "### Kron (broadcasted)\n",
        "\n",
        "Taken from https://stackoverflow.com/questions/57259557/kronecker-product-of-matrix-array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5saAin0lY69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kron_broadcasted(A,B):\n",
        "  i,j,k = A.shape\n",
        "  i,l,m = B.shape\n",
        "  return(np.einsum(\"ijk,ilm->ijlkm\",A,B).reshape(i,j*l,k*m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdB9CszhoA1R",
        "colab_type": "text"
      },
      "source": [
        "#### Vector to matrix (broadcasted)\n",
        "\n",
        "This function takes in a stack of vectors and returns the corresponding matrix forms of those vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wud5dy0CoBFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec2mat_broadcasted(vec):\n",
        "  \n",
        "  # Return matrix\n",
        "  return(vec.reshape(vec.shape[0], np.int64(np.sqrt(vec.shape[1])),np.int64(np.sqrt(vec.shape[1]))).transpose(0,2,1))\n",
        "\n",
        "# Example\n",
        "vec = np.random.randn(4,4,1)\n",
        "mat = vec2mat_broadcasted(vec)\n",
        "print(vec)\n",
        "print(mat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j75PTwshvngn",
        "colab_type": "text"
      },
      "source": [
        "#### Matrix to half vector (broadcasted)\n",
        "\n",
        "This function takes in a stack of matrices and returns the corresponding vector forms of the lower halves of those matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E31shCYgvnx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mat2vech_broadcasted(matrix):\n",
        "  \n",
        "  # Number of voxels, nv\n",
        "  nv = matrix.shape[0]\n",
        "  \n",
        "  # Get lower triangular indices\n",
        "  rowinds, colinds = np.tril_indices(matrix.shape[1]) \n",
        "  \n",
        "  # Number of covariance parameters, nc\n",
        "  nc = len(rowinds)\n",
        "  \n",
        "  # They're in the wrong order so we need to order them\n",
        "  # To do this we first hash them\n",
        "  indhash = colinds*matrix.shape[1]+rowinds\n",
        "  \n",
        "  # Sort permutation\n",
        "  perm=np.argsort(indhash)\n",
        "  \n",
        "  # Return vectorised half-matrix\n",
        "  return(matrix[:,rowinds[perm],colinds[perm]].reshape((nv,nc,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWzmL4Bp1QiX",
        "colab_type": "text"
      },
      "source": [
        "#### Half vector to matrix (broadcasted)\n",
        "\n",
        "This function takes in a stack of vectors and returns the corresponding matrix forms treating the elements of the vectors as the elements of lower halves of those matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV2UNK8L1Qxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vech2mat_broadcasted(vech):\n",
        "  \n",
        "  # Number of voxels\n",
        "  nv = vech.shape[0]\n",
        "  \n",
        "  # dimension of matrix\n",
        "  n = np.int64((-1+np.sqrt(1+8*vech.shape[1]))/2)\n",
        "  matrix = np.zeros((nv,n,n))\n",
        "  \n",
        "  # Get lower triangular indices\n",
        "  rowinds, colinds = np.tril_indices(n)\n",
        "  \n",
        "  # They're in the wrong order so we need to order them\n",
        "  # To do this we first hash them\n",
        "  indhash = colinds*n+rowinds\n",
        "  \n",
        "  # Sort permutation\n",
        "  perm=np.argsort(indhash)\n",
        "  \n",
        "  # Assign values to lower half\n",
        "  matrix[:,rowinds[perm],colinds[perm]] = vech.reshape(vech.shape[0],vech.shape[1])\n",
        "  \n",
        "  # Assign values to upper half\n",
        "  matrix[:,colinds[perm],rowinds[perm]] = vech.reshape(vech.shape[0],vech.shape[1])\n",
        "  \n",
        "  # Return vectorised half-matrix\n",
        "  return(matrix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXZTnBHRkOm7",
        "colab_type": "text"
      },
      "source": [
        "#### Initial D_k (broadcasted)\n",
        "\n",
        "The function below returns an initial estimate for the Random Effects Variance matrix for the $k^{th}$ grouping factor, $D_k$. The estimator used is an adaption of the suggested estimator in Demidenko (2012) and is given by:\n",
        "\n",
        "$$vec(\\hat{D}_{k})=\\bigg[\\sum_{j=1}^{l_k}(Z_{(k,j)}^TZ_{(k,j)}) \\otimes (Z_{(k,j)}^TZ_{(k,j)})\\bigg]^{-1}vec\\bigg(\\sum_{j=1}^{l_k}[\\hat{\\sigma}^{-2}_{OLS}Z_{(k,j)}^Tee^TZ_{(k,j)} - Z_{(k,j)}^TZ_{(k,j)}]\\bigg)$$\n",
        "\n",
        "Or:\n",
        "\n",
        "$$\\hat{D}_{k}=matrix\\bigg(\\bigg[\\sum_{j=1}^{l_k}(Z_{(k,j)}^TZ_{(k,j)}) \\otimes (Z_{(k,j)}^TZ_{(k,j)})\\bigg]^{-1}vec\\bigg(\\sum_{j=1}^{l_k}[\\hat{\\sigma}^{-2}_{OLS}Z_{(k,j)}^Tee^TZ_{(k,j)} - Z_{(k,j)}^TZ_{(k,j)}]\\bigg)\\bigg)$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The grouping factor we wish to estimate $D$ for ($k$ in the above notation)\n",
        " - `lk`: The number of levels belonging to grouping factor $k$ ($l_k$ in the above notation).\n",
        " - `ZtZ`: The $Z$ matrix transposed and then multiplied by itself ($Z^TZ$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z^Te=Z^T(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The OLS estimate of $\\sigma^2$ ($\\hat{\\sigma}^2_{OLS}$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `Dkest`: The inital estimate of $D_k$ ($\\hat{D}_k$ in the above notation).\n",
        "\n",
        "\n",
        "###CHECK DERIVATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSNOV2V5kO36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initDk_broadcasted(k, lk, ZtZ, Zte, sigma2):\n",
        "  \n",
        "  # Initalize D to zeros\n",
        "  invSig2ZteetZminusZtZ = np.zeros((Zte.shape[0],nparams[k],nparams[k]))\n",
        "  \n",
        "  # For each level j we need to add a term\n",
        "  for j in np.arange(nlevels[k]):\n",
        "    \n",
        "    Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "    # Work out Z_(k, j)'Z_(k, j)\n",
        "    ZkjtZkj = ZtZ[np.ix_(np.arange(ZtZ.shape[0]),Ikj,Ikj)]\n",
        "    \n",
        "    # Work out Z_(k,j)'e\n",
        "    Zkjte = Zte[:, Ikj,:]\n",
        "    \n",
        "    if j==0:\n",
        "      \n",
        "      # Add first Z_(k,j)'Z_(k,j) kron Z_(k,j)'Z_(k,j)\n",
        "      ZtZkronZtZ = kron_broadcasted(ZkjtZkj,ZkjtZkj.transpose(0,2,1))\n",
        "      \n",
        "      # Add first \\sigma^{-2}Z'ee'Z - Z_(k,j)'Z_(k,j)\n",
        "      invSig2ZteetZminusZtZ = np.einsum('i,ijk->ijk',1/sigma2,(Zkjte @ Zkjte.transpose(0,2,1))) - ZkjtZkj\n",
        "      \n",
        "    else:\n",
        "      \n",
        "      # Add next Z_(k,j)'Z_(k,j) kron Z_(k,j)'Z_(k,j)\n",
        "      ZtZkronZtZ = ZtZkronZtZ + kron_broadcasted(ZkjtZkj,ZkjtZkj.transpose(0,2,1))\n",
        "      \n",
        "      # Add next \\sigma^{-2}Z'ee'Z - Z_(k,j)'Z_(k,j)\n",
        "      invSig2ZteetZminusZtZ = invSig2ZteetZminusZtZ + np.einsum('i,ijk->ijk',1/sigma2,(Zkjte @ Zkjte.transpose(0,2,1))) - ZkjtZkj\n",
        "      \n",
        "  # Work out the final term.\n",
        "  Dkest = vec2mat_broadcasted(np.linalg.inv(ZtZkronZtZ) @ mat2vec_broadcasted(invSig2ZteetZminusZtZ)) \n",
        "  \n",
        "  \n",
        "  return(Dkest)\n",
        "\n",
        "Zte = ZtY-ZtX @ np.random.randn(ZtY.shape[0],ZtX.shape[2],1)\n",
        "\n",
        "t1 = time.time()\n",
        "initDk_broadcasted(0, nlevels[0], ZtZ, Zte , np.ones(Zte.shape[0]))\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "initDk_broadcasted(0, nlevels[0], ZtZ, Zte , np.ones(Zte.shape[0]))\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "\n",
        "print(initDk_broadcasted(0, nlevels[0], ZtZ, Zte , np.ones(Zte.shape[0]))[8,:,:])\n",
        "\n",
        "t1 = time.time()\n",
        "print(initDk(0, nlevels[0], ZtZ[0,:,:], Zte[8,:,:], 1))\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tddRYrhtNWG",
        "colab_type": "text"
      },
      "source": [
        "#### Make D non-negative definite (Broadcasted)\n",
        "\n",
        "This function projects a stack of matrices into the space of non-negative definite matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0en3ealntNes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeDnnd_broadcasted(D):\n",
        "  \n",
        "  # Check if we have negative eigenvalues\n",
        "  if not np.all(np.linalg.eigvals(D)>0):\n",
        "  \n",
        "    # If we have negative eigenvalues\n",
        "    eigvals,eigvecs = np.linalg.eigh(D)\n",
        "    \n",
        "    # Work out elementwise max of lambda and 0\n",
        "    lamplus = np.zeros((eigvals.shape[0], eigvals.shape[1], eigvals.shape[1]))\n",
        "    diag = np.arange(eigvals.shape[1])\n",
        "    lamplus[:, diag, diag] = np.maximum(eigvals,0)\n",
        "    \n",
        "    # Work out D+\n",
        "    D_nnd = eigvecs @ lamplus @ np.linalg.inv(eigvecs)\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    # D is already non-negative in this case\n",
        "    D_nnd = D\n",
        "    \n",
        "  return(D_nnd)\n",
        "  \n",
        "D = np.random.randn(100000,3,3)\n",
        "t1 = time.time()\n",
        "print(makeDnnd_broadcasted(D)[10,:,:])\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "t1 = time.time()\n",
        "print(makeDnnd(D[10,:,:]))\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "\n",
        "### COULD BE IMPROVED SPEED WISE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2RBNITFOdJs",
        "colab_type": "text"
      },
      "source": [
        "### Get D from dict (broadcasted)\n",
        "\n",
        "This function takes in a dictionary, `Ddict`, in which entry `k` is a stack of the $k^{th}$ diagonal block for every voxel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcziKRJvOdUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDfromDict_broadcasted(Ddict, nparams, nlevels):\n",
        "  \n",
        "  # Get number of voxels\n",
        "  nv = Ddict[0].shape[0]\n",
        "  \n",
        "  # Work out indices (there is one block of D per level)\n",
        "  inds = np.zeros(np.sum(nlevels)+1)\n",
        "  counter = 0\n",
        "  for k in np.arange(len(nparams)):\n",
        "    for j in np.arange(nlevels[k]):\n",
        "      inds[counter] = np.concatenate((np.array([0]), np.cumsum(nlevels*nparams)))[k] + nparams[k]*j\n",
        "      counter = counter + 1\n",
        "      \n",
        "  \n",
        "  # Last index will be missing so add it\n",
        "  inds[len(inds)-1]=inds[len(inds)-2]+nparams[-1]\n",
        "  \n",
        "  # Make sure indices are ints\n",
        "  inds = np.int64(inds)\n",
        "  \n",
        "  # Initial D\n",
        "  D = np.zeros((nv,np.sum(nparams*nlevels),np.sum(nparams*nlevels)))\n",
        "\n",
        "  counter = 0\n",
        "  for k in np.arange(len(nparams)):\n",
        "    for j in np.arange(nlevels[k]):\n",
        "\n",
        "      D[:, inds[counter]:inds[counter+1], inds[counter]:inds[counter+1]] = Ddict[k]\n",
        "      counter = counter + 1\n",
        "  \n",
        "  return(D)\n",
        "  \n",
        "# Example dict\n",
        "nparams_tmp = np.array([10,2,3])\n",
        "nlevels_tmp = np.array([30,22,4])\n",
        "\n",
        "Ddict_tmp = dict()\n",
        "for i in np.arange(len(nparams_tmp)):\n",
        "  \n",
        "  Ddict_tmp[i] = np.random.randn(2000,nparams_tmp[i],nparams_tmp[i])\n",
        "\n",
        "t1 = time.time()\n",
        "D = getDfromDict_broadcasted(Ddict_tmp, nparams_tmp, nlevels_tmp)\n",
        "t2 = time.time()\n",
        "print(t2-t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn997hc1hDGK",
        "colab_type": "text"
      },
      "source": [
        "#### Force Symmetric (Broadcasted)\n",
        "\n",
        "This function forces a stack of matrices to be symmetric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BphjFMdxhDWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Developer NOTE: DO NOT USE NUMBA ON THIS FUNCTION - NUMBA BUGGERS IT UP FOR UNKNOWN REASONS\n",
        "def forceSym_broadcasted(x):\n",
        "  \n",
        "  # Force it to be symmetric\n",
        "  return((x+x.transpose((0,2,1)))/2)\n",
        "\n",
        "  \n",
        "print(ZtZ.shape)\n",
        "t1 = time.time()\n",
        "ZtZ = forceSym_broadcasted(forceSym_broadcasted(ZtZ))\n",
        "print(time.time()-t1)\n",
        "\n",
        "print(ZtZ.shape)\n",
        "t1 = time.time()\n",
        "ZtZ = forceSym_broadcasted(forceSym_broadcasted(ZtZ))\n",
        "print(time.time()-t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T01OEeP9GT65",
        "colab_type": "text"
      },
      "source": [
        "#### Derivative of $\\frac{\\delta l}{\\delta \\beta}$ (broadcasted)\n",
        "\n",
        "This function returns the derivative of $l$ with respect to $\\beta$ for all voxels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwCgeYh0GUHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dldB_broadcasted(sigma2, Xte, XtZ, DinvIplusZtZD, Zte):\n",
        "  \n",
        "  # Work out the derivative (Note: we leave everything as 3D for ease of future computation)\n",
        "  deriv = np.einsum('i,ijk->ijk',1/sigma2, (Xte - (XtZ @ DinvIplusZtZD @ Zte)))\n",
        "                    \n",
        "  # Return the derivative\n",
        "  return(deriv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2wffHXtIgd2",
        "colab_type": "text"
      },
      "source": [
        "#### Derivative of $\\frac{\\delta l}{\\delta \\sigma^2}$ (broadcasted)\n",
        "\n",
        "This function returns the derivative of $l$ with respect to $\\sigma^2$ for all voxels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WUjR0_oIjJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dldsigma2_broadcasted(n, ete, Zte, sigma2, DinvIplusZtZD):\n",
        "  \n",
        "  # Get e'(I+ZDZ')^(-1)e=e'e-e'ZD(I+Z'ZD)^(-1)Z'e\n",
        "  etinvIplusZtDZe = ete - forceSym_broadcasted(Zte.transpose((0,2,1)) @ DinvIplusZtZD @ Zte)\n",
        "  \n",
        "  # Get the derivative\n",
        "  deriv = -n/(2*sigma2) + np.einsum('i,ijk->ijk',1/(2*(sigma2**2)), etinvIplusZtDZe).reshape(sigma2.shape[0])\n",
        "  \n",
        "  return(deriv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOn3facWIgoz",
        "colab_type": "text"
      },
      "source": [
        "#### Derivative of $\\frac{\\delta l}{\\delta D_k}$ (broadcasted)\n",
        "\n",
        "This function returns the derivative of $l$ with respect to $D_k$ for all voxels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWRg9WRpMwwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dldDk_broadcasted(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD):\n",
        "\n",
        "  # Number of voxels\n",
        "  nv = Zte.shape[0]\n",
        "  \n",
        "  # Initalize the derivative to zeros\n",
        "  dldDk = np.zeros((nv, nparams[k],nparams[k]))\n",
        "  \n",
        "  # For each level j we need to add a term\n",
        "  for j in np.arange(nlevels[k]):\n",
        "\n",
        "    # Get the indices for the kth factor jth level\n",
        "    Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "    \n",
        "    # Get (the kj^th columns of Z)^T multiplied by Z\n",
        "    Z_kjtZ = ZtZ[:,Ikj,:]\n",
        "    Z_kjte = Zte[:,Ikj,:]\n",
        "    \n",
        "    # Get the first term of the derivative\n",
        "    Z_kjtVinve = Z_kjte - (Z_kjtZ @ DinvIplusZtZD @ Zte)\n",
        "    firstterm = np.einsum('i,ijk->ijk',1/sigma2,forceSym_broadcasted(Z_kjtVinve @ Z_kjtVinve.transpose((0,2,1))))\n",
        "    \n",
        "    # Get (the kj^th columns of Z)^T multiplied by (the kj^th columns of Z)\n",
        "    Z_kjtZ_kj = ZtZ[np.ix_(np.arange(ZtZ.shape[0]),Ikj,Ikj)]\n",
        "    secondterm = forceSym_broadcasted(Z_kjtZ_kj) - forceSym_broadcasted(Z_kjtZ @ DinvIplusZtZD @ Z_kjtZ.transpose((0,2,1)))\n",
        "    \n",
        "    if j == 0:\n",
        "      \n",
        "      # Start a running sum over j\n",
        "      dldDk = firstterm - secondterm\n",
        "      \n",
        "    else:\n",
        "    \n",
        "      # Add these to the running sum\n",
        "      dldDk = dldDk + firstterm - secondterm\n",
        "    \n",
        "  # Halve the sum (the coefficient of a half was not included in the above)\n",
        "  dldDk = forceSym_broadcasted(dldDk/2)\n",
        "\n",
        "  # Store it in the dictionary\n",
        "  return(dldDk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh7nHo0KRHk-",
        "colab_type": "text"
      },
      "source": [
        "#### Covariance of derivative of $\\frac{\\delta l}{\\delta \\beta}$ (broadcasted)\n",
        "\n",
        "This function returns the covariance of the derivative of $l$ with respect to $\\beta$ for all voxels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIE2Oy4RHxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_covdldbeta_broadcasted(XtZ, XtX, ZtZ, DinvIplusZtZD, sigma2):\n",
        "  \n",
        "  # Get the covariance of the derivative\n",
        "  covderiv = np.einsum('i,ijk->ijk',1/sigma2,(XtX - forceSym_broadcasted(XtZ @ DinvIplusZtZD @ XtZ.transpose((0,2,1)))))\n",
        "  \n",
        "  # Return the covariance of the derivative\n",
        "  return(covderiv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-8VOZR5ULKX",
        "colab_type": "text"
      },
      "source": [
        "#### Covariance of derivative of $\\frac{\\delta l}{\\delta \\sigma^2}$ and $\\frac{\\delta l}{\\delta D_k}$ (broadcasted)\n",
        "\n",
        "This function returns the covariance of the derivative of $l$ with respect to $\\sigma^2$ and $D_k$ for all voxels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW40iTC-ULV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_covdldDkdsigma2_broadcasted(k, sigma2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict):\n",
        "  \n",
        "  # Number of voxels\n",
        "  nv = DinvIplusZtZD.shape[0]\n",
        "  \n",
        "  # Sum of R_(k, j) over j\n",
        "  RkSum = np.zeros((nv,nparams[k],nparams[k]))\n",
        "\n",
        "  for j in np.arange(nlevels[k]):\n",
        "\n",
        "    # Get the indices for the kth factor jth level\n",
        "    Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "    # Work out R_(k, j)\n",
        "    Rkj = ZtZ[np.ix_(np.arange(ZtZ.shape[0]),Ikj,Ikj)] - forceSym_broadcasted(ZtZ[:,Ikj,:] @ DinvIplusZtZD @ ZtZ[:,:,Ikj])\n",
        "    \n",
        "    # Add together\n",
        "    RkSum = RkSum + Rkj\n",
        "\n",
        "  # Multiply by duplication matrices and save\n",
        "  covdldDdldsigma2 = np.einsum('i,ijk->ijk', 1/(2*sigma2), invDupMatdict[k] @ mat2vec_broadcasted(RkSum))\n",
        "  \n",
        "  return(covdldDdldsigma2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d1GYRfPqLs3",
        "colab_type": "text"
      },
      "source": [
        "#### Covariance of derivative of $\\frac{\\delta l}{\\delta D_{k_1}}$ and $\\frac{\\delta l}{\\delta D_{k_2}}$ (broadcasted)\n",
        "\n",
        "This function returns the covariance of the derivative of $l$ with respect to $D_{k_1}$ and $D_{k_2}$ for all voxels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhknnB8aqL44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_covdldDk1Dk2_broadcasted(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict):\n",
        "  \n",
        "  # Sum of R_(k1, k2, i, j) kron R_(k1, k2, i, j) over i and j \n",
        "  for i in np.arange(nlevels[k1]):\n",
        "\n",
        "    for j in np.arange(nlevels[k2]):\n",
        "      \n",
        "      # Get the indices for the k1th factor jth level\n",
        "      Ik1i = faclev_indices(k1, i, nlevels, nparams)\n",
        "      Ik2j = faclev_indices(k2, j, nlevels, nparams)\n",
        "      \n",
        "      # Work out R_(k1, k2, i, j)\n",
        "      Rk1k2ij = ZtZ[np.ix_(np.arange(ZtZ.shape[0]),Ik1i,Ik2j)] - (ZtZ[:,Ik1i,:] @ DinvIplusZtZD @ ZtZ[:,:,Ik2j])\n",
        "      \n",
        "      # Work out Rk1k2ij kron Rk1k2ij\n",
        "      RkRt = kron_broadcasted(Rk1k2ij,Rk1k2ij)\n",
        "      \n",
        "      # Add together\n",
        "      if (i == 0) and (j == 0):\n",
        "      \n",
        "        RkRtSum = RkRt\n",
        "      \n",
        "      else:\n",
        "        \n",
        "        RkRtSum = RkRtSum + RkRt\n",
        "    \n",
        "  # Multiply by duplication matrices and save\n",
        "  covdldDk1dldk2 = 1/2 * invDupMatdict[k1] @ RkRtSum @ invDupMatdict[k2].transpose()\n",
        "  \n",
        "  # Return the result\n",
        "  return(covdldDk1dldk2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idaEKRat3dsM",
        "colab_type": "text"
      },
      "source": [
        "#### Log likelihood (broadcasted)\n",
        "\n",
        "This function returns the loglikelihood for all voxels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6OSs_pj3d55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def llh_broadcasted(n, ZtZ, Zte, ete, sigma2, DinvIplusZtZD,D):\n",
        "  \n",
        "  # Work out -1/2(nln(sigma^2) + ln|I+Z'ZD|)\n",
        "  firstterm = -0.5*(n*np.log(sigma2) + np.log(np.linalg.det(np.eye(ZtZ.shape[1]) + ZtZ @ D))).reshape(ete.shape[0])\n",
        "                    \n",
        "  # Work out sigma^(-2)*(e'e - e'ZD(I+Z'ZD)^(-1)Z'e)\n",
        "  secondterm = -0.5*np.einsum('i,ijk->ijk',(1/sigma2),(ete - forceSym_broadcasted(Zte.transpose((0,2,1)) @ DinvIplusZtZD @ Zte))).reshape(ete.shape[0])\n",
        "  \n",
        "  # Work out the log likelihood\n",
        "  llh = firstterm + secondterm\n",
        "  \n",
        "  # Return result\n",
        "  return(llh)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNOVuHBppePE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPxdgTRlpedA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getConvergedIndices(convergedBeforeIt, convergedDuringIt):\n",
        "  \n",
        "  # ============================================================================\n",
        "  # Global indices (i.e. relative to whole image)\n",
        "  # ----------------------------------------------------------------------------\n",
        "  \n",
        "  # Numbers 1 to number of voxels\n",
        "  indices = np.arange(len(convergedBeforeIt))\n",
        "  \n",
        "  # Indices of those which weren't converged before the iteration\n",
        "  indices_notConBeforeIt = indices[convergedBeforeIt==0]\n",
        "  \n",
        "  # Indices of those which weren't converged after the iteration\n",
        "  indices_notConAfterIt = indices_notConBeforeIt[convergedDuringIt==0]\n",
        "  \n",
        "  # Indices of those which were converged after iteration\n",
        "  indices_ConAfterIt = np.setdiff1d(indices, indices_notConAfterIt)\n",
        "  \n",
        "  # Indices of those which converged during iteration\n",
        "  indices_conDuringIt = np.setdiff1d(indices_notConBeforeIt, indices_notConAfterIt)\n",
        "  \n",
        "  # ============================================================================\n",
        "  # Local indices (i.e. relative to current voxels)\n",
        "  # ----------------------------------------------------------------------------\n",
        "  local_converged = np.arange(len(convergedDuringIt))[convergedDuringIt==1]\n",
        "  local_notconverged = np.arange(len(convergedDuringIt))[convergedDuringIt==0]\n",
        "  \n",
        "  return(indices_ConAfterIt, indices_notConAfterIt, indices_conDuringIt, local_converged, local_notconverged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x72ZuXyheljG",
        "colab_type": "text"
      },
      "source": [
        "### Broadcasted FS\n",
        "\n",
        "The below function performs FS for a NIFTI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJjgNbXjeszs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def FS_broadcasted(XtX, XtY, ZtX, ZtY, ZtZ, XtZ, YtZ, YtY, YtX, nlevels, nparams, tol,n):\n",
        "  \n",
        "  t1_total = time.time()\n",
        "  t1 = time.time()\n",
        "  \n",
        "  # Useful scalars\n",
        "  # ------------------------------------------------------------------------------\n",
        "\n",
        "  # Number of factors, r\n",
        "  r = len(nlevels)\n",
        "\n",
        "  # Number of random effects, q\n",
        "  q = np.sum(np.dot(nparams,nlevels))\n",
        "\n",
        "  # Number of fixed effects, p\n",
        "  p = XtX.shape[1]\n",
        "\n",
        "  # Number of voxels, nv\n",
        "  nv = XtY.shape[0]\n",
        "  \n",
        "  # Initial estimates\n",
        "  # ------------------------------------------------------------------------------\n",
        "\n",
        "  # Inital beta\n",
        "  beta = initBeta_broadcasted(XtX, XtY)\n",
        "  \n",
        "  # Work out e'e, X'e and Z'e\n",
        "  Xte = XtY - (XtX @ beta)\n",
        "  Zte = ZtY - (ZtX @ beta)\n",
        "  ete = ssr_broadcasted(YtX, YtY, XtX, beta)\n",
        "  \n",
        "  # Initial sigma2\n",
        "  sigma2 = initSigma2_broadcasted(ete, n)\n",
        "\n",
        "  Zte = ZtY - (ZtX @ beta) \n",
        "  \n",
        "  # Inital D\n",
        "  # Dictionary version\n",
        "  Ddict = dict()\n",
        "  for k in np.arange(len(nparams)):\n",
        "\n",
        "    Ddict[k] = makeDnnd_broadcasted(initDk_broadcasted(k, nlevels[k], ZtZ, Zte, sigma2))\n",
        "  \n",
        "  # Full version of D\n",
        "  D = getDfromDict_broadcasted(Ddict, nparams, nlevels)\n",
        "  \n",
        "  # Duplication matrices\n",
        "  # ------------------------------------------------------------------------------\n",
        "  invDupMatdict = dict()\n",
        "  for i in np.arange(len(nparams)):\n",
        "\n",
        "    invDupMatdict[i] = np.asarray(invDupMat(nparams[i]).todense())\n",
        "  \n",
        "  # Index variables\n",
        "  # ------------------------------------------------------------------------------\n",
        "  # Work out the total number of paramateres\n",
        "  tnp = np.int32(p + 1 + np.sum(nparams*(nparams+1)/2))\n",
        "\n",
        "  # Indices for submatrics corresponding to Dks\n",
        "  FishIndsDk = np.int32(np.cumsum(nparams*(nparams+1)/2) + p + 1)\n",
        "  FishIndsDk = np.insert(FishIndsDk,0,p+1)\n",
        "\n",
        "  Zte = ZtY - (ZtX @ beta)\n",
        "  \n",
        "  # Inverse of (I+Z'ZD) multiplied by D\n",
        "  IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "  DinvIplusZtZD =  forceSym_broadcasted(D @ np.linalg.inv(IplusZtZD)) \n",
        "  \n",
        "  # Step size lambda\n",
        "  lam = np.ones(nv)\n",
        "\n",
        "  # Initial log likelihoods\n",
        "  llhprev = -10*np.ones(XtY.shape[0])\n",
        "  llhcurr = 10*np.ones(XtY.shape[0])\n",
        "  \n",
        "  # Vector checking if all voxels converged\n",
        "  converged_global = np.zeros(nv)\n",
        "  \n",
        "  # Vector of saved parameters which have converged\n",
        "  savedparams = np.zeros((nv, np.int32(np.sum(nparams*(nparams+1)/2) + p + 1),1))\n",
        "  \n",
        "  t2 = time.time()\n",
        "  print('Setup time: ', t2-t1)\n",
        "  \n",
        "  nit=0\n",
        "  while np.any(np.abs(llhprev-llhcurr)>tol):\n",
        "    \n",
        "    t1 = time.time()\n",
        "    # Change current likelihood to previous\n",
        "    llhprev = llhcurr\n",
        "    \n",
        "    # Work out how many voxels are left\n",
        "    nv_iter = XtY.shape[0]\n",
        "    \n",
        "    # Derivatives\n",
        "    # ----------------------------------------------------------------------------\n",
        "\n",
        "    # Derivative wrt beta\n",
        "    dldB = get_dldB_broadcasted(sigma2, Xte, XtZ, DinvIplusZtZD, Zte)  \n",
        "    \n",
        "    # Derivative wrt sigma^2\n",
        "    dldsigma2 = get_dldsigma2_broadcasted(n, ete, Zte, sigma2, DinvIplusZtZD)\n",
        "    \n",
        "    # For each factor, factor k, work out dl/dD_k\n",
        "    dldDdict = dict()\n",
        "    for k in np.arange(len(nparams)):\n",
        "      # Store it in the dictionary\n",
        "      dldDdict[k] = get_dldDk_broadcasted(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD)\n",
        "    \n",
        "    # Covariances\n",
        "    # ----------------------------------------------------------------------------\n",
        "\n",
        "    # Construct the Fisher Information matrix\n",
        "    # ----------------------------------------------------------------------------\n",
        "    FisherInfoMat = np.zeros((nv_iter,tnp,tnp))\n",
        "    \n",
        "    # Covariance of dl/dsigma2\n",
        "    covdldsigma2 = n/(2*(sigma2**2))\n",
        "    \n",
        "    # Add dl/dsigma2 covariance\n",
        "    FisherInfoMat[:,p,p] = covdldsigma2\n",
        "    \n",
        "    # Add dl/dbeta covariance\n",
        "    covdldB = get_covdldbeta_broadcasted(XtZ, XtX, ZtZ, DinvIplusZtZD, sigma2)\n",
        "    FisherInfoMat[np.ix_(np.arange(nv_iter), np.arange(p),np.arange(p))] = covdldB\n",
        "    \n",
        "    # Add dl/dsigma2 dl/dD covariance\n",
        "    for k in np.arange(len(nparams)):\n",
        "\n",
        "      # Get covariance of dldsigma and dldD      \n",
        "      covdldsigmadD = get_covdldDkdsigma2_broadcasted(k, sigma2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict).reshape(nv_iter,FishIndsDk[k+1]-FishIndsDk[k])\n",
        "      \n",
        "      # Assign to the relevant block\n",
        "      FisherInfoMat[:,p, FishIndsDk[k]:FishIndsDk[k+1]] = covdldsigmadD\n",
        "      FisherInfoMat[:,FishIndsDk[k]:FishIndsDk[k+1],p:(p+1)] = FisherInfoMat[:,p:(p+1), FishIndsDk[k]:FishIndsDk[k+1]].transpose((0,2,1))\n",
        "      \n",
        "    # Add dl/dD covariance\n",
        "    for k1 in np.arange(len(nparams)):\n",
        "\n",
        "      for k2 in np.arange(k1+1):\n",
        "\n",
        "        IndsDk1 = np.arange(FishIndsDk[k1],FishIndsDk[k1+1])\n",
        "        IndsDk2 = np.arange(FishIndsDk[k2],FishIndsDk[k2+1])\n",
        "\n",
        "        # Get covariance between D_k1 and D_k2 \n",
        "        covdldDk1dDk2 = get_covdldDk1Dk2_broadcasted(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict)\n",
        "        \n",
        "        # Add to FImat\n",
        "        FisherInfoMat[np.ix_(np.arange(nv_iter), IndsDk1, IndsDk2)] = covdldDk1dDk2\n",
        "        FisherInfoMat[np.ix_(np.arange(nv_iter), IndsDk2, IndsDk1)] = FisherInfoMat[np.ix_(np.arange(nv_iter), IndsDk1, IndsDk2)].transpose((0,2,1))\n",
        "           \n",
        "    # Derivative and parameters\n",
        "    # ----------------------------------------------------------------------------\n",
        "\n",
        "    # Concatenate paramaters and derivatives together\n",
        "    # ----------------------------------------------------------------------------\n",
        "    paramVector = np.concatenate((beta, sigma2.reshape(nv_iter,1,1)),axis=1)\n",
        "    derivVector = np.concatenate((dldB, dldsigma2.reshape(nv_iter,1,1)),axis=1)\n",
        "\n",
        "    for k in np.arange(len(nparams)):\n",
        "\n",
        "      paramVector = np.concatenate((paramVector, mat2vech_broadcasted(Ddict[k])),axis=1)\n",
        "      derivVector = np.concatenate((derivVector, mat2vech_broadcasted(dldDdict[k])),axis=1)\n",
        "    \n",
        "    \n",
        "    # Update step\n",
        "    # ----------------------------------------------------------------------------\n",
        "    FisherInfoMat = forceSym_broadcasted(FisherInfoMat)\n",
        "    \n",
        "    paramVector = paramVector + np.einsum('i,ijk->ijk',lam,(np.linalg.inv(FisherInfoMat) @ derivVector))\n",
        "    \n",
        "    # Get the new parameters\n",
        "    beta = paramVector[:,0:p,:]\n",
        "    sigma2 = paramVector[:,p:(p+1)][:,0,0]\n",
        "    \n",
        "    # D as a dictionary\n",
        "    for k in np.arange(len(nparams)):\n",
        "\n",
        "      Ddict[k] = makeDnnd_broadcasted(vech2mat_broadcasted(paramVector[:,FishIndsDk[k]:FishIndsDk[k+1],:]))\n",
        "      \n",
        "    # Full version of D\n",
        "    D = getDfromDict_broadcasted(Ddict, nparams, nlevels)\n",
        "    \n",
        "    # Sum of squared residuals\n",
        "    ete = ssr_broadcasted(YtX, YtY, XtX, beta)\n",
        "    Zte = ZtY - (ZtX @ beta)\n",
        "    \n",
        "    # Inverse of (I+Z'ZD) multiplied by D\n",
        "    IplusZtZD = np.eye(q) + (ZtZ @ D)\n",
        "    DinvIplusZtZD = forceSym_broadcasted(D @ np.linalg.inv(IplusZtZD)) \n",
        "    \n",
        "    # Update the step size\n",
        "    llhcurr = llh_broadcasted(n, ZtZ, Zte, ete, sigma2, DinvIplusZtZD,D)\n",
        "    lam[llhprev>llhcurr] = lam[llhprev>llhcurr]/2\n",
        "        \n",
        "    # Work out which voxels converged\n",
        "    indices_ConAfterIt, indices_notConAfterIt, indices_ConDuringIt, localconverged, localnotconverged = getConvergedIndices(converged_global, (np.abs(llhprev-llhcurr)<tol))\n",
        "    converged_global[indices_ConDuringIt] = 1\n",
        "\n",
        "    # Save parameters from this run\n",
        "    savedparams[indices_ConDuringIt,:,:]=paramVector[localconverged,:,:]\n",
        "\n",
        "    # Update matrices\n",
        "    XtY = XtY[localnotconverged, :, :]\n",
        "    YtX = YtX[localnotconverged, :, :]\n",
        "    YtY = YtY[localnotconverged, :, :]\n",
        "    ZtY = ZtY[localnotconverged, :, :]\n",
        "    YtZ = YtZ[localnotconverged, :, :]\n",
        "    ete = ete[localnotconverged, :, :]\n",
        "    DinvIplusZtZD = DinvIplusZtZD[localnotconverged, :, :]\n",
        "\n",
        "    lam = lam[localnotconverged]\n",
        "    llhprev = llhprev[localnotconverged]\n",
        "    llhcurr = llhcurr[localnotconverged]\n",
        "\n",
        "    beta = beta[localnotconverged, :, :]\n",
        "    sigma2 = sigma2[localnotconverged]\n",
        "    D = D[localnotconverged, :, :]\n",
        "\n",
        "    for k in np.arange(len(nparams)):\n",
        "      Ddict[k] = Ddict[k][localnotconverged, :, :]\n",
        "      \n",
        "    # Matrices needed later by many calculations:\n",
        "    # ----------------------------------------------------------------------------\n",
        "    # X transpose e and Z transpose e\n",
        "    Xte = XtY - (XtX @ beta)\n",
        "    Zte = ZtY - (ZtX @ beta)\n",
        "    \n",
        "    t2 = time.time()\n",
        "    nit = nit + 1\n",
        "    print('Iteration num: ', nit)\n",
        "    print('Iteration time: ', t2-t1)\n",
        "    print('Num converged:', nv-nv_iter)\n",
        "  \n",
        "  print('Total time taken: ', time.time()-t1_total)\n",
        "  print('Estimated NIFTI time (hours): ', 100*100*100/(nv*60*60)*(time.time()-t1_total))\n",
        "  \n",
        "  return(savedparams)\n",
        "\n",
        "t1 = time.time()\n",
        "paramVec = FS_broadcasted(XtX, XtY, ZtX, ZtY, ZtZ, XtZ, YtZ, YtY, YtX, nlevels, nparams, 1e-6,n)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "print(\"Predicted time on nifti of size 100x100x100 (in hours): \", 100*100*100*(t2-t1)/(nv*60*60))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46rxdKv7GXqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n",
        "print(paramVec[1:10,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axQkNrbiKtLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_est_map=beta_True.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "# Show true beta, 3rd x-slice, 3rd parameter\n",
        "imshow(beta_est_map[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmn9Qm8XTshL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(paramVec.shape)\n",
        "beta_est_map=paramVec[:,0:p,:].reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "# Show true beta, 3rd x-slice, 3rd parameter\n",
        "imshow(beta_est_map[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYYN5DWIVtMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_est_map=paramVec[:,0:p,:].reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "beta_True_map=beta_True.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "# Show true beta, 3rd x-slice, 3rd parameter\n",
        "imshow((beta_est_map[3,:,:,3]-beta_True_map[3,:,:,3]).reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDcjZDH8ljV4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OazkyPfPGOOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(nparams)\n",
        "print(nlevels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_yKRnnyMVg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(b.shape)\n",
        "\n",
        "\n",
        "FishIndsDk = np.int32(np.cumsum(nparams*(nparams+1)/2) + p + 1)\n",
        "FishIndsDk = np.insert(FishIndsDk,0,p+1)\n",
        "\n",
        "# Get the parameters\n",
        "beta = paramVec[:,0:p,:]\n",
        "sigma2 = paramVec[:,p:(p+1)][:,0,0]\n",
        "\n",
        "# D as a dictionary\n",
        "for k in np.arange(len(nparams)):\n",
        "\n",
        "  Ddict[k] = makeDnnd_broadcasted(vech2mat_broadcasted(paramVec[:,FishIndsDk[k]:FishIndsDk[k+1],:]))\n",
        "\n",
        "\n",
        "  \n",
        "# Full version of D\n",
        "D = getDfromDict_broadcasted(Ddict, nparams, nlevels)\n",
        "\n",
        "DinvIplusZtZD = D @ np.linalg.inv(np.eye(q) + ZtZ @ D)\n",
        "\n",
        "Zte = ZtY - ZtX @ beta\n",
        "\n",
        "    \n",
        "b_est = (DinvIplusZtZD @ Zte).reshape(dimv[0],dimv[1],dimv[2],q)\n",
        "b_true = b.reshape(dimv[0],dimv[1],dimv[2],q)\n",
        "\n",
        "print(b_est.shape)\n",
        "# Show smoothed\n",
        "imshow(b_true[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGqvHaXgMYKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "imshow(b_est[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2alocsRqTTaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show difference\n",
        "display = 3\n",
        "imshow(b_true[display,:,:,1]-b_est[display,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "print(np.max(np.max(b_true)))\n",
        "print(np.mean(np.mean(np.abs(b_true-b_est))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYDe1behpdwK",
        "colab_type": "text"
      },
      "source": [
        "## Simplified Fisher Scoring (SFS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlKWxMdsE514",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mat_covdlDk(k, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict):\n",
        "  \n",
        "  # Sum of R_k kron R_(k1, k2, i, j) over i and j \n",
        "  for i in np.arange(nlevels[k]):\n",
        "\n",
        "    # Get the indices for the kth factor jth level\n",
        "    Iki = faclev_indices(k, i, nlevels, nparams)\n",
        "\n",
        "    # Work out R_k\n",
        "    Rki = ZtZ[np.ix_(np.arange(ZtZ.shape[0]),Iki,Iki)] - (ZtZ[:,Iki,:] @ DinvIplusZtZD @ ZtZ[:,:,Iki])\n",
        "\n",
        "    # Work out Rk kron Rk\n",
        "    RkRt = kron_broadcasted(Rki,Rki)\n",
        "\n",
        "    # Add together\n",
        "    if i == 0:\n",
        "\n",
        "      RkRtSum = RkRt\n",
        "\n",
        "    else:\n",
        "\n",
        "      RkRtSum = RkRtSum + RkRt\n",
        "\n",
        "  \n",
        "  # Return the result\n",
        "  return(forceSym_broadcasted(RkRtSum))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDE_uU7vGV61",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJnNypqYGWdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vec_2dlDk(k, nlevels, nparams, sigma2, ZtZ, Zte, DinvIplusZtZD):\n",
        "      \n",
        "  # Convert it to vector\n",
        "  vecOfInterest = 2*mat2vec_broadcasted(get_dldDk_broadcasted(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD))\n",
        "  \n",
        "  # Return it\n",
        "  return(vecOfInterest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UghzJd2kEs5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def FS_simplified_broadcasted(XtX, XtY, ZtX, ZtY, ZtZ, XtZ, YtZ, YtY, YtX, nlevels, nparams, tol,n):\n",
        "  \n",
        "  t1_total = time.time()\n",
        "  t1 = time.time()\n",
        "  \n",
        "  # Useful scalars\n",
        "  # ------------------------------------------------------------------------------\n",
        "\n",
        "  # Number of factors, r\n",
        "  r = len(nlevels)\n",
        "\n",
        "  # Number of random effects, q\n",
        "  q = np.sum(np.dot(nparams,nlevels))\n",
        "\n",
        "  # Number of fixed effects, p\n",
        "  p = XtX.shape[1]\n",
        "\n",
        "  # Number of voxels, nv\n",
        "  nv = XtY.shape[0]\n",
        "  \n",
        "  # Initial estimates\n",
        "  # ------------------------------------------------------------------------------\n",
        "\n",
        "  # Inital beta\n",
        "  beta = initBeta_broadcasted(XtX, XtY)\n",
        "  \n",
        "  # Work out e'e, X'e and Z'e\n",
        "  Xte = XtY - (XtX @ beta)\n",
        "  Zte = ZtY - (ZtX @ beta)\n",
        "  ete = ssr_broadcasted(YtX, YtY, XtX, beta)\n",
        "  \n",
        "  # Initial sigma2\n",
        "  sigma2 = initSigma2_broadcasted(ete, n)\n",
        "\n",
        "  Zte = ZtY - (ZtX @ beta) \n",
        "  \n",
        "  # Inital D\n",
        "  # Dictionary version\n",
        "  Ddict = dict()\n",
        "  for k in np.arange(len(nparams)):\n",
        "\n",
        "    Ddict[k] = makeDnnd_broadcasted(initDk_broadcasted(k, nlevels[k], ZtZ, Zte, sigma2))\n",
        "  \n",
        "  # Full version of D\n",
        "  D = getDfromDict_broadcasted(Ddict, nparams, nlevels)\n",
        "  \n",
        "  # Duplication matrices\n",
        "  # ------------------------------------------------------------------------------\n",
        "  invDupMatdict = dict()\n",
        "  dupInvDupMatdict = dict()\n",
        "  dupDuptMatdict = dict()\n",
        "  for i in np.arange(len(nparams)):\n",
        "\n",
        "    invDupMatdict[i] = np.asarray(invDupMat(nparams[i]).todense())\n",
        "    dupInvDupMatdict[i] = np.asarray(dupMat(nparams[i]).todense()) @ invDupMatdict[i]\n",
        "    dupDuptMatdict[i] = np.asarray(dupMat(nparams[i]).todense()) @ np.asarray(dupMat(nparams[i]).todense()).transpose()\n",
        "  \n",
        "  # Index variables\n",
        "  # ------------------------------------------------------------------------------\n",
        "  # Work out the total number of paramateres\n",
        "  tnp = np.int32(p + 1 + np.sum(nparams*(nparams+1)/2))\n",
        "\n",
        "  # Indices for submatrics corresponding to Dks\n",
        "  FishIndsDk = np.int32(np.cumsum(nparams*(nparams+1)/2) + p + 1)\n",
        "  FishIndsDk = np.insert(FishIndsDk,0,p+1)\n",
        "\n",
        "  Zte = ZtY - (ZtX @ beta)\n",
        "  \n",
        "  # Inverse of (I+Z'ZD) multiplied by D\n",
        "  IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "  DinvIplusZtZD =  forceSym_broadcasted(D @ np.linalg.inv(IplusZtZD)) \n",
        "  \n",
        "  # Step size lambda\n",
        "  lam = np.ones(nv)\n",
        "\n",
        "  # Initial log likelihoods\n",
        "  llhprev = -10*np.ones(XtY.shape[0])\n",
        "  llhcurr = 10*np.ones(XtY.shape[0])\n",
        "  \n",
        "  # Vector checking if all voxels converged\n",
        "  converged_global = np.zeros(nv)\n",
        "  \n",
        "  # Vector of saved parameters which have converged\n",
        "  savedparams = np.zeros((nv, np.int32(np.sum(nparams*(nparams+1)/2) + p + 1),1))\n",
        "  \n",
        "  \n",
        "  # Work out D indices (there is one block of D per level)\n",
        "  Dinds = np.zeros(np.sum(nlevels)+1)\n",
        "  counter = 0\n",
        "  for k in np.arange(len(nparams)):\n",
        "    for j in np.arange(nlevels[k]):\n",
        "      Dinds[counter] = np.concatenate((np.array([0]), np.cumsum(nlevels*nparams)))[k] + nparams[k]*j\n",
        "      counter = counter + 1\n",
        "      \n",
        "  # Last index will be missing so add it\n",
        "  Dinds[len(Dinds)-1]=Dinds[len(Dinds)-2]+nparams[-1]\n",
        "  \n",
        "  # Make sure indices are ints\n",
        "  Dinds = np.int64(Dinds)\n",
        "  \n",
        "  t2 = time.time()\n",
        "  print('Setup time: ', t2-t1)\n",
        "  \n",
        "  nit=0\n",
        "  while np.any(np.abs(llhprev-llhcurr)>tol):\n",
        "    \n",
        "    t1 = time.time()\n",
        "    # Change current likelihood to previous\n",
        "    llhprev = llhcurr\n",
        "    \n",
        "    # Work out how many voxels are left\n",
        "    nv_iter = XtY.shape[0]\n",
        "    \n",
        "    \n",
        "    #---------------------------------------------------------------------------\n",
        "    # Update beta\n",
        "    beta = np.linalg.solve(XtX - XtZ @ DinvIplusZtZD @ ZtX, XtY - XtZ @ DinvIplusZtZD @ ZtY)\n",
        "    \n",
        "    # Update sigma^2\n",
        "    ete = ssr_broadcasted(YtX, YtY, XtX, beta)\n",
        "    Zte = ZtY - (ZtX @ beta)\n",
        "    sigma2 = 1/n*(ete - Zte.transpose((0,2,1)) @ DinvIplusZtZD @ Zte).reshape(nv_iter)\n",
        "    \n",
        "    # Update D_k\n",
        "    counter = 0\n",
        "    for k in np.arange(len(nparams)):\n",
        "      \n",
        "      # Work out update amount\n",
        "      #update_k = forceSym_broadcasted(dupDuptMatdict[k] @ np.linalg.inv(get_mat_covdlDk(k, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict))) @ dupInvDupMatdict[k] @ get_vec_2dlDk(k, nlevels, nparams, sigma2, ZtZ, Zte, DinvIplusZtZD)\n",
        "      \n",
        "      #print(forceSym_broadcasted(np.linalg.inv(get_covdldDk1Dk2_broadcasted(k, k, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict))).shape)\n",
        "      #print(mat2vech_broadcasted(get_dldDk_broadcasted(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD)).shape)\n",
        "      #update_k2 = forceSym_broadcasted(np.linalg.inv(get_covdldDk1Dk2_broadcasted(k, k, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict))) @ mat2vech_broadcasted(get_dldDk_broadcasted(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD))\n",
        "      #update_k2 = mat2vec_broadcasted(vech2mat_broadcasted(update_k2))\n",
        "      \n",
        "      #print('1==2',update_k[1,:,:]-update_k2[1,:,:])\n",
        "      \n",
        "      \n",
        "      update_k3 = forceSym_broadcasted(np.linalg.inv(get_mat_covdlDk(k, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict))) @ get_vec_2dlDk(k, nlevels, nparams, sigma2, ZtZ, Zte, DinvIplusZtZD)\n",
        "      \n",
        "      #print('3==2',update_k3[1,:,:]-update_k2[1,:,:])\n",
        "      \n",
        "      # Multiply by stepsize\n",
        "      update_k3 = np.einsum('i,ijk->ijk',lam, update_k3)\n",
        "      \n",
        "      # Update D_k\n",
        "      Ddict[k] = makeDnnd_broadcasted(vec2mat_broadcasted(mat2vec_broadcasted(Ddict[k]) + update_k3))\n",
        "      \n",
        "      # Add D_k back into D and recompute DinvIplusZtZD\n",
        "      for j in np.arange(nlevels[k]):\n",
        "\n",
        "        D[:, Dinds[counter]:Dinds[counter+1], Dinds[counter]:Dinds[counter+1]] = Ddict[k]\n",
        "        counter = counter + 1\n",
        "      \n",
        "      #D = getDfromDict_broadcasted(Ddict,nparams,nlevels)\n",
        "      \n",
        "      # Inverse of (I+Z'ZD) multiplied by D\n",
        "      IplusZtZD = np.eye(q) + (ZtZ @ D)\n",
        "      DinvIplusZtZD = forceSym_broadcasted(D @ np.linalg.inv(IplusZtZD)) \n",
        "    \n",
        "    # Update the step size\n",
        "    llhcurr = llh_broadcasted(n, ZtZ, Zte, ete, sigma2, DinvIplusZtZD,D)\n",
        "    lam[llhprev>llhcurr] = lam[llhprev>llhcurr]/2\n",
        "    \n",
        "    # Work out which voxels converged\n",
        "    indices_ConAfterIt, indices_notConAfterIt, indices_ConDuringIt, localconverged, localnotconverged = getConvergedIndices(converged_global, (np.abs(llhprev-llhcurr)<tol))\n",
        "    converged_global[indices_ConDuringIt] = 1\n",
        "\n",
        "    # Save parameters from this run\n",
        "    savedparams[indices_ConDuringIt,0:p,:]=beta[localconverged,:,:]\n",
        "    savedparams[indices_ConDuringIt,p:(p+1),:]=sigma2[localconverged].reshape(sigma2[localconverged].shape[0],1,1)\n",
        "    \n",
        "    for k in np.arange(len(nparams)):\n",
        "      \n",
        "      # Get vech form of D_k\n",
        "      vech_Dk = mat2vech_broadcasted(Ddict[k][localconverged,:,:])\n",
        "      \n",
        "      # Make sure it has correct shape (i.e. shape (num voxels converged, num params for factor k squared, 1))\n",
        "      vech_Dk = vech_Dk.reshape(len(localconverged),nparams[k]*(nparams[k]+1)//2,1)\n",
        "      savedparams[indices_ConDuringIt,FishIndsDk[k]:FishIndsDk[k+1],:]=vech_Dk\n",
        "      \n",
        "    # Update matrices\n",
        "    XtY = XtY[localnotconverged, :, :]\n",
        "    YtX = YtX[localnotconverged, :, :]\n",
        "    YtY = YtY[localnotconverged, :, :]\n",
        "    ZtY = ZtY[localnotconverged, :, :]\n",
        "    YtZ = YtZ[localnotconverged, :, :]\n",
        "    ete = ete[localnotconverged, :, :]\n",
        "    DinvIplusZtZD = DinvIplusZtZD[localnotconverged, :, :]\n",
        "\n",
        "    lam = lam[localnotconverged]\n",
        "    llhprev = llhprev[localnotconverged]\n",
        "    llhcurr = llhcurr[localnotconverged]\n",
        "\n",
        "    beta = beta[localnotconverged, :, :]\n",
        "    sigma2 = sigma2[localnotconverged]\n",
        "    D = D[localnotconverged, :, :]\n",
        "\n",
        "    for k in np.arange(len(nparams)):\n",
        "      Ddict[k] = Ddict[k][localnotconverged, :, :]\n",
        "      \n",
        "    # Matrices needed later by many calculations:\n",
        "    # ----------------------------------------------------------------------------\n",
        "    # X transpose e and Z transpose e\n",
        "    Xte = XtY - (XtX @ beta)\n",
        "    Zte = ZtY - (ZtX @ beta)\n",
        "    \n",
        "    t2 = time.time()\n",
        "    nit = nit + 1\n",
        "    print('Iteration num: ', nit)\n",
        "    print('Iteration time: ', t2-t1)\n",
        "    print('Num converged:', nv-nv_iter)\n",
        "    \n",
        "  print('Total time taken: ', time.time()-t1_total)\n",
        "  print('Estimated NIFTI time (hours): ', 100*100*100/(nv*60*60)*(time.time()-t1_total))\n",
        "  \n",
        "  return(savedparams)\n",
        "\n",
        "t1 = time.time()\n",
        "paramVec = FS_simplified_broadcasted(XtX, XtY, ZtX, ZtY, ZtZ, XtZ, YtZ, YtY, YtX, nlevels, nparams, 1e-6,n)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "print(\"Predicted time on nifti of size 100x100x100 (in hours): \", 100*100*100*(t2-t1)/(nv*60*60))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPnOOTd260ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(nparams)\n",
        "print(nlevels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBXw9fiNGRKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_True_map=beta_True.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "# Show true beta, 3rd x-slice, 3rd parameter\n",
        "imshow(beta_True_map[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_RlaIJ96f-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_est_map=paramVec[:,0:p,:].reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "# Show true beta, 3rd x-slice, 3rd parameter\n",
        "imshow(beta_est_map[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtCzKnhHOxEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_est_map=paramVec[:,0:p,:].reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "beta_True_map=beta_True.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "# Show true beta, 3rd x-slice, 3rd parameter\n",
        "imshow((beta_est_map[3,:,:,3]-beta_True_map[3,:,:,3]).reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHYoRB4lQi9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n",
        "print(paramVec[1:10,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTG3UWyQQlyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITaM4phXEGY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(b.shape)\n",
        "\n",
        "\n",
        "FishIndsDk = np.int32(np.cumsum(nparams*(nparams+1)/2) + p + 1)\n",
        "FishIndsDk = np.insert(FishIndsDk,0,p+1)\n",
        "\n",
        "# Get the parameters\n",
        "beta = paramVec[:,0:p,:]\n",
        "sigma2 = paramVec[:,p:(p+1)][:,0,0]\n",
        "\n",
        "# D as a dictionary\n",
        "for k in np.arange(len(nparams)):\n",
        "\n",
        "  Ddict[k] = makeDnnd_broadcasted(vech2mat_broadcasted(paramVec[:,FishIndsDk[k]:FishIndsDk[k+1],:]))\n",
        "\n",
        "\n",
        "  \n",
        "# Full version of D\n",
        "D = getDfromDict_broadcasted(Ddict, nparams, nlevels)\n",
        "\n",
        "DinvIplusZtZD = D @ np.linalg.inv(np.eye(q) + ZtZ @ D)\n",
        "\n",
        "Zte = ZtY - ZtX @ beta\n",
        "\n",
        "    \n",
        "b_est = (DinvIplusZtZD @ Zte).reshape(dimv[0],dimv[1],dimv[2],q)\n",
        "b_true = b.reshape(dimv[0],dimv[1],dimv[2],q)\n",
        "\n",
        "print(b_est.shape)\n",
        "# Show smoothed\n",
        "imshow(b_true[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p85A1R9SEso7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show smoothed\n",
        "imshow(b_est[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4W1dCPgGbqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show difference\n",
        "display = 3\n",
        "imshow(b_true[display,:,:,1]-b_est[display,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx9WSBGjGoYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(nparams)\n",
        "print(nlevels)\n",
        "Ddict_tmp = dict()\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  Ddict_tmp[i] = np.random.randn(nv,nparams[i],nparams[i])\n",
        "  \n",
        "# Full version of D\n",
        "D = getDfromDict_broadcasted(Ddict_tmp, nparams, nlevels)\n",
        "\n",
        "t1 = time.time()\n",
        "IplusZtZD = np.eye(D.shape[1]) + ZtZ @ D\n",
        "DinvIplusZtZD = D @ np.linalg.inv(IplusZtZD)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "IplusDZtZ = np.eye(D.shape[1]) + D @ ZtZ\n",
        "k = np.linalg.solve(IplusDZtZ, D).transpose((0,2,1))\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "print(DinvIplusZtZD - k)\n",
        "print(k-k.transpose((0,2,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTtM53crDe1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DupinvDupMatdict = dict()\n",
        "for i in np.arange(len(nparams)):\n",
        "\n",
        "  DupinvDupMatdict[i] = np.asarray((dupMat(nparams[i]) @ invDupMat(nparams[i])).todense())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4074rJFzMSFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([[1,2,3],[1,2,3],[1,2,4]])\n",
        "\n",
        "print(x)\n",
        "print(makeDnnd(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfx8y6ZcQ6uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############# TODO\n",
        "\n",
        "def divAndConq(init_theta, current_inds, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds):\n",
        "  \n",
        "  # Number of voxels and dimension of block we are looking at\n",
        "  current_dimv = current_inds.shape\n",
        "  current_nv = np.prod(current_dimv)\n",
        "  \n",
        "  # Current indices as a vector\n",
        "  current_inds_vec = current_inds.reshape(current_nv)\n",
        "  \n",
        "  # Matrices for estimating mean of current block\n",
        "  XtX_current = cvxopt.matrix(XtX[0,:,:])\n",
        "  XtY_current = cvxopt.matrix(np.mean(XtY[current_inds_vec,:,:], axis=0))\n",
        "  XtZ_current = cvxopt.matrix(XtZ[0,:,:])\n",
        "  YtX_current = cvxopt.matrix(np.mean(YtX[current_inds_vec,:,:],axis=0))\n",
        "  YtY_current = cvxopt.matrix(np.mean(YtY[current_inds_vec,:,:],axis=0))\n",
        "  YtZ_current = cvxopt.matrix(np.mean(YtZ[current_inds_vec,:,:],axis=0))\n",
        "  ZtX_current = cvxopt.matrix(ZtX[0,:,:])\n",
        "  ZtY_current = cvxopt.matrix(np.mean(ZtY[current_inds_vec,:,:],axis=0))\n",
        "  ZtZ_current = cvxopt.sparse(cvxopt.matrix(ZtZ[0,:,:]))\n",
        "  \n",
        "  # Get new theta\n",
        "  tmp = minimize(PLS, init_theta, args=(ZtX_current, ZtY_current, XtX_current, ZtZ_current, XtY_current, YtX_current, YtZ_current, XtZ_current, YtY_current, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6)\n",
        "  new_theta = tmp.x\n",
        "  \n",
        "  #print('nv: ', current_nv)\n",
        "  #print('nit: ', tmp.nit)\n",
        "\n",
        "  \n",
        "  if current_dimv[0]!=1 and current_dimv[1]!=1 and current_dimv[2]!=1:\n",
        "  \n",
        "    # Split into blocks - assuming current inds is a block\n",
        "    current_inds_block1 = current_inds[:(current_dimv[0]//2),:(current_dimv[1]//2),:(current_dimv[2]//2)]\n",
        "    current_inds_block2 = current_inds[(current_dimv[0]//2):,:(current_dimv[1]//2),:(current_dimv[2]//2)]\n",
        "    current_inds_block3 = current_inds[:(current_dimv[0]//2),(current_dimv[1]//2):,:(current_dimv[2]//2)]\n",
        "    current_inds_block4 = current_inds[:(current_dimv[0]//2),:(current_dimv[1]//2),(current_dimv[2]//2):]\n",
        "    current_inds_block5 = current_inds[(current_dimv[0]//2):,(current_dimv[1]//2):,:(current_dimv[2]//2)]\n",
        "    current_inds_block6 = current_inds[(current_dimv[0]//2):,:(current_dimv[1]//2),(current_dimv[2]//2):]\n",
        "    current_inds_block7 = current_inds[:(current_dimv[0]//2),(current_dimv[1]//2):,(current_dimv[2]//2):]\n",
        "    current_inds_block8 = current_inds[(current_dimv[0]//2):,(current_dimv[1]//2):,(current_dimv[2]//2):]\n",
        "  \n",
        "    divAndConq(new_theta, current_inds_block1, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block2, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block3, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block4, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block5, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block6, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block7, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block8, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "  \n",
        "  elif current_dimv[0]!=1 and current_dimv[1]!=1:\n",
        "    \n",
        "    # Split into blocks - assuming current inds is a block\n",
        "    current_inds_block1 = current_inds[:(current_dimv[0]//2),:(current_dimv[1]//2),:]\n",
        "    current_inds_block2 = current_inds[(current_dimv[0]//2):,:(current_dimv[1]//2),:]\n",
        "    current_inds_block3 = current_inds[:(current_dimv[0]//2),(current_dimv[1]//2):,:]\n",
        "    current_inds_block4 = current_inds[(current_dimv[0]//2):,(current_dimv[1]//2):,:]\n",
        "  \n",
        "    divAndConq(new_theta, current_inds_block1, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block2, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block3, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block4, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    \n",
        "  elif current_dimv[0]!=1 and current_dimv[2]!=1:\n",
        "\n",
        "    # Split into blocks - assuming current inds is a block\n",
        "    current_inds_block1 = current_inds[:(current_dimv[0]//2),:,:(current_dimv[2]//2)]\n",
        "    current_inds_block2 = current_inds[(current_dimv[0]//2):,:,:(current_dimv[2]//2)]\n",
        "    current_inds_block3 = current_inds[:(current_dimv[0]//2),:,(current_dimv[2]//2):]\n",
        "    current_inds_block4 = current_inds[(current_dimv[0]//2):,:,(current_dimv[2]//2):]\n",
        "  \n",
        "    divAndConq(new_theta, current_inds_block1, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block2, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block3, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block4, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    \n",
        "  \n",
        "  elif current_dimv[1]!=1 and current_dimv[2]!=1:\n",
        "\n",
        "    # Split into blocks - assuming current inds is a block\n",
        "    current_inds_block1 = current_inds[:,:(current_dimv[1]//2),:(current_dimv[2]//2)]\n",
        "    current_inds_block2 = current_inds[:,(current_dimv[1]//2):,:(current_dimv[2]//2)]\n",
        "    current_inds_block3 = current_inds[:,:(current_dimv[1]//2),(current_dimv[2]//2):]\n",
        "    current_inds_block4 = current_inds[:,(current_dimv[1]//2):,(current_dimv[2]//2):]\n",
        "  \n",
        "    divAndConq(new_theta, current_inds_block1, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block2, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block3, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block4, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    \n",
        "  elif current_dimv[0]!=1:\n",
        "    \n",
        "    current_inds_block1 = current_inds[:(current_dimv[0]//2),:,:]\n",
        "    current_inds_block2 = current_inds[(current_dimv[0]//2):,:,:]\n",
        "    \n",
        "    divAndConq(new_theta, current_inds_block1, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block2, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "  \n",
        "  elif current_dimv[1]!=1:\n",
        "    \n",
        "    current_inds_block1 = current_inds[:,:(current_dimv[1]//2),:]\n",
        "    current_inds_block2 = current_inds[:,(current_dimv[1]//2):,:]\n",
        "    \n",
        "    divAndConq(new_theta, current_inds_block1, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block2, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "  \n",
        "  elif current_dimv[2]!=1:\n",
        "    \n",
        "    current_inds_block1 = current_inds[:,:,:(current_dimv[2]//2)]\n",
        "    current_inds_block2 = current_inds[:,:,(current_dimv[2]//2):]\n",
        "    \n",
        "    divAndConq(new_theta, current_inds_block1, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "    divAndConq(new_theta, current_inds_block2, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "  \n",
        "  #print('considering... ')\n",
        "  #print(current_inds)\n",
        "  #print('current dimv')\n",
        "  #print(current_dimv)\n",
        "  \n",
        "  #PLS(theta, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "  \n",
        "t1 = time.time()\n",
        "divAndConq(theta0, inds, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds)\n",
        "t2 = time.time()\n",
        "print('Time taken (seconds):', t2-t1)\n",
        "print('Estimated time taken on Nifti of size 100 by 100 by 100 (hours):', (t2-t1)*100*100*100/(nv*60*60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4xGDWx2unfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "k1 = 3\n",
        "k2 = 5\n",
        "\n",
        "N1 = dupMat(k1) @ invDupMat(k1)\n",
        "N2 = dupMat(k2) @ invDupMat(k2)\n",
        "\n",
        "\n",
        "print(N)\n",
        "\n",
        "#N = np.array([[1,0,0,0],[0,0.5,0.5,0],[0,0.5,0.5,0],[0,0,0,1]])\n",
        "\n",
        "R = np.random.randn(k1,k2)\n",
        "\n",
        "print(N1 @ np.kron(R,R))\n",
        "print(N1 @ np.kron(R,R) @ N2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh-ZQTkzllNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.random.randn(3,3,3)\n",
        "\n",
        "print(A.shape)\n",
        "\n",
        "print(np.kron(A[0,:,:],A[0,:,:])+np.kron(A[1,:,:],A[1,:,:])+np.kron(A[2,:,:],A[2,:,:]))\n",
        "\n",
        "print(np.kron(np.hstack((A[0,:,:],A[1,:,:],A[2,:,:])),np.vstack((A[0,:,:],A[1,:,:],A[2,:,:]))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oUZD2ujvG8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nibabel\n",
        "!pip install nilearn\n",
        "\n",
        "import numpy as np\n",
        "import nilearn\n",
        "import nibabel as nib\n",
        "\n",
        "# Random 4D matrix (unsmoothed)\n",
        "tmp_us = np.ones((10,10,10))\n",
        "\n",
        "# Some random affine, not important for this simulation\n",
        "affine = np.diag([1, 1, 1, 1])\n",
        "tmp_us_nii = nib.Nifti1Image(tmp_us, affine)\n",
        "\n",
        "# Smoothed beta nifti\n",
        "tmp_s = nilearn.image.smooth_img(tmp_us_nii, 0.02).get_fdata()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC2u3qUOkJAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tmp_s)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}